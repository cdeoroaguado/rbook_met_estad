<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 4 Análisis de estadística paramétrica y no paramétrica | Notas de métodos estadísticos</title>
  <meta name="description" content="Notas de clase de métodos estadísticos." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 4 Análisis de estadística paramétrica y no paramétrica | Notas de métodos estadísticos" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Notas de clase de métodos estadísticos." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 4 Análisis de estadística paramétrica y no paramétrica | Notas de métodos estadísticos" />
  
  <meta name="twitter:description" content="Notas de clase de métodos estadísticos." />
  

<meta name="author" content="Carlos de Oro Aguado" />


<meta name="date" content="2025-08-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="eda.html"/>
<link rel="next" href="tabcontingencia.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/codefolding-lua-1.1/codefolding-lua.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notas de métodos estadísticos</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Asignatura</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introducción</a>
<ul>
<li class="chapter" data-level="1.1" data-path="04-estparynopa.html"><a href="#introducci%C3%B3n-a-r-y-rstudio"><i class="fa fa-check"></i><b>1.1</b> Introducción a R y RStudio</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="04-estparynopa.html"><a href="#qu%C3%A9-es-r"><i class="fa fa-check"></i><b>1.1.1</b> ¿Qué es R?</a></li>
<li class="chapter" data-level="1.1.2" data-path="04-estparynopa.html"><a href="#qu%C3%A9-es-rstudio"><i class="fa fa-check"></i><b>1.1.2</b> ¿Qué es RStudio?</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="04-estparynopa.html"><a href="#introducci%C3%B3n-a-git-y-github"><i class="fa fa-check"></i><b>1.2</b> Introducción a Git y GitHub</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="04-estparynopa.html"><a href="#qu%C3%A9-es-git"><i class="fa fa-check"></i><b>1.2.1</b> ¿Qué es Git?</a></li>
<li class="chapter" data-level="1.2.2" data-path="04-estparynopa.html"><a href="#qu%C3%A9-es-github"><i class="fa fa-check"></i><b>1.2.2</b> ¿Qué es GitHub?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="04-estparynopa.html"><a href="#introducci%C3%B3n-a-tidyverse"><i class="fa fa-check"></i><b>1.3</b> Introducción a Tidyverse</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="04-estparynopa.html"><a href="#representaci%C3%B3n-visual-del-ecosistema-tidyverse"><i class="fa fa-check"></i><b>1.3.1</b> Representación visual del ecosistema Tidyverse</a></li>
<li class="chapter" data-level="1.3.2" data-path="intro.html"><a href="intro.html#principales-paquetes-del-tidyverse"><i class="fa fa-check"></i><b>1.3.2</b> Principales paquetes del Tidyverse</a></li>
<li class="chapter" data-level="1.3.3" data-path="04-estparynopa.html"><a href="#instalaci%C3%B3n-del-tidyverse-en-r"><i class="fa fa-check"></i><b>1.3.3</b> Instalación del Tidyverse en R</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#pasos-para-publicar-un-libro-bookdown-en-github-pages"><i class="fa fa-check"></i><b>1.4</b> Pasos para publicar un libro <code>bookdown</code> en GitHub Pages</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="04-estparynopa.html"><a href="#video-paso-a-paso-de-la-publicaci%C3%B3n-del-libro-en-github-pages"><i class="fa fa-check"></i><b>1.4.1</b> Video paso a paso de la publicación del libro en GitHub Pages</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reglas.html"><a href="reglas.html"><i class="fa fa-check"></i><b>2</b> Reglas de curso y diagnostico</a>
<ul>
<li class="chapter" data-level="2.1" data-path="reglas.html"><a href="reglas.html#reglas-de-las-clases"><i class="fa fa-check"></i><b>2.1</b> Reglas de las clases</a></li>
<li class="chapter" data-level="2.2" data-path="04-estparynopa.html"><a href="#pol%C3%ADtica-de-evaluaci%C3%B3n-y-normas-de-integridad-acad%C3%A9mica"><i class="fa fa-check"></i><b>2.2</b> Política de evaluación y normas de integridad académica</a></li>
<li class="chapter" data-level="2.3" data-path="reglas.html"><a href="reglas.html#fechas-de-taller-y-examenes"><i class="fa fa-check"></i><b>2.3</b> Fechas de taller y examenes</a></li>
<li class="chapter" data-level="2.4" data-path="04-estparynopa.html"><a href="#programaci%C3%B3n-del-curso-por-unidad"><i class="fa fa-check"></i><b>2.4</b> Programación del curso por unidad</a></li>
<li class="chapter" data-level="2.5" data-path="reglas.html"><a href="reglas.html#referencias"><i class="fa fa-check"></i><b>2.5</b> Referencias</a></li>
<li class="chapter" data-level="2.6" data-path="04-estparynopa.html"><a href="#terminos-b%C3%A1sicos-de-la-estad%C3%ADstica"><i class="fa fa-check"></i><b>2.6</b> Terminos básicos de la estadística</a></li>
<li class="chapter" data-level="2.7" data-path="04-estparynopa.html"><a href="#diagnostico-de-estad%C3%ADstica-b%C3%A1sica"><i class="fa fa-check"></i><b>2.7</b> Diagnostico de estadística básica</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="eda.html"><a href="eda.html"><i class="fa fa-check"></i><b>3</b> Análisis exploratorio de datos (EDA)</a>
<ul>
<li class="chapter" data-level="3.1" data-path="04-estparynopa.html"><a href="#cu%C3%A1ndo-debo-utilizarlo"><i class="fa fa-check"></i><b>3.1</b> ¿Cuándo debo utilizarlo?</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="04-estparynopa.html"><a href="#tipos-de-an%C3%A1lisis-exploratorio"><i class="fa fa-check"></i><b>3.1.1</b> Tipos de análisis exploratorio:</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="04-estparynopa.html"><a href="#representaci%C3%B3n-de-datos-seg%C3%BAn-su-naturaleza"><i class="fa fa-check"></i><b>3.2</b> Representación de datos según su naturaleza</a></li>
<li class="chapter" data-level="3.3" data-path="04-estparynopa.html"><a href="#presentaci%C3%B3n-y-an%C3%A1lisis-de-la-informaci%C3%B3n-en-estudios-descriptivos"><i class="fa fa-check"></i><b>3.3</b> Presentación y análisis de la información en estudios descriptivos</a></li>
<li class="chapter" data-level="3.4" data-path="04-estparynopa.html"><a href="#an%C3%A1lisis-explotario-con-variable-respuesta-num%C3%A9rica"><i class="fa fa-check"></i><b>3.4</b> Análisis explotario con variable respuesta numérica</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="eda.html"><a href="eda.html#contexto-de-los-datos-de-walmart"><i class="fa fa-check"></i><b>3.4.1</b> Contexto de los datos de Walmart</a></li>
<li class="chapter" data-level="3.4.2" data-path="04-estparynopa.html"><a href="#extracci%C3%B3n-transformaci%C3%B3n-y-carga-etl"><i class="fa fa-check"></i><b>3.4.2</b> Extracción, transformación y carga (ETL)</a></li>
<li class="chapter" data-level="3.4.3" data-path="04-estparynopa.html"><a href="#an%C3%A1lisis-de-la-variable-weekly_sales-target"><i class="fa fa-check"></i><b>3.4.3</b> Análisis de la variable <code>weekly_sales</code> (Target)</a></li>
<li class="chapter" data-level="3.4.4" data-path="04-estparynopa.html"><a href="#an%C3%A1lisis-de-las-variables-caracter%C3%ADsticas-independientes"><i class="fa fa-check"></i><b>3.4.4</b> Análisis de las variables características (independientes)</a></li>
<li class="chapter" data-level="3.4.5" data-path="04-estparynopa.html"><a href="#an%C3%A1lisis-exploratorio-bivariado"><i class="fa fa-check"></i><b>3.4.5</b> Análisis exploratorio bivariado</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="04-estparynopa.html"><a href="#an%C3%A1lisis-explotario-con-variable-respuesta-categ%C3%B3rica"><i class="fa fa-check"></i><b>3.5</b> Análisis explotario con variable respuesta categórica</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="eda.html"><a href="eda.html#contexto-del-conjunto-de-datos-de-marketing-de-un-banco"><i class="fa fa-check"></i><b>3.5.1</b> Contexto del conjunto de datos de marketing de un banco</a></li>
<li class="chapter" data-level="3.5.2" data-path="04-estparynopa.html"><a href="#extracci%C3%B3n-transformaci%C3%B3n-y-carga-etl-1"><i class="fa fa-check"></i><b>3.5.2</b> Extracción, transformación y carga (ETL)</a></li>
<li class="chapter" data-level="3.5.3" data-path="04-estparynopa.html"><a href="#an%C3%A1lisis-de-la-variable-y-target"><i class="fa fa-check"></i><b>3.5.3</b> Análisis de la variable <code>y</code> (Target)</a></li>
<li class="chapter" data-level="3.5.4" data-path="04-estparynopa.html"><a href="#an%C3%A1lisis-de-las-variables-caracter%C3%ADsticas-independientes-1"><i class="fa fa-check"></i><b>3.5.4</b> Análisis de las variables características (independientes)</a></li>
<li class="chapter" data-level="3.5.5" data-path="04-estparynopa.html"><a href="#an%C3%A1lisis-exploratorio-bivariado-1"><i class="fa fa-check"></i><b>3.5.5</b> Análisis exploratorio bivariado</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="estparynopar.html"><a href="estparynopar.html"><i class="fa fa-check"></i><b>4</b> Análisis de estadística paramétrica y no paramétrica</a>
<ul>
<li class="chapter" data-level="4.1" data-path="04-estparynopa.html"><a href="#comparaci%C3%B3n-de-medias-entre-dos-grupos-independientes-con-estad%C3%ADstica-param%C3%A9trica"><i class="fa fa-check"></i><b>4.1</b> Comparación de medias entre dos grupos independientes con estadística paramétrica</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="estparynopar.html"><a href="estparynopar.html#condiciones-del-t-test-para-muestras-independientes"><i class="fa fa-check"></i><b>4.1.1</b> Condiciones del t-test para muestras independientes</a></li>
<li class="chapter" data-level="4.1.2" data-path="estparynopar.html"><a href="estparynopar.html#grados-de-libertad"><i class="fa fa-check"></i><b>4.1.2</b> Grados de libertad</a></li>
<li class="chapter" data-level="4.1.3" data-path="04-estparynopa.html"><a href="#error-est%C3%A1ndar-de-la-diferencia-de-medias"><i class="fa fa-check"></i><b>4.1.3</b> Error estándar de la diferencia de medias</a></li>
<li class="chapter" data-level="4.1.4" data-path="04-estparynopa.html"><a href="#tama%C3%B1o-del-efecto-effect-size-en-comparaciones-de-medias"><i class="fa fa-check"></i><b>4.1.4</b> Tamaño del Efecto (Effect Size) en comparaciones de medias</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="04-estparynopa.html"><a href="#comparaci%C3%B3n-de-medias-entre-dos-grupos-pareados-con-estad%C3%ADstica-param%C3%A9trica"><i class="fa fa-check"></i><b>4.2</b> Comparación de medias entre dos grupos pareados con estadística paramétrica</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="estparynopar.html"><a href="estparynopar.html#supuestos-del-t-test-para-muestras-dependientes"><i class="fa fa-check"></i><b>4.2.1</b> Supuestos del t-test para muestras dependientes</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="04-estparynopa.html"><a href="#comparaci%C3%B3n-de-dos-grupos-independientes-con-estad%C3%ADstica-no-param%C3%A9trica"><i class="fa fa-check"></i><b>4.3</b> Comparación de dos grupos independientes con estadística no paramétrica</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="estparynopar.html"><a href="estparynopar.html#fundamento-conceptual"><i class="fa fa-check"></i><b>4.3.1</b> Fundamento conceptual</a></li>
<li class="chapter" data-level="4.3.2" data-path="04-estparynopa.html"><a href="#comparaci%C3%B3n-con-el-test-t"><i class="fa fa-check"></i><b>4.3.2</b> Comparación con el test t</a></li>
<li class="chapter" data-level="4.3.3" data-path="04-estparynopa.html"><a href="#supuestos-y-condiciones-de-aplicaci%C3%B3n"><i class="fa fa-check"></i><b>4.3.3</b> Supuestos y condiciones de aplicación</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="04-estparynopa.html"><a href="#comparaci%C3%B3n-de-dos-grupos-pareados-con-estad%C3%ADstica-no-param%C3%A9trica"><i class="fa fa-check"></i><b>4.4</b> Comparación de dos grupos pareados con estadística no paramétrica</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="04-estparynopa.html"><a href="#cu%C3%A1ndo-se-recomienda-utilizar-esta-prueba"><i class="fa fa-check"></i><b>4.4.1</b> ¿Cuándo se recomienda utilizar esta prueba?</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="04-estparynopa.html"><a href="#anova-an%C3%A1lisis-de-varianza-para-comparar-m%C3%BAltiples-medias"><i class="fa fa-check"></i><b>4.5</b> ANOVA (análisis de varianza para comparar múltiples medias)</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="04-estparynopa.html"><a href="#supuestos-y-formulaci%C3%B3n-de-las-hip%C3%B3tesis"><i class="fa fa-check"></i><b>4.5.1</b> Supuestos y formulación de las hipótesis</a></li>
<li class="chapter" data-level="4.5.2" data-path="04-estparynopa.html"><a href="#sumas-de-cuadrados-y-teorema-de-descomposici%C3%B3n"><i class="fa fa-check"></i><b>4.5.2</b> Sumas de cuadrados y teorema de descomposición</a></li>
<li class="chapter" data-level="4.5.3" data-path="estparynopar.html"><a href="estparynopar.html#estimaciones-insesgadas-de-la-varianza-poblacional"><i class="fa fa-check"></i><b>4.5.3</b> Estimaciones insesgadas de la varianza poblacional</a></li>
<li class="chapter" data-level="4.5.4" data-path="04-estparynopa.html"><a href="#teorema-de-contraste-para-el-an%C3%A1lisis-de-varianza"><i class="fa fa-check"></i><b>4.5.4</b> Teorema de contraste para el análisis de varianza</a></li>
<li class="chapter" data-level="4.5.5" data-path="04-estparynopa.html"><a href="#comparaciones-m%C3%BAltiples"><i class="fa fa-check"></i><b>4.5.5</b> Comparaciones múltiples</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="estparynopar.html"><a href="estparynopar.html#kruskalwallis"><i class="fa fa-check"></i><b>4.6</b> Kruskal–Wallis</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="04-estparynopa.html"><a href="#hip%C3%B3tesis-del-test"><i class="fa fa-check"></i><b>4.6.1</b> Hipótesis del test</a></li>
<li class="chapter" data-level="4.6.2" data-path="04-estparynopa.html"><a href="#estad%C3%ADstico-de-prueba"><i class="fa fa-check"></i><b>4.6.2</b> Estadístico de prueba</a></li>
<li class="chapter" data-level="4.6.3" data-path="estparynopar.html"><a href="estparynopar.html#condiciones-del-test-de-kruskalwallis"><i class="fa fa-check"></i><b>4.6.3</b> Condiciones del test de Kruskal–Wallis</a></li>
<li class="chapter" data-level="4.6.4" data-path="estparynopar.html"><a href="estparynopar.html#comparaciones-post-hoc"><i class="fa fa-check"></i><b>4.6.4</b> Comparaciones Post-Hoc</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="tabcontingencia.html"><a href="tabcontingencia.html"><i class="fa fa-check"></i><b>5</b> Tabla de contingencia</a>
<ul>
<li class="chapter" data-level="5.1" data-path="04-estparynopa.html"><a href="#tablas-de-contingencia-con-dos-criterios-de-clasificaci%C3%B3n"><i class="fa fa-check"></i><b>5.1</b> Tablas de contingencia con dos criterios de clasificación</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="tabcontingencia.html"><a href="tabcontingencia.html#prueba-de-homogeneidad"><i class="fa fa-check"></i><b>5.1.1</b> Prueba de homogeneidad</a></li>
<li class="chapter" data-level="5.1.2" data-path="tabcontingencia.html"><a href="tabcontingencia.html#prueba-de-independencia"><i class="fa fa-check"></i><b>5.1.2</b> Prueba de independencia</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="correglin.html"><a href="correglin.html"><i class="fa fa-check"></i><b>6</b> Correlación y regresión lineal simple</a>
<ul>
<li class="chapter" data-level="6.1" data-path="04-estparynopa.html"><a href="#correlaci%C3%B3n"><i class="fa fa-check"></i><b>6.1</b> Correlación</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias-1.html"><a href="referencias-1.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notas de métodos estadísticos</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="estparynopar" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Capítulo 4</span> Análisis de estadística paramétrica y no paramétrica<a href="estparynopar.html#estparynopar" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>El análisis de estadística paramétrica y no paramétrica comprende un conjunto de técnicas inferenciales utilizadas para contrastar hipótesis y evaluar relaciones entre variables.</p>
<p>La estadística paramétrica se basa en supuestos específicos sobre la distribución de los datos, como la normalidad y la homogeneidad de varianzas, lo que permite aplicar pruebas como la t de Student, ANOVA y pruebas de proporciones.</p>
<p>Por su parte, la estadística no paramétrica ofrece métodos alternativos que no requieren dichos supuestos estrictos, siendo útiles cuando los datos no cumplen condiciones de normalidad o se trata de escalas ordinales. Este enfoque incluye pruebas como la de Wilcoxon, Mann-Whitney, Kruskal-Wallis y Chi-cuadrado. Ambos enfoques permiten tomar decisiones estadísticas robustas y fundamentadas, adaptándose a la naturaleza de los datos analizados.</p>
<div id="comparación-de-medias-entre-dos-grupos-independientes-con-estadística-paramétrica" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Comparación de medias entre dos grupos independientes con estadística paramétrica<a href="#comparaci%C3%B3n-de-medias-entre-dos-grupos-independientes-con-estad%C3%ADstica-param%C3%A9trica" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Una de las estrategias más empleadas al comparar una variable cuantitativa entre dos grupos independientes es el contraste de medias. No obstante, observar diferencias en los promedios muestrales no implica automáticamente que exista una diferencia estadísticamente significativa a nivel poblacional. Esto se debe a que cada grupo presenta su propia variabilidad (varianza intrínseca), lo cual puede generar diferencias aparentes por el simple azar muestral.</p>
<p>Para evaluar si la diferencia observada es estadísticamente significativa, se recurre a pruebas paramétricas como el <strong>test <span class="math inline">\(Z\)</span></strong> (cuando se conoce la desviación estándar poblacional y los tamaños muestrales son grandes) o, más comúnmente, al <strong>t-test de Student</strong>, que es aplicable cuando las desviaciones estándar poblacionales son desconocidas.</p>
<p>Este tipo de pruebas permite:</p>
<ul>
<li><p><strong>Realizar pruebas de hipótesis</strong>, bajo la formulación:</p>
<p><span class="math display">\[
H_0: \mu_1 = \mu_2 \quad \text{vs} \quad H_a: \mu_1 \ne \mu_2
\]</span></p></li>
<li><p><strong>Construir intervalos de confianza</strong> para estimar la diferencia real entre las medias poblacionales con un nivel de confianza específico (por ejemplo, 95%).</p></li>
</ul>
<div id="condiciones-del-t-test-para-muestras-independientes" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Condiciones del t-test para muestras independientes<a href="estparynopar.html#condiciones-del-t-test-para-muestras-independientes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para que los resultados del t-test sean válidos, deben cumplirse las siguientes condiciones:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Independencia</strong>: Las observaciones dentro y entre los grupos deben ser independientes. Esto se garantiza si el muestreo es aleatorio y si el tamaño muestral no supera el 10% de la población (cuando no se hace con reemplazo).</p></li>
<li><p><strong>Normalidad</strong>: Las poblaciones deben seguir una distribución normal. Si bien esta condición se formula sobre las poblaciones, en la práctica se evalúa con las muestras. La prueba es robusta frente a desviaciones moderadas de normalidad si cada grupo tiene al menos 30 observaciones, gracias al <strong>Teorema del Límite Central</strong>.</p></li>
<li><p><strong>Homogeneidad de varianzas (homocedasticidad)</strong>: Se asume que ambas poblaciones tienen varianzas iguales. Esta condición puede ser verificada con pruebas como <strong>Levene</strong> o <strong>F de Fisher</strong> o <strong>Bartless</strong>. Si no se cumple, se utiliza una versión alternativa del t-test: el <strong>Welch Two Sample t-test</strong>, que ajusta los grados de libertad para corregir esta desigualdad, aunque con una ligera pérdida de precisión.</p></li>
</ol>
</div>
<div id="grados-de-libertad" class="section level3 hasAnchor" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Grados de libertad<a href="estparynopar.html#grados-de-libertad" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>En el t-test clásico (varianzas iguales):</p>
<p><span class="math display">\[df = n_1 + n_2 - 2\]</span></p></li>
<li><p>En el t-test de Welch (varianzas desiguales), los grados de libertad se aproximan con:</p>
<p><span class="math display">\[df \approx \frac{ \left( \frac{s_1^2}{n_1} + \frac{s_2^2}{n_2} \right)^2 }{ \frac{ \left( \frac{s_1^2}{n_1} \right)^2 }{n_1 - 1} + \frac{ \left( \frac{s_2^2}{n_2} \right)^2 }{n_2 - 1} }\]</span></p></li>
</ul>
</div>
<div id="error-estándar-de-la-diferencia-de-medias" class="section level3 hasAnchor" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> Error estándar de la diferencia de medias<a href="#error-est%C3%A1ndar-de-la-diferencia-de-medias" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El <strong>error estándar (SE)</strong> para comparar dos medias es:</p>
<p><span class="math display">\[SE = \sqrt{ \frac{s_1^2}{n_1} + \frac{s_2^2}{n_2} }\]</span></p>
<p>Este valor se utiliza tanto para construir intervalos de confianza como para calcular el estadístico de prueba:</p>
<p><span class="math display">\[t = \frac{\bar{x}_1 - \bar{x}_2}{SE}\]</span></p>
<p>Cuando se cumplen las condiciones mencionadas, se puede considerar que la diferencia de medias muestrales sigue una distribución <strong>t de Student</strong> con los grados de libertad apropiados. En consecuencia, los <strong>t-scores</strong> reemplazan a los <strong>z-scores</strong> en los cálculos, ajustando así los valores críticos a la incertidumbre inherente al tamaño muestral.</p>
<p>Este enfoque proporciona una herramienta poderosa para evaluar efectos de tratamientos, diferencias entre grupos y pruebas de efectividad, en una amplia gama de contextos experimentales y observacionales.</p>
</div>
<div id="tamaño-del-efecto-effect-size-en-comparaciones-de-medias" class="section level3 hasAnchor" number="4.1.4">
<h3><span class="header-section-number">4.1.4</span> Tamaño del Efecto (Effect Size) en comparaciones de medias<a href="#tama%C3%B1o-del-efecto-effect-size-en-comparaciones-de-medias" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El <strong>tamaño del efecto</strong> es una medida que cuantifica la magnitud de la diferencia observada entre grupos, sin depender del tamaño muestral ni de la inferencia estadística. A diferencia de los <em>p-values</em>, que únicamente indican si la diferencia es estadísticamente significativa bajo una hipótesis nula, el tamaño del efecto ofrece una medida de <strong>relevancia práctica</strong> o <strong>importancia clínica</strong> de los resultados.</p>
<p>En contextos de comparación de medias mediante <strong>t-tests para muestras independientes</strong>, dos de las métricas más utilizadas para estimar el tamaño del efecto son:</p>
<ol style="list-style-type: decimal">
<li>La <strong>d de Cohen</strong> representa la diferencia estandarizada entre medias, es decir, cuántas desviaciones estándar separan en promedio los grupos comparados:</li>
</ol>
<p><span class="math display">\[d = \frac{|\bar{X}_1 - \bar{X}_2|}{s_p},\]</span></p>
<p>donde <span class="math inline">\(s_p\)</span> es la desviación estándar combinada. Existen dos formas comunes de calcularla:</p>
<p>La primera es <strong>desviación estándar ponderada</strong>:</p>
<p><span class="math display">\[s_p = \sqrt{ \frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2} }\]</span>
y se usa cuando asumes que las varianzas de los dos grupos son iguales.</p>
<p>La segunda es el <strong>promedio cuadrático simple</strong>:</p>
<p><span class="math display">\[s_p = \sqrt{ \frac{s_1^2 + s_2^2}{2} }\]</span>
y se usa cuando asumes que las varianzas de los dos grupos son iguales.</p>
<p>Además, la interpretacion de valores de <span class="math inline">\(d\)</span> es:</p>
<ul>
<li><span class="math inline">\(d \leq 0.2\)</span>: tamaño del efecto <strong>pequeño</strong></li>
<li><span class="math inline">\(d \approx 0.5\)</span>: tamaño del efecto <strong>mediano</strong></li>
<li><span class="math inline">\(d \geq 0.8\)</span>: tamaño del efecto <strong>grande</strong></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><span class="math inline">\(r\)</span> de Pearson (para t-test)</li>
</ol>
<p>Este coeficiente mide la fuerza de asociación entre una variable categórica binaria (grupo) y una variable continua:</p>
<p><span class="math display">\[r = \sqrt{ \frac{t^2}{t^2 + gl} }\]</span></p>
<p>donde:</p>
<ul>
<li><span class="math inline">\(t\)</span> es el estadístico del t-test.</li>
<li><span class="math inline">\(gl\)</span> son los grados de libertad.</li>
</ul>
<p>La interpretación de valores de <span class="math inline">\(r\)</span>:</p>
<ul>
<li><span class="math inline">\(r \leq 0.1\)</span>: tamaño del efecto <strong>pequeño</strong></li>
<li><span class="math inline">\(r \geq 0.3\)</span>: tamaño del efecto <strong>mediano</strong></li>
<li><span class="math inline">\(r \geq 0.5\)</span>: tamaño del efecto <strong>grande</strong></li>
</ul>
<div class="admon-box ejemplo">
<div class="admon-title">
<span class="icon"></span> Ejemplo de presión arterial
</div>
<p>
Se ha recolectado una muestra aleatoria de pacientes para evaluar sus niveles de presión arterial. En el archivo <a href="https://github.com/cdeoroaguado/Datos/blob/main/datadescrip/datos_medicos.xlsx"><code>datos_medicos.xlsx</code></a> se encuentran registradas dos variables continuas: <code>PresionSistolica</code> y <code>PresionDiastolica</code>, correspondientes a la presión sistólica y diastólica de cada individuo, respectivamente.
</p>
<p>
Con base en esta información, verifique si existe o no una diferencia significativa entre la presión sistólica y la diastólica en la muestra analizada, y si esta diferencia es relevante desde el punto de vista práctico.
</p>
</div>
<p style="text-align: center;">
<strong>Solución</strong>
</p>
<ul>
<li>Carguemos los datos</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="estparynopar.html#cb1-1" tabindex="-1"></a><span class="fu">library</span>(readxl)</span>
<span id="cb1-2"><a href="estparynopar.html#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="estparynopar.html#cb1-3" tabindex="-1"></a><span class="co"># Lectura de los datos</span></span>
<span id="cb1-4"><a href="estparynopar.html#cb1-4" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">read_excel</span>(<span class="st">&quot;data/datos_medicos.xlsx&quot;</span>)</span>
<span id="cb1-5"><a href="estparynopar.html#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="estparynopar.html#cb1-6" tabindex="-1"></a><span class="co"># Ver las 5 primeras obeservaciones</span></span>
<span id="cb1-7"><a href="estparynopar.html#cb1-7" tabindex="-1"></a><span class="fu">head</span>(df)</span></code></pre></div>
</details>
<pre><code>## # A tibble: 6 × 2
##   Presion          Valores
##   &lt;chr&gt;              &lt;dbl&gt;
## 1 PresionSistolica    114.
## 2 PresionSistolica    118.
## 3 PresionSistolica    136.
## 4 PresionSistolica    121.
## 5 PresionSistolica    121.
## 6 PresionSistolica    137.</code></pre>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio
</div>
<p>
Realiza el análisis exploratorio del conjunto de datos
</p>
</div>
<ul>
<li>Verifiquemos si los datos tiene comportamiento normal</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="estparynopar.html#cb3-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb3-2"><a href="estparynopar.html#cb3-2" tabindex="-1"></a></span>
<span id="cb3-3"><a href="estparynopar.html#cb3-3" tabindex="-1"></a><span class="co"># dataframe de presion sistolica</span></span>
<span id="cb3-4"><a href="estparynopar.html#cb3-4" tabindex="-1"></a>dfps <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> </span>
<span id="cb3-5"><a href="estparynopar.html#cb3-5" tabindex="-1"></a>  <span class="fu">filter</span>(Presion <span class="sc">==</span> <span class="st">&quot;PresionSistolica&quot;</span>)</span>
<span id="cb3-6"><a href="estparynopar.html#cb3-6" tabindex="-1"></a></span>
<span id="cb3-7"><a href="estparynopar.html#cb3-7" tabindex="-1"></a><span class="co"># dataframe de presion diastolica</span></span>
<span id="cb3-8"><a href="estparynopar.html#cb3-8" tabindex="-1"></a>dfpd <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> </span>
<span id="cb3-9"><a href="estparynopar.html#cb3-9" tabindex="-1"></a>  <span class="fu">filter</span>(Presion <span class="sc">==</span> <span class="st">&quot;PresionDiastolica&quot;</span>)</span></code></pre></div>
</details>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="estparynopar.html#cb4-1" tabindex="-1"></a><span class="co"># kolmogorov-smirnov</span></span>
<span id="cb4-2"><a href="estparynopar.html#cb4-2" tabindex="-1"></a><span class="fu">ks.test</span>(<span class="fu">scale</span>(dfps<span class="sc">$</span>Valores),pnorm)</span></code></pre></div>
</details>
<pre><code>## 
##  Asymptotic one-sample Kolmogorov-Smirnov test
## 
## data:  scale(dfps$Valores)
## D = 0.058097, p-value = 0.8884
## alternative hypothesis: two-sided</code></pre>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="estparynopar.html#cb6-1" tabindex="-1"></a><span class="fu">ks.test</span>(<span class="fu">scale</span>(dfpd<span class="sc">$</span>Valores),pnorm)</span></code></pre></div>
</details>
<pre><code>## 
##  Asymptotic one-sample Kolmogorov-Smirnov test
## 
## data:  scale(dfpd$Valores)
## D = 0.057927, p-value = 0.8905
## alternative hypothesis: two-sided</code></pre>
<p>Con una confianza del <span class="math inline">\(95\%\)</span>, vemos que las distribuciones de la presión sistolica (<span class="math inline">\(D = 0.058097, p-valor = 0.8884\)</span>) y presión diastolica (<span class="math inline">\(D = 0.057927, p-valor = 0.8905\)</span>) proviene de una distribución normal</p>
<ul>
<li>Verifiquemos igualdad de varianzas (homocedasticidad):</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="estparynopar.html#cb8-1" tabindex="-1"></a><span class="fu">var.test</span>(dfps<span class="sc">$</span>Valores, dfpd<span class="sc">$</span>Valores)</span></code></pre></div>
</details>
<pre><code>## 
##  F test to compare two variances
## 
## data:  dfps$Valores and dfpd$Valores
## F = 0.92784, num df = 99, denom df = 99, p-value = 0.7102
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.6242897 1.3789878
## sample estimates:
## ratio of variances 
##          0.9278405</code></pre>
<p>Con una confianza del <span class="math inline">\(95\%\)</span>, vemos que no diferencias estadísticamente significativa en las varianzas de la presión sistolica y diastolica (<span class="math inline">\(F_{(99,99)}=0.92784, p-valor=0.7102\)</span>).</p>
<div class="admon-box teorema">
<div class="admon-title">
<span class="icon"></span> Teorema de razón de varianzas
</div>
<p>
<p>Si <span class="math inline">\(s_1^2\)</span> y <span class="math inline">\(s_2^2\)</span> son las varianzas de muestras aleatorias independientes de tamaño <span class="math inline">\(n_1\)</span> y <span class="math inline">\(n_2\)</span>, tomadas de poblaciones normales con varianzas <span class="math inline">\(\sigma_1^2\)</span> y <span class="math inline">\(\sigma_2^2\)</span>, respectivamente, entonces, una prueba de hipótesis con nivel de significancia <span class="math inline">\(\alpha\)</span> para la razón de varianzas <span class="math inline">\(\sigma_1^2 / \sigma_2^2\)</span> se basa en el siguiente estadístico de prueba:</p>
<p><span class="math display">\[
F = \frac{s_1^2}{s_2^2}
\]</span></p>
<p>donde <span class="math inline">\(F\)</span> se distribuye como una variable aleatoria con distribución <span class="math inline">\(F\)</span> de Fisher-Snedecor con <span class="math inline">\(v_1 = n_1 - 1\)</span> y <span class="math inline">\(v_2 = n_2 - 1\)</span> grados de libertad.</p>
<p>Además, un <strong>intervalo de confianza bilateral al nivel <span class="math inline">\(1 - \alpha\)</span></strong> para la razón de varianzas <span class="math inline">\(\sigma_1^2 / \sigma_2^2\)</span> está dado por:</p>
<p><span class="math display">\[
\left( \frac{s_1^2}{s_2^2} \cdot \frac{1}{F_{1 - \alpha/2}(v_1, v_2)},\ \frac{s_1^2}{s_2^2} \cdot \frac{1}{F_{\alpha/2}(v_1, v_2)} \right)
\]</span></p>
donde <span class="math inline">\(F_{\alpha/2}(v_1, v_2)\)</span> y <span class="math inline">\(F_{1 - \alpha/2}(v_1, v_2)\)</span> son los cuantiles de la distribución F que dejan un área de <span class="math inline">\(\alpha/2\)</span> en las colas derecha e izquierda, respectivamente.
</p>
</div>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio
</div>
<p>
Usando el teorema de razón de varianzas verifica la salida de la función <code>var.test</code> con los datos de presión arterial.
</p>
</div>
<div id="paso-a-paso-igualdad-de-varianzas" class="section level4 hasAnchor" number="4.1.4.1">
<h4><span class="header-section-number">4.1.4.1</span> Paso a paso igualdad de varianzas<a href="estparynopar.html#paso-a-paso-igualdad-de-varianzas" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>En el video pueden ver la homocedasticidad usando la función <code>var.test</code> y haciendo paso a paso con el teorema de razón de varianzas.</p>
<iframe width="100%" height="400" src="https://www.youtube.com/embed/qWObe71o2tQ" frameborder="0" allowfullscreen>
</iframe>
<ul>
<li>Veamos si hay diferencia significativas o no en el promedio de la presión sistolica y diastolica.</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="estparynopar.html#cb10-1" tabindex="-1"></a><span class="fu">t.test</span>(dfps<span class="sc">$</span>Valores,</span>
<span id="cb10-2"><a href="estparynopar.html#cb10-2" tabindex="-1"></a>       dfpd<span class="sc">$</span>Valores,</span>
<span id="cb10-3"><a href="estparynopar.html#cb10-3" tabindex="-1"></a>       <span class="at">paired=</span><span class="cn">FALSE</span>,           <span class="co"># muestras independientes</span></span>
<span id="cb10-4"><a href="estparynopar.html#cb10-4" tabindex="-1"></a>       <span class="at">var.equal =</span> <span class="cn">TRUE</span>        <span class="co"># homocedasticidad</span></span>
<span id="cb10-5"><a href="estparynopar.html#cb10-5" tabindex="-1"></a>       )</span></code></pre></div>
</details>
<pre><code>## 
##  Two Sample t-test
## 
## data:  dfps$Valores and dfpd$Valores
## t = 31.888, df = 198, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  39.36328 44.55275
## sample estimates:
## mean of x mean of y 
## 120.90406  78.94604</code></pre>
<p>La prueba <span class="math inline">\(t\)</span> para muestras independientes nos indica que con una confianza del 95%, se concluye que existe una diferencia estadísticamente significativa entre las medias de la presión sistólica y la presión diastólica (<span class="math inline">\(t_{(198)} = 31.888, p-valor &lt; 0.001\)</span>).</p>
<ul>
<li>Veamos el calculo del tamaño del efecto</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="estparynopar.html#cb12-1" tabindex="-1"></a><span class="fu">library</span>(effsize)</span>
<span id="cb12-2"><a href="estparynopar.html#cb12-2" tabindex="-1"></a></span>
<span id="cb12-3"><a href="estparynopar.html#cb12-3" tabindex="-1"></a><span class="fu">cohen.d</span>(dfps<span class="sc">$</span>Valores,</span>
<span id="cb12-4"><a href="estparynopar.html#cb12-4" tabindex="-1"></a>        dfpd<span class="sc">$</span>Valores,</span>
<span id="cb12-5"><a href="estparynopar.html#cb12-5" tabindex="-1"></a>        <span class="at">paired =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
</details>
<pre><code>## 
## Cohen&#39;s d
## 
## d estimate: 4.509702 (large)
## 95 percent confidence interval:
##    lower    upper 
## 3.984821 5.034583</code></pre>
<p>Con base en el resultado del <strong>índice de Cohen’s d</strong>, se obtiene un valor estimado de <span class="math inline">\(4.51\)</span> (<span class="math inline">\(IC_{95\%}=(3.98,5.03)\)</span>), lo que indica un tamaño del efecto <strong>extremadamente grande</strong>. Esto indica que dicha diferencia no solo es estadísticamente significativa, sino también altamente relevante desde el punto de vista práctico o clínico.</p>
<div class="admon-box teorema">
<div class="admon-title">
<span class="icon"></span> Teorema de la diferencia de medias (muestras independientes con varianzas iguales)
</div>
<p>
<p>Sea <span class="math inline">\(\bar{X}_1\)</span> y <span class="math inline">\(\bar{X}_2\)</span> las medias muestrales de dos poblaciones independientes, con tamaños <span class="math inline">\(n_1\)</span> y <span class="math inline">\(n_2\)</span>, y varianzas poblacionales iguales <span class="math inline">\(\sigma_1^2 = \sigma_2^2 = \sigma^2\)</span>. Si ambas poblaciones siguen una distribución normal, o si los tamaños muestrales son suficientemente grandes (por el teorema central del límite), entonces la estadística de prueba para contrastar la hipótesis nula:</p>
<p><span class="math display">\[
H_0 : \mu_1 = \mu_2
\quad \text{vs} \quad
H_1 : \mu_1 \neq \mu_2
\]</span></p>
<p>está dada por:</p>
<p><span class="math display">\[
t = \frac{\bar{X}_1 - \bar{X}_2}{\sqrt{S_p^2 \left( \frac{1}{n_1} + \frac{1}{n_2} \right)}}
\]</span></p>
<p>donde <span class="math inline">\(S_p^2\)</span> es la <strong>varianza combinada (pooled variance)</strong>, definida como:</p>
<p><span class="math display">\[
S_p^2 = \frac{(n_1 - 1)S_1^2 + (n_2 - 1)S_2^2}{n_1 + n_2 - 2}
\]</span></p>
<p>y <span class="math inline">\(S_1^2\)</span> y <span class="math inline">\(S_2^2\)</span> son las varianzas muestrales.</p>
<p>Esta estadística sigue una <strong>distribución t de Student</strong> con <span class="math inline">\(n_1 + n_2 - 2\)</span> grados de libertad.</p>
<p>Además, un <strong>intervalo de confianza al nivel <span class="math inline">\(1 - \alpha\)</span></strong> para la diferencia de medias <span class="math inline">\(\mu_1 - \mu_2\)</span> está dado por:</p>
<p><span class="math display">\[
\left(
(\bar{X}_1 - \bar{X}_2) \pm t_{(1 - \alpha/2,\; n_1 + n_2 - 2)} \cdot \sqrt{S_p^2 \left( \frac{1}{n_1} + \frac{1}{n_2} \right)}
\right)
\]</span></p>
</p>
</div>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio
</div>
<ol>
<li>
Usando el teorema de la diferencia de medias verifica la salida de la función <code>t.test</code> con los datos de presión arterial.
</li>
<li>
Aplica el teorema de diferencia de medias con la distribución normal.
</li>
</ol>
</div>
<div class="admon-box ejemplo">
<div class="admon-title">
<span class="icon"></span> Ejemplo de comparación de precios por tipo de cuenta
</div>
<p>
Se ha recolectado una muestra aleatoria de cuentas clasificadas en dos tipos: <code>Inversión</code> y <code>Ganancia</code>, con el fin de evaluar si existe una diferencia significativa en el valor promedio de los precios registrados. En la variable <code>Precio</code> se encuentra el valor económico asociado a cada cuenta. En el archivo <a href="https://github.com/cdeoroaguado/Datos/blob/main/datadescrip/datos_economia.xlsx"><code>datos_economia.xlsx</code></a>
</p>
<p>
Con base en esta información, se propone realizar una prueba estadística para determinar si hay diferencia significativa entre los promedios de precio según el tipo de cuenta, y evaluar si dicha diferencia es relevante desde el punto de vista práctico.
</p>
<p>
Este análisis permitirá tomar decisiones fundamentadas sobre las políticas financieras relacionadas con los tipos de cuenta manejados por la institución.
</p>
</div>
<p style="text-align: center;">
<strong>Solución</strong>
</p>
<ul>
<li>Carguemos los datos</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="estparynopar.html#cb14-1" tabindex="-1"></a><span class="fu">library</span>(readxl)</span>
<span id="cb14-2"><a href="estparynopar.html#cb14-2" tabindex="-1"></a></span>
<span id="cb14-3"><a href="estparynopar.html#cb14-3" tabindex="-1"></a><span class="co"># Lectura de los datos</span></span>
<span id="cb14-4"><a href="estparynopar.html#cb14-4" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">read_excel</span>(<span class="st">&quot;data/datos_economia.xlsx&quot;</span>)</span>
<span id="cb14-5"><a href="estparynopar.html#cb14-5" tabindex="-1"></a></span>
<span id="cb14-6"><a href="estparynopar.html#cb14-6" tabindex="-1"></a><span class="co"># Ver las 5 primeras observaciones</span></span>
<span id="cb14-7"><a href="estparynopar.html#cb14-7" tabindex="-1"></a><span class="fu">head</span>(df)</span></code></pre></div>
</details>
<pre><code>## # A tibble: 6 × 2
##   `Tipo de cuenta`   Precio
##   &lt;chr&gt;               &lt;dbl&gt;
## 1 Inversion        4439524.
## 2 Inversion        4769823.
## 3 Inversion        6558708.
## 4 Inversion        5070508.
## 5 Inversion        5129288.
## 6 Inversion        6715065.</code></pre>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio
</div>
<p>
Realiza el análisis exploratorio del conjunto de datos
</p>
</div>
<ul>
<li>Verifiquemos si los datos tiene comportamiento normal</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="estparynopar.html#cb16-1" tabindex="-1"></a><span class="co"># dataframe de inversion</span></span>
<span id="cb16-2"><a href="estparynopar.html#cb16-2" tabindex="-1"></a>inversion <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> </span>
<span id="cb16-3"><a href="estparynopar.html#cb16-3" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="st">`</span><span class="at">Tipo de cuenta</span><span class="st">`</span> <span class="sc">==</span> <span class="st">&quot;Inversion&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb16-4"><a href="estparynopar.html#cb16-4" tabindex="-1"></a>  <span class="fu">pull</span>(Precio)</span>
<span id="cb16-5"><a href="estparynopar.html#cb16-5" tabindex="-1"></a></span>
<span id="cb16-6"><a href="estparynopar.html#cb16-6" tabindex="-1"></a><span class="co"># dataframe de ganancia</span></span>
<span id="cb16-7"><a href="estparynopar.html#cb16-7" tabindex="-1"></a>ganancia <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> </span>
<span id="cb16-8"><a href="estparynopar.html#cb16-8" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="st">`</span><span class="at">Tipo de cuenta</span><span class="st">`</span> <span class="sc">==</span>  <span class="st">&quot;Ganancia&quot;</span>)<span class="sc">%&gt;%</span> </span>
<span id="cb16-9"><a href="estparynopar.html#cb16-9" tabindex="-1"></a>  <span class="fu">pull</span>(Precio)</span></code></pre></div>
</details>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="estparynopar.html#cb17-1" tabindex="-1"></a><span class="co"># kolmogorov-smirnov</span></span>
<span id="cb17-2"><a href="estparynopar.html#cb17-2" tabindex="-1"></a><span class="fu">ks.test</span>(<span class="fu">scale</span>(inversion),pnorm)</span></code></pre></div>
</details>
<pre><code>## 
##  Asymptotic one-sample Kolmogorov-Smirnov test
## 
## data:  scale(inversion)
## D = 0.058097, p-value = 0.8884
## alternative hypothesis: two-sided</code></pre>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="estparynopar.html#cb19-1" tabindex="-1"></a><span class="fu">ks.test</span>(<span class="fu">scale</span>(ganancia),pnorm)</span></code></pre></div>
</details>
<pre><code>## 
##  Asymptotic one-sample Kolmogorov-Smirnov test
## 
## data:  scale(ganancia)
## D = 0.057927, p-value = 0.8905
## alternative hypothesis: two-sided</code></pre>
<p>Con una confianza del <span class="math inline">\(95\%\)</span>, vemos que las distribuciones de la inversión (<span class="math inline">\(D = 0.058097, p-valor = 0.8884\)</span>) y la ganancia (<span class="math inline">\(D = 0.057927, p-valor = 0.8905\)</span>) proviene de una distribución normal</p>
<ul>
<li>Verifiquemos igualdad de varianzas (homocedasticidad):</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="estparynopar.html#cb21-1" tabindex="-1"></a><span class="fu">var.test</span>(Precio <span class="sc">~</span> <span class="st">`</span><span class="at">Tipo de cuenta</span><span class="st">`</span>,<span class="at">data =</span> df)</span></code></pre></div>
</details>
<pre><code>## 
##  F test to compare two variances
## 
## data:  Precio by Tipo de cuenta
## F = 0.044888, num df = 99, denom df = 99, p-value &lt; 2.2e-16
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.03020281 0.06671472
## sample estimates:
## ratio of variances 
##         0.04488844</code></pre>
<p>Con una confianza del <span class="math inline">\(95\%\)</span>, vemos que hay diferencias estadísticamente significativa en las varianzas (<span class="math inline">\(F_{(99,99)}=0.044, p-valor &lt; 0.001\)</span>).</p>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio
</div>
<p>
Aplica las pruebas de Bartlett, Levene y Fligner-Killeen, explica detalladamente cada prueba y cual distribución usa y despues interpreta el resultado.
</p>
</div>
<ul>
<li>Veamos si hay diferencia significativas o no en el promedio de la presión sistolica y diastolica.</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="estparynopar.html#cb23-1" tabindex="-1"></a><span class="fu">t.test</span>(inversion,</span>
<span id="cb23-2"><a href="estparynopar.html#cb23-2" tabindex="-1"></a>       ganancia, </span>
<span id="cb23-3"><a href="estparynopar.html#cb23-3" tabindex="-1"></a>       <span class="at">var.equal =</span> <span class="cn">FALSE</span>,</span>
<span id="cb23-4"><a href="estparynopar.html#cb23-4" tabindex="-1"></a>       <span class="at">paired=</span><span class="cn">FALSE</span>)</span></code></pre></div>
</details>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  inversion and ganancia
## t = 46.212, df = 107.87, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  4126960 4496870
## sample estimates:
## mean of x mean of y 
## 5090405.9  778490.6</code></pre>
<p>La prueba de Welch para muestras independientes nos indica que con una confianza del 95%, se concluye que existe una diferencia estadísticamente significativa entre las medias de la presión sistólica y la presión diastólica (<span class="math inline">\(t_{(107.87)} = 46.212, p-valor &lt; 0.001\)</span>).</p>
<ul>
<li>Veamos el calculo del tamaño del efecto</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="estparynopar.html#cb25-1" tabindex="-1"></a><span class="fu">library</span>(effsize)</span>
<span id="cb25-2"><a href="estparynopar.html#cb25-2" tabindex="-1"></a></span>
<span id="cb25-3"><a href="estparynopar.html#cb25-3" tabindex="-1"></a><span class="fu">cohen.d</span>(inversion,</span>
<span id="cb25-4"><a href="estparynopar.html#cb25-4" tabindex="-1"></a>        ganancia,</span>
<span id="cb25-5"><a href="estparynopar.html#cb25-5" tabindex="-1"></a>        <span class="at">paired =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
</details>
<pre><code>## 
## Cohen&#39;s d
## 
## d estimate: 6.535323 (large)
## 95 percent confidence interval:
##    lower    upper 
## 5.833174 7.237472</code></pre>
<p>Con base en el resultado del <strong>índice de Cohen’s d</strong>, se obtiene un valor estimado de <span class="math inline">\(6.53\)</span> (<span class="math inline">\(IC_{95\%}=(5.83,7.23)\)</span>), lo que indica un tamaño del efecto <strong>extremadamente grande</strong>. Esto indica que dicha diferencia no solo es estadísticamente significativa, sino también altamente relevante en el tipo de cuenta.</p>
</div>
</div>
</div>
<div id="comparación-de-medias-entre-dos-grupos-pareados-con-estadística-paramétrica" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Comparación de medias entre dos grupos pareados con estadística paramétrica<a href="#comparaci%C3%B3n-de-medias-entre-dos-grupos-pareados-con-estad%C3%ADstica-param%C3%A9trica" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Dos medias se consideran <strong>dependientes</strong> o <strong>pareadas</strong> cuando provienen de muestras relacionadas, es decir, cuando existe una correspondencia directa entre las observaciones de ambos grupos. Este tipo de diseño es común cuando las mediciones se realizan sobre los <strong>mismos individuos</strong> bajo dos condiciones diferentes.</p>
<div id="ejemplos-comunes" class="section level4 hasAnchor" number="4.2.0.1">
<h4><span class="header-section-number">4.2.0.1</span> Ejemplos comunes<a href="estparynopar.html#ejemplos-comunes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Comparar el rendimiento de estudiantes en dos pruebas distintas (por ejemplo, lectura y escritura).</li>
<li>Evaluar el efecto de un tratamiento médico comparando una variable antes y después del tratamiento en los mismos pacientes.</li>
</ul>
<p>En este contexto, para determinar si hay una diferencia significativa entre las condiciones <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>, se calcula para cada individuo la diferencia:</p>
<p><span class="math display">\[d_i = x_i - y_i\]</span></p>
<p>Aunque la hipótesis nula plantee que no existe diferencia (es decir, que <span class="math inline">\(\mu_X = \mu_Y\)</span>), debido a la variabilidad natural entre observaciones, las diferencias individuales <span class="math inline">\(d_i\)</span> no serán exactamente cero. No obstante, si no hay efecto sistemático, el promedio de estas diferencias tenderá a cero por compensación aleatoria:</p>
<p><span class="math display">\[\bar{d} = \frac{1}{n} \sum_{i=1}^{n} (x_i - y_i)\]</span></p>
<p>El análisis se centra en evaluar si este promedio de diferencias es <strong>significativamente distinto de cero</strong>, utilizando una prueba t de muestras pareadas.</p>
</div>
<div id="supuestos-del-t-test-para-muestras-dependientes" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Supuestos del t-test para muestras dependientes<a href="estparynopar.html#supuestos-del-t-test-para-muestras-dependientes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Normalidad</strong>: Se asume que las diferencias <span class="math inline">\(d_i\)</span> provienen de una distribución normal. Este supuesto puede evaluarse a partir de la muestra si no se tiene información poblacional.</li>
<li><strong>Igualdad de varianzas</strong>: <strong>No es necesario</strong> que las varianzas de los grupos originales sean iguales (no se requiere homocedasticidad).</li>
</ul>
<p>Si los supuestos se cumplen, se puede considerar que:</p>
<p><span class="math display">\[
d_i \sim \mathcal{N}(\mu_d, \sigma_d^2)
\]</span></p>
<p>Como en la mayoría de situaciones de inferencia estadística, los parámetros poblacionales son desconocidos, por lo que se estiman a partir de la muestra. Bajo estos supuestos, se tiene:</p>
<p><span class="math display">\[
\bar{d} \sim \mathcal{N}(\mu_d, \hat{\sigma}_d^2)
\]</span></p>
<p>donde <span class="math inline">\(\bar{d}\)</span> es el promedio muestral de las diferencias y <span class="math inline">\(\hat{\sigma}_d^2\)</span> es la varianza muestral de dichas diferencias.</p>
<p>El test <span class="math inline">\(t\)</span> pareado se utiliza para verificar la hipótesis:</p>
<p><span class="math display">\[
H_0: \mu_d = 0 \quad \text{vs} \quad H_1: \mu_d \neq 0
\]</span></p>
<p>La estadística de prueba está dada por:</p>
<p><span class="math display">\[
t = \frac{\bar{d}}{s_d / \sqrt{n}} \sim t_{n-1}
\]</span></p>
<p>donde</p>
<ul>
<li><span class="math inline">\(\bar{d}\)</span>: media de las diferencias</li>
<li><span class="math inline">\(s_d\)</span>: desviación estándar de las diferencias</li>
<li><span class="math inline">\(n\)</span>: número de pares</li>
</ul>
<div class="admon-box ejemplo">
<div class="admon-title">
<span class="icon"></span> Ejemplo: Evaluación del desempeño en una intervención educativa
</div>
<p>
Una institución educativa implementa una nueva estrategia de enseñanza con el objetivo de mejorar el desempeño de los estudiantes en una prueba estandarizada. Para evaluar su efectividad, se selecciona aleatoriamente una muestra de 10 estudiantes y se registra su tiempo (en segundos) para completar una tarea cognitiva específica al inicio del periodo académico. Al finalizar el año, se repite la misma medición con los mismos estudiantes.
</p>
<p>
Este diseño corresponde a un esquema de <strong>medidas pareadas</strong>, ya que las observaciones antes y después de la intervención se realizan sobre los <strong>mismos individuos</strong>. Por tanto, el análisis estadístico adecuado consiste en aplicar una <em>prueba t para muestras dependientes</em>, que permita evaluar si la estrategia implementada produjo un cambio significativo en el desempeño de los estudiantes.
</p>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="estparynopar.html#cb27-1" tabindex="-1"></a><span class="co"># Datos de tiempos antes y después de la intervención educativa</span></span>
<span id="cb27-2"><a href="estparynopar.html#cb27-2" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb27-3"><a href="estparynopar.html#cb27-3" tabindex="-1"></a>  <span class="at">estudiante =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>),</span>
<span id="cb27-4"><a href="estparynopar.html#cb27-4" tabindex="-1"></a>  <span class="at">antes =</span> <span class="fu">c</span>(<span class="fl">12.9</span>, <span class="fl">13.5</span>, <span class="fl">12.8</span>, <span class="fl">15.6</span>, <span class="fl">17.2</span>, <span class="fl">19.2</span>, <span class="fl">12.6</span>, <span class="fl">15.3</span>, <span class="fl">14.4</span>, <span class="fl">11.3</span>),</span>
<span id="cb27-5"><a href="estparynopar.html#cb27-5" tabindex="-1"></a>  <span class="at">despues =</span> <span class="fu">c</span>(<span class="fl">12.7</span>, <span class="fl">13.6</span>, <span class="fl">12.0</span>, <span class="fl">15.2</span>, <span class="fl">16.8</span>, <span class="fl">20.0</span>, <span class="fl">12.0</span>, <span class="fl">15.9</span>, <span class="fl">16.0</span>, <span class="fl">11.1</span>)</span>
<span id="cb27-6"><a href="estparynopar.html#cb27-6" tabindex="-1"></a>)</span></code></pre></div>
</details>
<p>
Con base en estas mediciones, se procederá a aplicar la prueba estadística para determinar si existe evidencia significativa de mejora en los tiempos registrados tras la implementación de la nueva metodología.
</p>
</div>
<p style="text-align: center;">
<strong>Solución</strong>
</p>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio
</div>
<p>
Realiza el análisis exploratorio del conjunto de datos
</p>
</div>
<ul>
<li>Veamos si los datos tiene comportamiento normal:</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="estparynopar.html#cb28-1" tabindex="-1"></a><span class="co"># prueba de normalidad</span></span>
<span id="cb28-2"><a href="estparynopar.html#cb28-2" tabindex="-1"></a><span class="fu">shapiro.test</span>(datos<span class="sc">$</span>antes)</span></code></pre></div>
</details>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  datos$antes
## W = 0.94444, p-value = 0.6033</code></pre>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="estparynopar.html#cb30-1" tabindex="-1"></a><span class="fu">shapiro.test</span>(datos<span class="sc">$</span>despues)</span></code></pre></div>
</details>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  datos$despues
## W = 0.93638, p-value = 0.5135</code></pre>
<p>La prueba de Shapiro_Will, nos muestra que la intervención de antes (<span class="math inline">\(W = 0.9444, p-valor = 0.6033\)</span>) y despues (<span class="math inline">\(W = 0.93638, p-valor = 0.5135\)</span>) tienen comportamiento normal.</p>
<ul>
<li>Veamos si hay diferencia significativas en los promedios de las intervenciones de antes y despues</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="estparynopar.html#cb32-1" tabindex="-1"></a><span class="fu">t.test</span>(<span class="at">x =</span> datos<span class="sc">$</span>despues,</span>
<span id="cb32-2"><a href="estparynopar.html#cb32-2" tabindex="-1"></a>       <span class="at">y =</span> datos<span class="sc">$</span>antes,</span>
<span id="cb32-3"><a href="estparynopar.html#cb32-3" tabindex="-1"></a>       <span class="at">paired =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
</details>
<pre><code>## 
##  Paired t-test
## 
## data:  datos$despues and datos$antes
## t = 0.21331, df = 9, p-value = 0.8358
## alternative hypothesis: true mean difference is not equal to 0
## 95 percent confidence interval:
##  -0.4802549  0.5802549
## sample estimates:
## mean difference 
##            0.05</code></pre>
<p>La prueba <span class="math inline">\(t\)</span> nos indica que no hay diferencias estadísticamente significativa en los promedios de las intervenciones de antes y despues (<span class="math inline">\(t_{(9)}=0.2133, p-valor = 0.8358\)</span>)</p>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio
</div>
<p>
Usando el teorema de la diferencia de medias para datos pareados verifica la salida de la función <code>t.test</code> con los datos de la intervención educativa
</p>
</div>
<ul>
<li>Calculemos el tamaño del efecto</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="estparynopar.html#cb34-1" tabindex="-1"></a><span class="fu">cohen.d</span>(<span class="at">d =</span> datos<span class="sc">$</span>antes, </span>
<span id="cb34-2"><a href="estparynopar.html#cb34-2" tabindex="-1"></a>        <span class="at">f =</span> datos<span class="sc">$</span>despues, </span>
<span id="cb34-3"><a href="estparynopar.html#cb34-3" tabindex="-1"></a>        <span class="at">paired =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
</details>
<pre><code>## 
## Cohen&#39;s d
## 
## d estimate: -0.0169815 (negligible)
## 95 percent confidence interval:
##      lower      upper 
## -0.1842481  0.1502851</code></pre>
<p>El resultado del tamaño del efecto calculado mediante Cohen’s d para muestras pareadas fue de <span class="math inline">\(-0.017\)</span> (<span class="math inline">\(IC_{95\%}=(-0.184,0.150)\)</span>), lo cual es prácticamente inexistente desde el punto de vista práctico. El intervalo de confianza nos confirma que no hay evidencia de un cambio significativo ni relevante en los tiempos registrados antes y después de la intervención.</p>
</div>
</div>
<div id="comparación-de-dos-grupos-independientes-con-estadística-no-paramétrica" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Comparación de dos grupos independientes con estadística no paramétrica<a href="#comparaci%C3%B3n-de-dos-grupos-independientes-con-estad%C3%ADstica-no-param%C3%A9trica" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El test de Mann–Whitney–Wilcoxon (WMW), también conocido como <strong>Wilcoxon rank-sum test</strong> o <strong>U-test de Mann–Whitney</strong>, es una prueba estadística no paramétrica utilizada para comparar dos muestras independientes. Su objetivo es determinar si ambas proceden de poblaciones con distribuciones similares, sin asumir normalidad ni trabajar directamente con las medias, como ocurre en los test t.</p>
<div id="fundamento-conceptual" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Fundamento conceptual<a href="estparynopar.html#fundamento-conceptual" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La idea central del test es la siguiente: si dos muestras provienen de poblaciones con la misma distribución, al combinar todas las observaciones y ordenarlas de menor a mayor, se esperaría que los valores de ambas muestras estén <strong>aleatoriamente intercalados</strong>. En cambio, si una de las muestras tiende a tener valores sistemáticamente mayores o menores, sus observaciones tenderán a <strong>agruparse hacia un extremo del ordenamiento</strong>.</p>
<p>Desde una perspectiva probabilística, el test contrasta si la probabilidad de que una observación de una población sea mayor que una de la otra es igual a 0.5:</p>
<p><span class="math display">\[
H_0: P(X &gt; Y) = 0.5 \quad \text{(no hay diferencia entre grupos)}
\]</span>
<span class="math display">\[
H_1: P(X &gt; Y) \neq 0.5 \quad \text{(hay diferencia entre grupos)}
\]</span></p>
<p>Este planteamiento no presupone normalidad ni igualdad de medias, sino que se basa en la <strong>equidistribución</strong> de las poblaciones.</p>
<div id="interpretación-y-alcance" class="section level4 hasAnchor" number="4.3.1.1">
<h4><span class="header-section-number">4.3.1.1</span> Interpretación y alcance<a href="#interpretaci%C3%B3n-y-alcance" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Aunque es frecuente leer que el test de Mann–Whitney–Wilcoxon compara medianas, esta interpretación <strong>solo es válida si ambas poblaciones tienen la misma forma de distribución</strong> (es decir, misma asimetría y varianza). En general, lo que el test evalúa es una diferencia en <strong>tendencias centrales</strong> sin especificar la medida exacta (media o mediana).</p>
<div class="admon-box advertencia">
<div class="admon-title">
<span class="icon"></span> Nota técnica: ¿El test WMW compara medianas?
</div>
<p>
Si bien se suele afirmar que el test de Mann–Whitney–Wilcoxon compara medianas, esto es estrictamente cierto <strong>solo cuando ambas poblaciones tienen la misma forma de distribución</strong>. Es decir, se requiere que presenten igual dispersión, simetría y curtosis.
</p>
<p>
En ese caso, una diferencia en la ubicación central puede interpretarse como una diferencia de medianas. Sin embargo, si las distribuciones difieren en forma, el test detecta diferencias en la <em>distribución global</em>, y no exclusivamente en la mediana.
</p>
<p>
Por tanto, el test WMW evalúa diferencias en localización general, y su interpretación como comparación de medianas debe hacerse con cautela, y solo bajo condiciones que aseguren homogeneidad de forma entre grupos.
</p>
</div>
</div>
</div>
<div id="comparación-con-el-test-t" class="section level3 hasAnchor" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Comparación con el test t<a href="#comparaci%C3%B3n-con-el-test-t" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El test WMW suele ser <strong>menos potente</strong> que el t-test cuando los supuestos del análisis paramétrico se cumplen (la pérdida de potencia se estima en torno al 5%). Esto se debe a que el WMW <strong>trabaja con rangos y no con valores reales</strong>, lo que reduce su sensibilidad frente a diferencias pequeñas. Sin embargo, esta misma característica le confiere mayor <strong>robustez ante valores atípicos</strong> y violaciones de normalidad, convirtiéndolo en una alternativa preferible en contextos donde los datos no cumplen los supuestos clásicos.</p>
</div>
<div id="supuestos-y-condiciones-de-aplicación" class="section level3 hasAnchor" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Supuestos y condiciones de aplicación<a href="#supuestos-y-condiciones-de-aplicaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para aplicar correctamente el test de Mann–Whitney–Wilcoxon se deben cumplir las siguientes condiciones:</p>
<ul>
<li><strong>Independencia de las observaciones</strong> entre los dos grupos.</li>
<li>Los datos deben ser al menos <strong>ordinales</strong>, es decir, deben poder ordenarse de menor a mayor.</li>
<li><strong>No se requiere normalidad</strong> ni homocedasticidad estricta.</li>
<li>Para interpretar el test como una comparación de medianas, se requiere que ambas poblaciones tengan <strong>distribuciones con forma similar</strong> (igual dispersión y simetría).</li>
<li>Es preferible que las muestras tengan <strong>tamaños comparables</strong>, aunque no es obligatorio.</li>
</ul>
<p>El test de Mann–Whitney–Wilcoxon es una herramienta flexible y robusta para comparar dos muestras independientes cuando no se puede asumir normalidad o cuando existen valores extremos. A cambio de una ligera pérdida de potencia frente al test t, ofrece mayor fiabilidad en contextos no paramétricos y mantiene una base sólida para contrastar diferencias de ubicación entre grupos.</p>
<div class="admon-box ejemplo">
<div class="admon-title">
<span class="icon"></span> Ejemplo de peso al nacer y hábito de fumar
</div>
<p>
Se ha recolectado una muestra representativa de nacimientos contenida en el conjunto de datos <code>births</code>, disponible en el paquete <code>openintro</code> de R. Dentro de este conjunto, se encuentran registradas variables como el <code>peso al nacer</code> (en onzas) y si la madre <code>fumó o no</code> durante el embarazo (variable categórica <code>smoke</code>: “yes” o “no”).
</p>
<p>
Con base en esta información, verifique si existe o no una diferencia significativa en el peso al nacer entre los recién nacidos cuyas madres fumaron durante el embarazo y aquellos cuyas madres no lo hicieron. Además, evalúe si esta diferencia es relevante desde el punto de vista práctico.
</p>
</div>
<p style="text-align: center;">
<strong>Solución</strong>
</p>
<ul>
<li>Carguemos los datos</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="estparynopar.html#cb36-1" tabindex="-1"></a><span class="fu">library</span>(openintro)</span>
<span id="cb36-2"><a href="estparynopar.html#cb36-2" tabindex="-1"></a></span>
<span id="cb36-3"><a href="estparynopar.html#cb36-3" tabindex="-1"></a><span class="co"># Cargar los datos</span></span>
<span id="cb36-4"><a href="estparynopar.html#cb36-4" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;births&quot;</span>)</span>
<span id="cb36-5"><a href="estparynopar.html#cb36-5" tabindex="-1"></a></span>
<span id="cb36-6"><a href="estparynopar.html#cb36-6" tabindex="-1"></a><span class="co"># Asignar a un data frame</span></span>
<span id="cb36-7"><a href="estparynopar.html#cb36-7" tabindex="-1"></a>df <span class="ot">&lt;-</span> births</span>
<span id="cb36-8"><a href="estparynopar.html#cb36-8" tabindex="-1"></a></span>
<span id="cb36-9"><a href="estparynopar.html#cb36-9" tabindex="-1"></a><span class="co"># Ver las 5 primeras observaciones</span></span>
<span id="cb36-10"><a href="estparynopar.html#cb36-10" tabindex="-1"></a><span class="fu">head</span>(df)</span></code></pre></div>
</details>
<pre><code>## # A tibble: 6 × 9
##   f_age m_age weeks premature visits gained weight sex_baby smoke    
##   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt;      &lt;int&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;    
## 1    31    30    39 full term     13      1   6.88 male     smoker   
## 2    34    36    39 full term      5     35   7.69 male     nonsmoker
## 3    36    35    40 full term     12     29   8.88 male     nonsmoker
## 4    41    40    40 full term     13     30   9    female   nonsmoker
## 5    42    37    40 full term     NA     10   7.94 male     nonsmoker
## 6    37    28    40 full term     12     35   8.25 male     smoker</code></pre>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio
</div>
<p>
Realiza el análisis exploratorio del conjunto de datos
</p>
</div>
<ul>
<li>Veamos si tienen comportamiento normal</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="estparynopar.html#cb38-1" tabindex="-1"></a><span class="fu">library</span>(nortest)</span>
<span id="cb38-2"><a href="estparynopar.html#cb38-2" tabindex="-1"></a></span>
<span id="cb38-3"><a href="estparynopar.html#cb38-3" tabindex="-1"></a>df <span class="sc">%&gt;%</span></span>
<span id="cb38-4"><a href="estparynopar.html#cb38-4" tabindex="-1"></a>  <span class="fu">group_by</span>(smoke) <span class="sc">%&gt;%</span></span>
<span id="cb38-5"><a href="estparynopar.html#cb38-5" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">n =</span> <span class="fu">length</span>(weight),</span>
<span id="cb38-6"><a href="estparynopar.html#cb38-6" tabindex="-1"></a>            <span class="at">est_ks =</span> <span class="fu">ks.test</span>(<span class="fu">scale</span>(weight),<span class="st">&#39;pnorm&#39;</span>)<span class="sc">$</span>statistic,</span>
<span id="cb38-7"><a href="estparynopar.html#cb38-7" tabindex="-1"></a>            <span class="at">p_ks =</span> <span class="fu">ks.test</span>(<span class="fu">scale</span>(weight),<span class="st">&#39;pnorm&#39;</span>)<span class="sc">$</span>p.value,</span>
<span id="cb38-8"><a href="estparynopar.html#cb38-8" tabindex="-1"></a>            <span class="at">estsw =</span> <span class="fu">shapiro.test</span>(weight)<span class="sc">$</span>statistic,</span>
<span id="cb38-9"><a href="estparynopar.html#cb38-9" tabindex="-1"></a>            <span class="at">p_sw =</span> <span class="fu">shapiro.test</span>(weight)<span class="sc">$</span>p.value,</span>
<span id="cb38-10"><a href="estparynopar.html#cb38-10" tabindex="-1"></a>            <span class="at">est_lt =</span> <span class="fu">lillie.test</span>(weight)<span class="sc">$</span>statistic,</span>
<span id="cb38-11"><a href="estparynopar.html#cb38-11" tabindex="-1"></a>            <span class="at">p_lt =</span> <span class="fu">lillie.test</span>(weight)<span class="sc">$</span>p.value)</span></code></pre></div>
</details>
<pre><code>## Warning: There were 4 warnings in `summarise()`.
## The first warning was:
## ℹ In argument: `est_ks = ks.test(scale(weight), &quot;pnorm&quot;)$statistic`.
## ℹ In group 1: `smoke = nonsmoker`.
## Caused by warning in `ks.test.default()`:
## ! ties should not be present for the one-sample Kolmogorov-Smirnov test
## ℹ Run `dplyr::last_dplyr_warnings()` to see the 3 remaining warnings.</code></pre>
<pre><code>## # A tibble: 2 × 8
##   smoke         n est_ks   p_ks estsw      p_sw est_lt     p_lt
##   &lt;fct&gt;     &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;
## 1 nonsmoker   100  0.132 0.0604 0.924 0.0000223  0.132 0.000184
## 2 smoker       50  0.125 0.413  0.895 0.000328   0.125 0.0484</code></pre>
<p>El test de <code>Lilliefors</code> evidencia que el peso de los recién nacidos no presenta un comportamiento normal en ninguno de los grupos analizados. En el caso de los hijos de madres que no fuman(<span class="math inline">\(Lilliefors = 0.132, p-valor &lt; 0.001\)</span>); mientras que para los hijos de madres que fuman (<span class="math inline">\(Lilliefors = 0.125, p-valor = 0.048\)</span>).</p>
<p>Dado que no se cumple con el supuesto de normalidad en los grupos analizados, la comparación de varianzas debe realizarse mediante pruebas robustas a esta condición. En este contexto, se recomienda emplear el test de <code>Levene</code> o el test no paramétrico de <code>Fligner-Killeen</code>, ambos diseñados para evaluar la homogeneidad de varianzas y que utilizan la mediana como medida de tendencia central, lo que los hace adecuados en presencia de datos no normales.</p>
<ul>
<li>Veamos la igualdad de varianza</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="estparynopar.html#cb41-1" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb41-2"><a href="estparynopar.html#cb41-2" tabindex="-1"></a></span>
<span id="cb41-3"><a href="estparynopar.html#cb41-3" tabindex="-1"></a><span class="fu">leveneTest</span>(weight <span class="sc">~</span> smoke, <span class="at">data =</span> df, <span class="at">center =</span> <span class="st">&quot;median&quot;</span>)</span></code></pre></div>
</details>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = &quot;median&quot;)
##        Df F value Pr(&gt;F)
## group   1  0.4442 0.5062
##       148</code></pre>
<p>La prueba de <code>Levene</code> nos indica no se encuentran diferencias significativas en la varianza del peso entre los recién nacidos de madres fumadoras y no fumadoras (<span class="math inline">\(F_{(1)}=0.4442, p-valor=0.5062\)</span>).</p>
<ul>
<li>Veamos si hay diferencia en los grupos de madres:</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="estparynopar.html#cb43-1" tabindex="-1"></a><span class="fu">library</span>(rstatix)</span>
<span id="cb43-2"><a href="estparynopar.html#cb43-2" tabindex="-1"></a></span>
<span id="cb43-3"><a href="estparynopar.html#cb43-3" tabindex="-1"></a>df <span class="sc">%&gt;%</span></span>
<span id="cb43-4"><a href="estparynopar.html#cb43-4" tabindex="-1"></a>  <span class="fu">wilcox_test</span>(weight <span class="sc">~</span> smoke, </span>
<span id="cb43-5"><a href="estparynopar.html#cb43-5" tabindex="-1"></a>              <span class="at">paired =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
</details>
<pre><code>## # A tibble: 1 × 7
##   .y.    group1    group2    n1    n2 statistic     p
## * &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;
## 1 weight nonsmoker smoker   100    50      2879 0.131</code></pre>
<p>La prueba de U de Mann-Whitney, nos muestra que no hay evidencia estadísticamente significativa de una diferencia en el peso de los recien nacidos entre madres fumadoras y no fumadoras (<span class="math inline">\(U = 2879, p-valor = 0.131\)</span>).</p>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="estparynopar.html#cb45-1" tabindex="-1"></a><span class="fu">library</span>(rstatix)</span>
<span id="cb45-2"><a href="estparynopar.html#cb45-2" tabindex="-1"></a></span>
<span id="cb45-3"><a href="estparynopar.html#cb45-3" tabindex="-1"></a>df <span class="sc">%&gt;%</span></span>
<span id="cb45-4"><a href="estparynopar.html#cb45-4" tabindex="-1"></a>  <span class="fu">wilcox_effsize</span>(weight <span class="sc">~</span> smoke, <span class="at">paired =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
</details>
<pre><code>## # A tibble: 1 × 7
##   .y.    group1    group2 effsize    n1    n2 magnitude
## * &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;ord&gt;    
## 1 weight nonsmoker smoker   0.123   100    50 small</code></pre>
<p>Es claro que si no hay diferencia estadísticamente en los grupos, el efecto es pequeño o no existe.</p>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio
</div>
<p>
¿Puedes usar una prueba paramétrica?. En caso afirmativo, ejecutela
</p>
</div>
</div>
</div>
<div id="comparación-de-dos-grupos-pareados-con-estadística-no-paramétrica" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Comparación de dos grupos pareados con estadística no paramétrica<a href="#comparaci%C3%B3n-de-dos-grupos-pareados-con-estad%C3%ADstica-no-param%C3%A9trica" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La <strong>prueba de los rangos con signo de Wilcoxon</strong> (Wilcoxon signed-rank test) es una herramienta estadística no paramétrica utilizada para comparar dos muestras relacionadas. Su uso es especialmente recomendable cuando los datos no cumplen con los supuestos de normalidad requeridos por pruebas paramétricas como el t-test para muestras pareadas.</p>
<p>Esta prueba resulta útil cuando la distribución de las diferencias entre pares de observaciones muestra asimetría, colas pesadas o cuando el tamaño muestral es demasiado reducido como para validar la normalidad mediante métodos gráficos o contrastes de hipótesis.</p>
<div id="condiciones-para-aplicar-la-prueba-de-wilcoxon-signed-rank" class="section level4 hasAnchor" number="4.4.0.1">
<h4><span class="header-section-number">4.4.0.1</span> Condiciones para aplicar la prueba de Wilcoxon signed-rank<a href="estparynopar.html#condiciones-para-aplicar-la-prueba-de-wilcoxon-signed-rank" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Antes de aplicar esta prueba, deben cumplirse las siguientes condiciones:</p>
<ul>
<li><p><strong>Dependencia entre las muestras</strong>: los datos deben provenir de <strong>observaciones emparejadas</strong> o relacionadas (por ejemplo, mediciones antes y después sobre los mismos individuos).</p></li>
<li><p><strong>Datos ordenables</strong>: los valores deben ser <strong>ordinales o continuos</strong>, de manera que puedan ordenarse de menor a mayor (o viceversa).</p></li>
<li><p><strong>No se requiere normalidad</strong>, pero sí <strong>simetría en las diferencias</strong>: no es necesario que las diferencias entre pares sigan una distribución normal, pero sí se espera que tengan una distribución <strong>simétrica alrededor de un valor central</strong> (típicamente cero).</p></li>
<li><p><strong>Opera sobre medianas</strong>: a diferencia del t-test, que se basa en la media, el Wilcoxon signed-rank test evalúa la <strong>simetría de las diferencias</strong>, lo cual suele interpretarse como un contraste sobre la <strong>mediana de las diferencias</strong>.</p></li>
<li><p>Es preferible al t-test cuando:</p>
<ul>
<li>Hay <strong>valores atípicos</strong> en los datos</li>
<li>No se cumple el <strong>criterio de normalidad</strong></li>
<li>El <strong>tamaño de muestra es pequeño</strong></li>
</ul></li>
</ul>
</div>
<div id="cuándo-se-recomienda-utilizar-esta-prueba" class="section level3 hasAnchor" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> ¿Cuándo se recomienda utilizar esta prueba?<a href="#cu%C3%A1ndo-se-recomienda-utilizar-esta-prueba" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Existen dos situaciones clave en las que es más apropiado usar el Wilcoxon signed-rank test en lugar del t-test pareado:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Cuando se detecta no normalidad</strong>:<br />
Si los datos permiten identificar que las diferencias no se distribuyen normalmente (mediante gráficos o contrastes), el t-test deja de ser adecuado. En estos casos, el test de Wilcoxon constituye una alternativa robusta. Otras opciones también válidas son el bootstrapping, la regresión cuantílica o los tests de permutación.</p></li>
<li><p><strong>Cuando no se puede verificar la distribución</strong>:<br />
Si el tamaño de muestra es tan pequeño que no permite evaluar con certeza la forma de la distribución, y no se dispone de evidencia previa sobre su comportamiento, es más prudente aplicar el Wilcoxon signed-rank test, ya que no requiere asumir normalidad.</p></li>
</ol>
<div class="admon-box nota">
<div class="admon-title">
<span class="icon"></span> Características principales
</div>
<ol>
<li>
Evalúa si las <strong>diferencias entre pares</strong> siguen una distribución <strong>simétrica</strong> alrededor de cero.
</li>
<li>
Se basa en los <strong>rangos</strong> de las diferencias absolutas, por lo que no utiliza los valores originales sino su orden.
</li>
<li>
Es aplicable a variables que se puedan ordenar (ordinales o continuas).
</li>
<li>
Posee <strong>menor poder estadístico</strong> que el t-test en datos normales, ya que ignora la magnitud exacta de los valores extremos. Sin embargo, esto lo hace <strong>más robusto frente a valores atípicos</strong> y distribuciones no normales.
</li>
</ol>
</div>
<div class="admon-box advertencia">
<div class="admon-title">
<span class="icon"></span> Consideraciones finales
</div>
<p>
El <strong>Wilcoxon signed-rank test</strong> es una opción sólida para el análisis de muestras emparejadas cuando los supuestos del t-test no se cumplen. No obstante, debe tenerse presente que un tamaño muestral pequeño limita la inferencia estadística, independientemente de la prueba empleada. Por ello, el análisis debe acompañarse de juicio experto y de otras fuentes de información cuando estén disponibles.
</p>
</div>
<div class="admon-box ejemplo">
<div class="admon-title">
<span class="icon"></span> Ejemplo
</div>
<p>
<p>Un grupo de participantes fue evaluado antes y después de una intervención formativa mediante un cuestionario estructurado. El ítem Q1 del cuestionario mide una dimensión específica del desempeño o conocimiento relacionado con la temática abordada en la intervención. A cada participante se le asignó una puntuación en dos momentos temporales: durante la fase de Pretest (antes de la intervención) y durante la fase de Posttest (después de la intervención).</p>
El propósito de este análisis es determinar si la intervención generó un cambio significativo en las respuestas al ítem Q1. Para ello, se aplicará una prueba estadística que permita comparar las puntuaciones obtenidas en el pretest y el posttest para cada participante, evaluando si dichas diferencias son estadísticamente significativas.
</p>
</div>
<p style="text-align: center;">
<strong>Solución</strong>
</p>
<ul>
<li>Carguemos el conjunto de datos</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="estparynopar.html#cb47-1" tabindex="-1"></a>url_dat <span class="ot">&lt;-</span> <span class="st">&quot;https://docs.google.com/spreadsheets/d/e/2PACX-1vQaVafuOSuEnOIiJJoB_OLF6GHib4EGqtAPnFBkNXFj29iB8yex4wYXYAAyIW16eA/pub?gid=1616716040&amp;single=true&amp;output=tsv&quot;</span></span>
<span id="cb47-2"><a href="estparynopar.html#cb47-2" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">read.delim</span>(url_dat)</span>
<span id="cb47-3"><a href="estparynopar.html#cb47-3" tabindex="-1"></a></span>
<span id="cb47-4"><a href="estparynopar.html#cb47-4" tabindex="-1"></a>datos <span class="ot">&lt;-</span> datos <span class="sc">%&gt;%</span></span>
<span id="cb47-5"><a href="estparynopar.html#cb47-5" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">c</span>(Experimento, Genero,Nivel.educativo), as.factor)) </span></code></pre></div>
</details>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio
</div>
<p>
Realiza el análisis exploratorio del conjunto de datos
</p>
</div>
<ul>
<li>Veamos si tienen comportamiento normal</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="estparynopar.html#cb48-1" tabindex="-1"></a>datos <span class="sc">%&gt;%</span></span>
<span id="cb48-2"><a href="estparynopar.html#cb48-2" tabindex="-1"></a>  <span class="fu">group_by</span>(Experimento) <span class="sc">%&gt;%</span></span>
<span id="cb48-3"><a href="estparynopar.html#cb48-3" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">n =</span> <span class="fu">length</span>(Q1),</span>
<span id="cb48-4"><a href="estparynopar.html#cb48-4" tabindex="-1"></a>            <span class="at">est_ks =</span> <span class="fu">ks.test</span>(<span class="fu">scale</span>(Q1),<span class="st">&#39;pnorm&#39;</span>)<span class="sc">$</span>statistic,</span>
<span id="cb48-5"><a href="estparynopar.html#cb48-5" tabindex="-1"></a>            <span class="at">p_ks =</span> <span class="fu">ks.test</span>(<span class="fu">scale</span>(Q1),<span class="st">&#39;pnorm&#39;</span>)<span class="sc">$</span>p.value,</span>
<span id="cb48-6"><a href="estparynopar.html#cb48-6" tabindex="-1"></a>            <span class="at">estsw =</span> <span class="fu">shapiro.test</span>(Q1)<span class="sc">$</span>statistic,</span>
<span id="cb48-7"><a href="estparynopar.html#cb48-7" tabindex="-1"></a>            <span class="at">p_sw =</span> <span class="fu">shapiro.test</span>(Q1)<span class="sc">$</span>p.value,</span>
<span id="cb48-8"><a href="estparynopar.html#cb48-8" tabindex="-1"></a>            <span class="at">est_lt =</span> <span class="fu">lillie.test</span>(Q1)<span class="sc">$</span>statistic,</span>
<span id="cb48-9"><a href="estparynopar.html#cb48-9" tabindex="-1"></a>            <span class="at">p_lt =</span> <span class="fu">lillie.test</span>(Q1)<span class="sc">$</span>p.value)</span></code></pre></div>
</details>
<pre><code>## Warning: There were 4 warnings in `summarise()`.
## The first warning was:
## ℹ In argument: `est_ks = ks.test(scale(Q1), &quot;pnorm&quot;)$statistic`.
## ℹ In group 1: `Experimento = Post-test`.
## Caused by warning in `ks.test.default()`:
## ! ties should not be present for the one-sample Kolmogorov-Smirnov test
## ℹ Run `dplyr::last_dplyr_warnings()` to see the 3 remaining warnings.</code></pre>
<pre><code>## # A tibble: 2 × 8
##   Experimento     n est_ks        p_ks estsw          p_sw est_lt     p_lt
##   &lt;fct&gt;       &lt;int&gt;  &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;
## 1 Post-test      49  0.410 0.000000143 0.645 0.00000000123  0.410 2.43e-23
## 2 Pretest        49  0.324 0.0000688   0.791 0.000000652    0.324 3.28e-14</code></pre>
<p>La prueba de <code>Shapiro-Will</code> nos muestra que los experimentos del pretest (<span class="math inline">\(W = 0.7905, p-valor &lt; 0.001\)</span>) y postest (<span class="math inline">\(W = .6447, p-valor &lt; 0.001\)</span>) no tienen comportamiento normal.</p>
<ul>
<li>Veamos si hay diferencia de la pregunta 1 segun el experimento:</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="estparynopar.html#cb51-1" tabindex="-1"></a>datos <span class="sc">%&gt;%</span></span>
<span id="cb51-2"><a href="estparynopar.html#cb51-2" tabindex="-1"></a>  rstatix<span class="sc">::</span><span class="fu">wilcox_test</span>(Q1 <span class="sc">~</span> Experimento, <span class="at">paired =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
</details>
<pre><code>## # A tibble: 1 × 7
##   .y.   group1    group2     n1    n2 statistic             p
## * &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;         &lt;dbl&gt;
## 1 Q1    Post-test Pretest    49    49      1128 0.00000000145</code></pre>
<p>La prueba de los rangos con signo de Wilcoxon para muestras pareadas nos indica que la intervención produjo un cambio estadísticamente significativo en las respuestas al ítem Q1 (<span class="math inline">\(W=1128, p-valor &lt; 0.001\)</span>). La dirección de este cambio sugiere una mejora en el desempeño de los participantes, <strong>dado que las puntuaciones en el post-test son consistentemente mayores que en el pretest</strong>.</p>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="estparynopar.html#cb53-1" tabindex="-1"></a>datos <span class="sc">%&gt;%</span></span>
<span id="cb53-2"><a href="estparynopar.html#cb53-2" tabindex="-1"></a>  rstatix<span class="sc">::</span><span class="fu">wilcox_effsize</span>(Q1 <span class="sc">~</span> Experimento, <span class="at">paired =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
</details>
<pre><code>## # A tibble: 1 × 7
##   .y.   group1    group2  effsize    n1    n2 magnitude
## * &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;ord&gt;    
## 1 Q1    Post-test Pretest   0.879    49    49 large</code></pre>
<p>Además del resultado estadísticamente significativo, el tamaño del efecto obtenido para la comparación entre las puntuaciones de Q1 en el pretest y el post-test fue de <span class="math inline">\(r = 0.8794\)</span>, lo cual representa un efecto grande. Esto indica que el cambio observado no solo es significativo, sino que también tiene relevancia práctica considerable sobre el desempeño de los participantes tras la intervención.</p>
</div>
</div>
<div id="anova-análisis-de-varianza-para-comparar-múltiples-medias" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> ANOVA (análisis de varianza para comparar múltiples medias)<a href="#anova-an%C3%A1lisis-de-varianza-para-comparar-m%C3%BAltiples-medias" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La <strong>técnica de análisis de varianza (ANOVA)</strong>, también conocida como <strong>análisis factorial</strong>, fue desarrollada por <strong>Ronald Fisher</strong> en la década de 1930 y constituye una herramienta estadística fundamental para evaluar el efecto de uno o más factores (cada uno con dos o más niveles) sobre la <strong>media de una variable continua</strong>.</p>
<p>ANOVA se utiliza cuando se desea comparar simultáneamente las medias de <strong>dos o más grupos</strong>, evaluando si las diferencias observadas son estadísticamente significativas. Además, esta técnica puede extenderse para analizar no solo los efectos principales de los factores, sino también sus posibles <strong>interacciones</strong> y, en ciertos casos, el efecto de los factores sobre la <strong>variabilidad (varianza)</strong> de la variable dependiente.</p>
<div id="supuestos-y-formulación-de-las-hipótesis" class="section level3 hasAnchor" number="4.5.1">
<h3><span class="header-section-number">4.5.1</span> Supuestos y formulación de las hipótesis<a href="#supuestos-y-formulaci%C3%B3n-de-las-hip%C3%B3tesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Se considera que existen <span class="math inline">\(k\)</span> poblaciones distintas, denominadas <strong>tratamientos</strong> o <strong>categorías</strong>, cada una de las cuales está normalmente distribuida con medias <span class="math inline">\(\mu_1, \mu_2, \dots, \mu_k\)</span>, y comparten una misma varianza común <span class="math inline">\(\sigma^2\)</span>. Para representarlas, se extraen <strong>muestras aleatorias independientes</strong> de tamaños <span class="math inline">\(n_1, n_2, \dots, n_k\)</span>, respectivamente.</p>
<p>A lo largo del análisis se utiliza la notación <span class="math inline">\(y_{ij}\)</span> para denotar la <strong>i-ésima observación</strong> dentro del <strong>j-ésimo grupo o tratamiento</strong>, facilitando así el estudio comparativo entre medias categorizadas.</p>
<p>Bajo este esquema, los datos pueden organizarse como se muestra en la Tabla <a href="estparynopar.html#tab:tabla-anova">4.1</a>, lo cual permite aplicar la técnica de análisis de varianza de un factor para contrastar la hipótesis de igualdad entre medias poblacionales <span class="citation">(<a href="#ref-llinas2019">Solano 2019</a>)</span>.</p>
<table>
<caption>
<span id="tab:tabla-anova">Tabla 4.1: </span>Observaciones muestrales de muestras aleatorias independientes de <span class="math inline">\(k\)</span> poblaciones
</caption>
<thead>
<tr>
<th style="text-align:left;">
Población 1
</th>
<th style="text-align:left;">
Población 2
</th>
<th style="text-align:left;">
Población 3
</th>
<th style="text-align:left;">
…
</th>
<th style="text-align:left;">
Población <span class="math inline">\(k\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<span class="math inline">\(y_{11}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{12}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{13}\)</span>
</td>
<td style="text-align:left;">
…
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{1k}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(y_{21}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{22}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{23}\)</span>
</td>
<td style="text-align:left;">
…
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{2k}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\vdots\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\vdots\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\vdots\)</span>
</td>
<td style="text-align:left;">
…
</td>
<td style="text-align:left;">
<span class="math inline">\(\vdots\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(y_{n_{1},1}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{n_{2},2}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{n_{3},3}\)</span>
</td>
<td style="text-align:left;">
…
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{n_{k},k}\)</span>
</td>
</tr>
</tbody>
</table>
<p>Entonces, el procedimiento para contrastar la hipótesis de igualdad de medias en este contexto se denomina <em>análisis de varianza de un factor</em>, una terminología que se hará más clara cuando tratemos otros modelos de análisis de varianza.</p>
<div class="admon-box definicion">
<div class="admon-title">
<span class="icon"></span> Definición (Hipótesis en el análisis de varianza de un factor)
</div>
<p>
<em>Supongamos que tenemos muestras aleatorias independientes con tamaños <span class="math inline">\(n_1, n_2, \ldots, n_k\)</span>. Si representamos las medias poblacionales por <span class="math inline">\(\mu_1, \mu_2, \ldots, \mu_k\)</span>, el <strong>análisis de varianza de un factor</strong> está diseñado para contrastar la hipótesis nula de que todas las medias poblacionales son iguales, es decir:</em>
</p>
<p><span class="math display">\[
  H_0: \mu_1 = \mu_2 = \cdots = \mu_k \quad \text{vs} \quad H_1: \text{Al menos dos medias son diferentes}.
  \]</span></p>
</div>
<p>A partir de la definición anterior, en este apartado desarrollaremos el contraste de la hipótesis nula de igualdad de medias entre <span class="math inline">\(k\)</span> poblaciones, considerando que se dispone de muestras aleatorias independientes para cada una de ellas.</p>
<p>Con el fin de facilitar los cálculos y el análisis posterior, los datos serán organizados en una tabla estructurada por categorías, como se muestra a continuación.</p>
<table>
<caption>
<span id="tab:tabla-anova-2">Tabla 4.2: </span>Observaciones muestrales de muestras aleatorias independientes de <span class="math inline">\(k\)</span> poblaciones
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Población 1
</th>
<th style="text-align:left;">
Población 2
</th>
<th style="text-align:left;">
Población 3
</th>
<th style="text-align:left;">
…
</th>
<th style="text-align:left;">
Población <span class="math inline">\(k\)</span>
</th>
<th style="text-align:left;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Muestras
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{11}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{12}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{13}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\cdots\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{1k}\)</span>
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{21}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{22}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{23}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\cdots\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{2k}\)</span>
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
<span class="math inline">\(\vdots\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\vdots\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\vdots\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\cdots\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\vdots\)</span>
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{n_{1},1}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{n_{2},2}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{n_{3},3}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\cdots\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(y_{n_{k},k}\)</span>
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Tamaño
</td>
<td style="text-align:left;">
<span class="math inline">\(n_1\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(n_2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(n_3\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\cdots\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(n_k\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(N\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Sumas
</td>
<td style="text-align:left;">
<span class="math inline">\(T_1\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(T_2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(T_3\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\cdots\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(T_k\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(T\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Medias
</td>
<td style="text-align:left;">
<span class="math inline">\(\bar{y}_1\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\bar{y}_2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\bar{y}_3\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\cdots\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\bar{y}_k\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\bar{y}\)</span>
</td>
</tr>
</tbody>
</table>
<p>donde</p>
<ul>
<li><span class="math inline">\(y_{ij}\)</span> es la <em>i</em>-ésima observación del tratamiento <span class="math inline">\(j\)</span>.</li>
<li><span class="math inline">\(n_j\)</span> es el tamaño de la <em>j</em>-ésima muestra.</li>
<li><span class="math inline">\(N = n_1 + n_2 + \cdots + n_k\)</span> es la suma de todos los tamaños de muestra.</li>
<li><span class="math inline">\(T_j = y_{1j} + y_{2j} + \cdots + y_{n_j,j}\)</span> es la suma de las observaciones de la muestra <em>j</em>-ésima.</li>
<li><span class="math inline">\(T = T_1 + T_2 + \cdots + T_k\)</span> es la suma de todas las observaciones.</li>
<li><span class="math inline">\(\bar{y}_j = \frac{T_j}{n_j}\)</span> es la media de las observaciones de la muestra <em>j</em>-ésima.</li>
<li><span class="math inline">\(\bar{y} = \frac{T}{N}\)</span> es la media total de todas las observaciones.</li>
</ul>
</div>
<div id="sumas-de-cuadrados-y-teorema-de-descomposición" class="section level3 hasAnchor" number="4.5.2">
<h3><span class="header-section-number">4.5.2</span> Sumas de cuadrados y teorema de descomposición<a href="#sumas-de-cuadrados-y-teorema-de-descomposici%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El contraste de igualdad de medias se fundamenta en la comparación entre dos fuentes de variabilidad en los datos muestrales:</p>
<ol style="list-style-type: decimal">
<li><p>La primera es la variabilidad en torno a las medias muestrales individuales de los <span class="math inline">\(k\)</span> grupos de observaciones. Esta se denomina <strong>variabilidad dentro de los grupos</strong>.</p></li>
<li><p>La segunda es la variabilidad entre las medias de los <span class="math inline">\(k\)</span> grupos. Esta se denomina <strong>variabilidad entre grupos</strong>.</p></li>
</ol>
<p>A continuación, definiremos medidas cuantitativas para ambos tipos de variabilidad.</p>
<div class="admon-box definicion">
<div class="admon-title">
<span class="icon"></span> Definición. Variabilidad dentro de los grupos
</div>
<p>
Es la variación de las observaciones individuales respecto a su propia media muestral dentro de cada grupo. Para el grupo <span class="math inline">\(j = 1, \ldots, k\)</span> , se define como:
</p>
<p><span class="math display">\[
  (SE)_j = \sum_{i=1}^{n_j} (y_{ij} - \bar{y}_j)^2
  \]</span></p>
</div>
<div class="admon-box definicion">
<div class="admon-title">
<span class="icon"></span> Definición. Suma de cuadrados del error (SSE)
</div>
<p>
Es la suma total de la variabilidad dentro de todos los grupos. También se conoce como <strong>suma de cuadrados dentro de los grupos</strong> y se define como:
</p>
<p><span class="math display">\[
  SSE = \sum_{j=1}^{k} \sum_{i=1}^{n_j} (y_{ij} - \bar{y}_j)^2
  \]</span></p>
</div>
<div class="admon-box definicion">
<div class="admon-title">
<span class="icon"></span> Definición. Suma de cuadrados entre grupos (SSA)
</div>
<p>
En relación con la variabilidad entre grupos, que simbolizaremos como <strong>SSA</strong>, una medida natural consiste en calcular las diferencias entre las medias muestrales de cada grupo y la media muestral global.
</p>
<p>
Estas diferencias se elevan al cuadrado para representar la desviación de cada grupo respecto a la media global. Como cada grupo <span class="math inline">\(j\)</span> tiene un tamaño <span class="math inline">\(n_j\)</span>, se pondera cada diferencia por dicho tamaño.
</p>
<p>
Así, la <strong>suma de cuadrados entre grupos</strong> (también llamada <em>suma de cuadrados de tratamientos</em>) se define como:
</p>
<p><span class="math display">\[
  SSA = \sum_{j=1}^{k} n_j (\bar{y}_j - \bar{y})^2
  \]</span></p>
<p>
donde
</p>
<ul>
<li><span class="math inline">\(\bar{y}_j\)</span> es la media muestral del grupo <span class="math inline">\(j\)</span>,</li>
<li><span class="math inline">\(\bar{y}\)</span> es la media muestral global,</li>
<li><span class="math inline">\(n_j\)</span> es el tamaño de la muestra del grupo <span class="math inline">\(j\)</span>,</li>
<li><span class="math inline">\(k\)</span> es el número total de grupos.</li>
</ul>
</div>
<div class="admon-box definicion">
<div class="admon-title">
<span class="icon"></span> Definición. Suma de cuadrados total (SST)
</div>
<p>
Es la variabilidad total de todas las observaciones con respecto a la media global. Se define como:
</p>
<p><span class="math display">\[
  SST = \sum_{j=1}^{k} \sum_{i=1}^{n_j} (y_{ij} - \bar{y})^2
  \]</span></p>
</div>
<div class="admon-box teorema">
<div class="admon-title">
<span class="icon"></span> Teorema. Descomposición de la suma de cuadrados
</div>
<p>
Supongamos que tenemos muestras aleatorias independientes de tamaños <span class="math inline">\(n_1, n_2, \ldots, n_k\)</span>, correspondientes a <span class="math inline">\(k\)</span> poblaciones. Sean <span class="math inline">\(y_{ij}\)</span> la i-ésima observación muestral en el grupo <span class="math inline">\(j\)</span>, <span class="math inline">\(\bar{y}_1, \bar{y}_2, \ldots, \bar{y}_k\)</span> las medias muestrales por grupo, y <span class="math inline">\(\bar{y}\)</span> la media muestral global. Definimos las siguientes sumas de cuadrados:
</p>
<ul>
<li><p><strong>Suma de cuadrados total (SST):</strong></p>
<p><span class="math display">\[
SST = \sum_{j=1}^{k} \sum_{i=1}^{n_j} (y_{ij} - \bar{y})^2 = \sum_{j=1}^{k} \sum_{i=1}^{n_j} y_{ij}^2 - \frac{T^2}{N}
\]</span></p></li>
<li><p><strong>Suma de cuadrados entre grupos (SSA):</strong></p>
<p><span class="math display">\[
SSA = \sum_{j=1}^{k} (\bar{y}_j - \bar{y})^2 n_j = \sum_{j=1}^{k} \frac{T_j^2}{n_j} - \frac{T^2}{N}
\]</span></p></li>
<li><p><strong>Suma de cuadrados dentro de los grupos (SSE):</strong></p>
<p><span class="math display">\[
SSE = \sum_{j=1}^{k} \sum_{i=1}^{n_j} (y_{ij} - \bar{y}_j)^2
\]</span></p></li>
</ul>
<p>
Entonces, se cumple que:
</p>
<p><span class="math display">\[
  SST = SSA + SSE
  \]</span></p>
</div>
<p style="text-align: left;">
<strong>Demostración del teorema</strong>
</p>
<p>Recordemos que la <strong>suma total de cuadrados</strong> se define como:</p>
<p><span class="math display">\[
SST = \sum_{j=1}^{k} \sum_{i=1}^{n_j} (y_{ij} - \bar{y})^2
\]</span></p>
<p>Descomponemos la diferencia <span class="math inline">\(y_{ij} - \bar{y}\)</span></p>
<p><span class="math display">\[
y_{ij} - \bar{y} = (y_{ij} - \bar{y}_j) + (\bar{y}_j - \bar{y})
\]</span></p>
<p>Elevamos al cuadrado y aplicamos la identidad</p>
<p><span class="math display">\[
(y_{ij} - \bar{y})^2 = (y_{ij} - \bar{y}_j)^2 + 2(y_{ij} - \bar{y}_j)(\bar{y}_j - \bar{y}) + (\bar{y}_j - \bar{y})^2
\]</span></p>
<p>Sumamos sobre <span class="math inline">\(i\)</span> y <span class="math inline">\(j\)</span></p>
<p><span class="math display">\[
SST = \sum_{j=1}^{k} \sum_{i=1}^{n_j} (y_{ij} - \bar{y}_j)^2 + 2 \sum_{j=1}^{k} \sum_{i=1}^{n_j} (y_{ij} - \bar{y}_j)(\bar{y}_j - \bar{y}) + \sum_{j=1}^{k} \sum_{i=1}^{n_j} (\bar{y}_j - \bar{y})^2
\]</span></p>
<p>Notemos que</p>
<ul>
<li><span class="math inline">\(\sum_{i=1}^{n_j} (y_{ij} - \bar{y}_j) = 0\)</span>, por lo tanto la <strong>segunda suma es cero</strong>.</li>
<li>En la tercera suma, <span class="math inline">\((\bar{y}_j - \bar{y})^2\)</span> no depende de <span class="math inline">\(i\)</span>, así que:</li>
</ul>
<p><span class="math display">\[
\sum_{i=1}^{n_j} (\bar{y}_j - \bar{y})^2 = n_j (\bar{y}_j - \bar{y})^2
\]</span></p>
<p>Entonces</p>
<p><span class="math display">\[
SST = \underbrace{\sum_{j=1}^{k} \sum_{i=1}^{n_j} (y_{ij} - \bar{y}_j)^2}_{SSE} + \underbrace{\sum_{j=1}^{k} n_j (\bar{y}_j - \bar{y})^2}_{SSA}
\]</span></p>
<p>Por tanto, se cumple la relación de descomposición</p>
<p><span class="math display">\[
SST = SSE + SSA. \quad \square
\]</span></p>
<details class="admon-box observacion">
<summary class="admon-title">
<span class="icon"></span> ¿Por qué <span class="math inline">\(\sum_{i=1}^{n_j} (y_{ij} - \bar{y}_j) = 0\)</span>?
</summary>
<p>
Vamos a analizar el término interno
<span class="math display">\[\sum_{i=1}^{n_j} (y_{ij} - \bar{y}_j)\]</span>
Este representa la suma de las <strong>desviaciones de cada valor respecto a su propia media grupal</strong>. Es decir, por definición tenemos que
<span class="math display">\[\bar{y}_j = \frac{1}{n_j} \sum_{i=1}^{n_j} y_{ij}
\quad \Rightarrow \quad
\sum_{i=1}^{n_j} y_{ij} = n_j \bar{y}_j.\]</span>
Entonces
<span class="math display">\[\sum_{i=1}^{n_j} (y_{ij} - \bar{y}_j)
= \sum_{i=1}^{n_j} y_{ij} - \sum_{i=1}^{n_j} \bar{y}_j
= \sum_{i=1}^{n_j} y_{ij} - n_j \bar{y}_j
= n_j \bar{y}_j - n_j \bar{y}_j = 0\]</span>
Esto se cumple <strong>para cada grupo</strong> <span class="math inline">\(j\)</span>. Luego
<span class="math display">\[\sum_{i=1}^{n_j} (y_{ij} - \bar{y}_j)(\bar{y}_j - \bar{y})
= (\bar{y}_j - \bar{y}) \cdot \sum_{i=1}^{n_j} (y_{ij} - \bar{y}_j) = (\bar{y}_j - \bar{y}) \cdot 0 = 0.\]</span>
</details>
</div>
<div id="estimaciones-insesgadas-de-la-varianza-poblacional" class="section level3 hasAnchor" number="4.5.3">
<h3><span class="header-section-number">4.5.3</span> Estimaciones insesgadas de la varianza poblacional<a href="estparynopar.html#estimaciones-insesgadas-de-la-varianza-poblacional" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El contraste de igualdad de medias en el análisis de varianza se fundamenta en el supuesto de que las <span class="math inline">\(k\)</span> poblaciones involucradas comparten una varianza poblacional común. Si la hipótesis nula de igualdad de medias es verdadera, entonces tanto la suma de cuadrados entre grupos (SSA) como la suma de cuadrados dentro de los grupos (SSE) pueden considerarse como bases válidas para estimar dicha varianza común.</p>
<p>No obstante, para obtener estimaciones adecuadas, es necesario dividir cada suma de cuadrados entre sus respectivos grados de libertad, conforme se establece en el siguiente teorema.</p>
<p>Antes de iniciar con los teoremas debemos recordar algunos conceptos de teoricos</p>
<div class="admon-box definicion">
<div class="admon-title">
<span class="icon"></span> Definición. Esperanza de una variable aleatoria
</div>
<p>
Sea <span class="math inline">\((\Omega, \mathcal{F}, P)\)</span> un espacio de probabilidad y <span class="math inline">\(X\)</span> una variable aleatoria real.
</p>
<p>
<strong>a)</strong> Si <span class="math inline">\(X\)</span> es una variable aleatoria discreta con valores <span class="math inline">\(x_1, x_2, \ldots\)</span>, se dice que la <strong>esperanza</strong> de <span class="math inline">\(X\)</span> existe si:
</p>
<p><span class="math display">\[
  \sum_{k=1}^{\infty} |x_k| P(X = k) &lt; \infty
  \]</span></p>
<p>
En este caso, se define la esperanza o valor esperado de <span class="math inline">\(X\)</span> como:
</p>
<p><span class="math display">\[
  E(X) = \sum_{k=1}^{\infty} x_k P(X = k)
  \]</span></p>
<p>
<strong>b)</strong> Si <span class="math inline">\(X\)</span> es una variable aleatoria continua con función de densidad <span class="math inline">\(f_X\)</span>, se dice que la esperanza de <span class="math inline">\(X\)</span> existe si:
</p>
<p><span class="math display">\[
  \int_{-\infty}^{\infty} |x| f_X(x) \, dx &lt; \infty
  \]</span></p>
<p>
En este caso, se define la esperanza o valor esperado de <span class="math inline">\(X\)</span> como:
</p>
<p><span class="math display">\[
  E(X) = \int_{-\infty}^{\infty} x f_X(x) \, dx
  \]</span></p>
</div>
<div class="admon-box teorema">
<div class="admon-title">
<span class="icon"></span> Teorema. Propiedades de la esperanza
</div>
<p>
Sean <span class="math inline">\((\Omega, \mathcal{F}, P)\)</span> un espacio de probabilidad y <span class="math inline">\(X\)</span> sean variables aleatorias reales. Entonces:
</p>
<ol>
<li>
<span class="math inline">\(E(a) = a\)</span>; para cada constante <span class="math inline">\(a \in \mathbb{R}\)</span>.
</li>
<li>
Si <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> son constantes y si <span class="math inline">\(g\)</span> y <span class="math inline">\(h\)</span> son funciones, tales que <span class="math inline">\(g(X)\)</span> y <span class="math inline">\(h(X)\)</span> son variables aleatorias cuyos valores esperados existen, entonces el valor esperado de <span class="math inline">\((a g(X) + b h(X))\)</span> existe y:
<span class="math display">\[
      E(a g(X) + b h(X)) = a E(g(X)) + b E(h(X))
      \]</span>
</li>
<li>
Si <span class="math inline">\(g\)</span> y <span class="math inline">\(h\)</span> son funciones tales que <span class="math inline">\(g(X)\)</span> y <span class="math inline">\(h(X)\)</span> son variables aleatorias cuyos valores esperados existen y si <span class="math inline">\(g(x) \leq h(x)\)</span> para todo <span class="math inline">\(x\)</span>, entonces:
<span class="math display">\[
      E(g(X)) \leq E(h(X)).
      \]</span>
En particular, <span class="math inline">\(|E(X)| \leq E(|X|)\)</span>.
</li>
</ol>
</div>
<div class="admon-box definicion">
<div class="admon-title">
<span class="icon"></span> Definición. Estimador insesgado
</div>
<p>
Sea <span class="math inline">\(\theta\)</span> un parámetro poblacional y <span class="math inline">\(\hat{\theta}\)</span> un estimador de <span class="math inline">\(\theta\)</span>. Se dice que <span class="math inline">\(\hat{\theta}\)</span> es <strong>insesgado</strong> si su valor esperado coincide con el valor verdadero del parámetro, es decir,
</p>
<p><span class="math display">\[
  E(\hat{\theta}) = \theta
  \]</span></p>
<p>
En otras palabras, un estimador es insesgado cuando, en promedio, no sobrestima ni subestima el valor del parámetro que pretende estimar.
</p>
</div>
<div class="admon-box teorema">
<div class="admon-title">
<span class="icon"></span> Teorema. MSA y MSE insesgado de <span class="math inline">\(\, \sigma^2\)</span>
</div>
<p>
Supongamos que tenemos muestras aleatorias independientes de tamaños <span class="math inline">\(n_1, n_2, \ldots, n_k\)</span>, correspondientes a <span class="math inline">\(k\)</span> poblaciones con varianzas iguales (<span class="math inline">\(\sigma^2\)</span>). Sea <span class="math inline">\(N\)</span> el tamaño muestral total, de manera que <span class="math inline">\(N = n_1 + n_2 + \cdots + n_k\)</span>. Sean <span class="math inline">\(SSA\)</span> y <span class="math inline">\(SSE\)</span> como en el teorema de descomposición de la suma de cuadrados. Entonces, dos estimaciones insesgadas de <span class="math inline">\(\sigma^2\)</span> son las siguientes:
</p>
<ul>
<li><p><strong>Cuadrado medio entre los grupos (o del tratamiento):</strong></p>
<p><span class="math display">\[
MSA = \frac{SSA}{k - 1}
\]</span></p></li>
<li><p><strong>Cuadrado medio dentro de los grupos (o del error):</strong></p>
<p><span class="math display">\[
MSE = \frac{SSE}{N - k}
\]</span></p></li>
</ul>
</div>
<p style="text-align: left;">
<strong>Demostración del teorema</strong>
</p>
<p>Primero probemos que <span class="math inline">\(\mathbb{E}[MSE] = \sigma^2\)</span>. Sabemos que</p>
<p><span class="math display">\[SSE = \sum_{j=1}^{k} \sum_{i=1}^{n_j} (y_{ij} - \bar{y}_j)^2 = \sum_{j=1}^k (n_j - 1) s_j^2, \quad \left( s=\frac{\sum_{i=1}^{n}(x_i-\bar{x})^2}{n-1}\right)\]</span></p>
<p>Cada <span class="math inline">\(s_j^2\)</span> es un estimador insesgado de la varianza poblacional por lo que</p>
<p><span class="math display">\[\mathbb{E}[s_j^2] = \sigma^2 \Rightarrow \mathbb{E}[(n_j - 1) s_j^2] = (n_j - 1) \sigma^2\]</span></p>
<p>luego</p>
<p><span class="math display">\[\mathbb{E}[SSE] = \sum_{j=1}^{k} \mathbb{E}[(n_j - 1) s_j^2] = \sum_{j=1}^k (n_j - 1) \sigma^2 = (N - k) \sigma^2.\]</span></p>
<p>En consecuencia</p>
<p><span class="math display">\[\mathbb{E}[MSE] = \mathbb{E} \left[ \frac{SSE}{N - k} \right] = \frac{\mathbb{E}[SSE]}{N - k} = \frac{(N - k)\sigma^2}{N - k} = \sigma^2\]</span></p>
<p>Esto preuba que <strong>MSE es un estimador insesgado de</strong> <span class="math inline">\(\sigma^2\)</span>.</p>
<p>De otro lado, probemos que <span class="math inline">\(\mathbb{E}[MSA] = \sigma^2\)</span>. En efecto, supongamos que se tienen <span class="math inline">\(k\)</span> grupos independientes, cada uno con <span class="math inline">\(n_j\)</span> observaciones:</p>
<p><span class="math display">\[y_{ij} = \mu + \tau_j + \epsilon_{ij} \quad \text{con } \epsilon_{ij} \sim \mathcal{N}(0, \sigma^2), \text{ independientes}\]</span></p>
<p>donde:</p>
<ul>
<li><span class="math inline">\(y_{ij}\)</span>: i-ésima observación del grupo j</li>
<li><span class="math inline">\(\mu\)</span>: media global general</li>
<li><span class="math inline">\(\tau_j\)</span>: efecto del tratamiento j (con <span class="math inline">\(\sum_{j=1}^k \tau_j = 0\)</span>)</li>
<li><span class="math inline">\(\epsilon_{ij}\)</span>: error aleatorio con varianza común <span class="math inline">\(\sigma^2\)</span></li>
</ul>
<p>y supongamos que</p>
<p><span class="math display">\[H_0: \tau_1 = \tau_2 = \cdots = \tau_k = 0\]</span></p>
<p>Sabemos que la suma de cuadrados entre tratamientos (SSA) se define como:</p>
<p><span class="math display">\[SSA = \sum_{j=1}^{k} n_j (\bar{y}_j - \bar{y})^2\]</span></p>
<p>donde</p>
<ul>
<li><span class="math inline">\(\bar{y}_j = \frac{1}{n_j} \sum_{i=1}^{n_j} y_{ij}\)</span>: media del grupo <span class="math inline">\(j\)</span></li>
<li><span class="math inline">\(\bar{y} = \frac{1}{N} \sum_{j=1}^k \sum_{i=1}^{n_j} y_{ij}\)</span>: media global, con <span class="math inline">\(N = \sum_{j=1}^k n_j.\)</span></li>
</ul>
<p>Entonces</p>
<p><span class="math inline">\(\mathbb{E}[\bar{y}_j] = \mu + \tau_j\)</span>,</p>
<p><span class="math inline">\(\mathbb{E}[\bar{y}] = \mu \quad \text{(ya que } \sum \tau_j = 0 \text{)}\)</span></p>
<p>por lo que la expresión en términos de variables aleatorias</p>
<p><span class="math display">\[\mathbb{E}[SSA] = \mathbb{E}\left[ \sum_{j=1}^k n_j (\bar{y}_j - \bar{y})^2 \right],\]</span></p>
<p>expandiendo el cuadrado</p>
<p><span class="math display">\[
(\bar{y}_j - \bar{y})^2 = \bar{y}_j^2 - 2\bar{y}_j\bar{y} + \bar{y}^2
\]</span></p>
<p>luego</p>
<p><span class="math display">\[
SSA = \sum_{j=1}^k n_j \left(\bar{y}_j^2 - 2\bar{y}_j\bar{y} + \bar{y}^2\right) = \sum_{j=1}^k n_j \bar{y}_j^2 - 2\bar{y} \sum_{j=1}^k n_j \bar{y}_j + N \bar{y}^2
\]</span></p>
<p>Sabemos que</p>
<p><span class="math display">\[
\sum_{j=1}^k n_j \bar{y}_j = N \bar{y}
\]</span></p>
<p>y por lo tanto</p>
<p><span class="math display">\[
SSA = \sum_{j=1}^k n_j \bar{y}_j^2 - N \bar{y}^2
\]</span></p>
<p>Ahora, la esperanza de SSA</p>
<p><span class="math display">\[
\mathbb{E}[SSA] = \sum_{j=1}^k n_j \mathbb{E}[\bar{y}_j^2] - N \mathbb{E}[\bar{y}]^2
\]</span></p>
<p>usando</p>
<p><span class="math display">\[
\text{Var}(\bar{y}_j) = \frac{\sigma^2}{n_j}, \quad \mathbb{E}[\bar{y}_j^2] = (\mu + \tau_j)^2 + \frac{\sigma^2}{n_j}
\]</span></p>
<p><span class="math display">\[
\mathbb{E}[\bar{y}]^2 = \mu^2 + \text{Var}(\bar{y}) = \mu^2 + \frac{\sigma^2}{N}
\]</span></p>
<p>por lo que</p>
<p><span class="math display">\[
\mathbb{E}[SSA] = \sum_{j=1}^k n_j \left[(\mu + \tau_j)^2 + \frac{\sigma^2}{n_j}\right] - N \left(\mu^2 + \frac{\sigma^2}{N}\right)
\]</span></p>
<p>distribuyendo</p>
<p><span class="math display">\[
\sum_{j=1}^k n_j (\mu + \tau_j)^2 + \sum_{j=1}^k \sigma^2 - N\mu^2 - \sigma^2.
\]</span></p>
<p>Observamos que</p>
<p><span class="math display">\[
\sum_{j=1}^k n_j (\mu + \tau_j)^2 = N\mu^2 + \sum_{j=1}^k n_j \tau_j^2 \quad \text{(ya que } \sum n_j \tau_j = 0 \text{)}
\]</span></p>
<p>y finalmente</p>
<p><span class="math display">\[
\mathbb{E}[SSA] = N\mu^2 + \sum n_j \tau_j^2 + k\sigma^2 - N\mu^2 - \sigma^2 = \sum n_j \tau_j^2 + (k - 1)\sigma^2
\]</span></p>
<p><strong>Bajo la hipótesis nula H₀: todos los <span class="math inline">\(\tau_j = 0\)</span>, entonces:</strong></p>
<p><span class="math display">\[
\mathbb{E}[SSA] = (k - 1)\sigma^2
\]</span></p>
<p>En conclusión,
<span class="math display">\[
\mathbb{E}\left[\frac{SSA}{k - 1}\right] = \sigma^2 \Rightarrow MSA \text{ es insesgado.} \quad \square
\]</span></p>
</div>
<div id="teorema-de-contraste-para-el-análisis-de-varianza" class="section level3 hasAnchor" number="4.5.4">
<h3><span class="header-section-number">4.5.4</span> Teorema de contraste para el análisis de varianza<a href="#teorema-de-contraste-para-el-an%C3%A1lisis-de-varianza" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Si la <strong>hipótesis nula</strong> fuera cierta, contaríamos con dos estimaciones insesgadas de una misma cantidad: la <strong>varianza poblacional común</strong>. Sería razonable esperar que ambas estimaciones fueran numéricamente similares. Sin embargo, a mayor discrepancia entre ellas, suponiendo que todo lo demás permanece constante, mayor será la sospecha de que la hipótesis nula no se cumple.</p>
<p>Por tanto, el contraste de la hipótesis nula de igualdad de medias se basa en la <strong>razón entre los cuadrados medios</strong>:</p>
<p><span class="math display">\[
F = \frac{MSA}{MSE}
\]</span></p>
<p>donde:</p>
<ul>
<li><span class="math inline">\(MSA\)</span> es el <strong>cuadrado medio entre grupos</strong> (Mean Square for the Factor),</li>
<li><span class="math inline">\(MSE\)</span> es el <strong>cuadrado medio dentro de los grupos</strong> (Mean Square Error).</li>
</ul>
<p>Si el cociente <span class="math inline">\(F\)</span> se aproxima a 1, no hay evidencia para rechazar la hipótesis nula, lo que indicaría que las medias poblacionales son estadísticamente similares. Sin embargo, si la <strong>variabilidad entre grupos</strong> es considerablemente mayor en comparación con la <strong>variabilidad interna</strong>, entonces <span class="math inline">\(F\)</span> será sustancialmente mayor que 1, y se interpretará como evidencia contra la hipótesis nula.</p>
<p>Este razonamiento se formaliza mediante un contraste estadístico: si la hipótesis nula es verdadera y se cumplen los supuestos de normalidad y homogeneidad de varianzas, entonces el estadístico <span class="math inline">\(F\)</span> sigue una <strong>distribución F de Snedecor</strong>, con:</p>
<ul>
<li><span class="math inline">\(k - 1\)</span> grados de libertad en el numerador, y<br />
</li>
<li><span class="math inline">\(n - k\)</span> grados de libertad en el denominador,</li>
</ul>
<p>donde <span class="math inline">\(k\)</span> es el número de grupos y <span class="math inline">\(n\)</span> es el tamaño total de la muestra.</p>
<p>Este resultado se resume en el siguiente teorema:</p>
<div class="admon-box teorema">
<div class="admon-title">
<span class="icon"></span> Teorema. Contraste de hipótesis para el análisis de varianza de un factor.
</div>
<p>
Supongamos que se tienen muestras aleatorias independientes de tamaños <span class="math inline">\(n_1, n_2, \dots, n_k\)</span>, correspondientes a <span class="math inline">\(k\)</span> poblaciones. Sea <span class="math inline">\(N\)</span> el tamaño muestral total, de modo que:
</p>
<p><span class="math display">\[N = n_1 + n_2 + \cdots + n_k\]</span></p>
<p>
Si las medias poblacionales se denotan por <span class="math inline">\(\mu_1, \mu_2, \dots, \mu_k\)</span>, entonces la hipótesis nula que se desea contrastar es:
</p>
<p><span class="math display">\[H_0 : \mu_1 = \mu_2 = \cdots = \mu_k \quad \text{versus} \quad H_1 : \text{al menos una } \mu_j \text{ difiere.}\]</span></p>
<p>
Bajo el supuesto de normalidad y homogeneidad de varianzas, el estadístico de prueba es:
</p>
<p><span class="math display">\[F = \frac{MSA}{MSE}\]</span></p>
<p>
Este estadístico sigue una distribución <span class="math inline">\(F\)</span> con <span class="math inline">\(\nu_1 = k - 1\)</span> grados de libertad en el numerador y <span class="math inline">\(\nu_2 = N - k\)</span> grados de libertad en el denominador.
La hipótesis nula se rechaza al nivel de significancia <span class="math inline">\(\alpha\)</span> si:
</p>
<p><span class="math display">\[F &gt; F_{\alpha, \nu_1, \nu_2}\]</span></p>
<p>
donde <span class="math inline">\(F_{\alpha, \nu_1, \nu_2}\)</span> representa el valor crítico de la distribución F correspondiente al nivel de significancia <span class="math inline">\(\alpha\)</span>.
</p>
</div>
<p style="text-align: left;">
<strong>Demostración del teorema</strong>
</p>
<p>Basta con usar el teorema de descomposición de la suma de cuadrados y el teorema de MSA y MSE insesgado de <span class="math inline">\(\sigma^2\)</span>. <span class="math inline">\(\quad \square\)</span></p>
<p>Los cálculos necesarios para llevar a cabo este contraste se pueden resumir en una tabla de análisis de varianza de un factor (<a href="estparynopar.html#tab:tabla-anova-3">4.3</a>), como se muestra a continuación:</p>
<table>
<caption><span id="tab:tabla-anova-3">Tabla 4.3: </span>Formato general de la tabla de ANOVA de un factor</caption>
<colgroup>
<col width="27%" />
<col width="18%" />
<col width="19%" />
<col width="20%" />
<col width="14%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Fuente.de.variación</th>
<th align="center">Suma.de.cuadrados</th>
<th align="center">Grados.de.libertad</th>
<th align="center">Cuadrado.medio</th>
<th align="center">Razón.F</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Tratamientos (entre grupos)</td>
<td align="center">SSA</td>
<td align="center">k - 1</td>
<td align="center">MSA = SSA / (k - 1)</td>
<td align="center">F = MSA / MSE</td>
</tr>
<tr class="even">
<td align="left">Error (dentro de grupos)</td>
<td align="center">SSE</td>
<td align="center">N - k</td>
<td align="center">MSE = SSE / (N - k)</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left">Total</td>
<td align="center">SST</td>
<td align="center">N - 1</td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<div class="admon-box ejemplo">
<div class="admon-title">
<span class="icon"></span> Ejemplo
</div>
<p>
La siguiente tabla presenta los porcentajes (en microgramos) de concentración plasmática de una sustancia química en tres grupos poblacionales:
</p>
<ul>
<li>
<strong>Empleados expuestos</strong>: trabajadores que manipulan o están en contacto directo con la sustancia en entornos industriales.
</li>
<li>
<strong>Agricultores expuestos</strong>: población rural en contacto con agroquímicos que contienen el compuesto.
</li>
<li>
<strong>No expuestos</strong>: personas que no presentan exposición conocida al agente químico (grupo control).
</li>
</ul>
<p>
Se desea determinar si existen diferencias estadísticamente significativas en los niveles medios del compuesto entre los tres grupos. Para ello, se aplicará un análisis de varianza de un factor (ANOVA) bajo las siguientes condiciones:
</p>
<ul>
<li>
Las poblaciones son normales.
</li>
<li>
Las varianzas son iguales.
</li>
<li>
El nivel de significancia es <span class="math inline">\(\alpha = 0{.}05\)</span>.
</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="estparynopar.html#cb55-1" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Empleados =</span> <span class="fu">c</span>(<span class="fl">0.66</span>, <span class="fl">0.63</span>, <span class="fl">0.65</span>, <span class="fl">0.69</span>, <span class="fl">0.44</span>, <span class="fl">0.63</span>, <span class="fl">0.61</span>, <span class="fl">0.42</span>, <span class="fl">0.59</span>, <span class="fl">0.46</span>),</span>
<span id="cb55-2"><a href="estparynopar.html#cb55-2" tabindex="-1"></a>                 <span class="at">Agricultores =</span> <span class="fu">c</span>(<span class="fl">0.65</span>, <span class="fl">0.60</span>, <span class="fl">0.69</span>, <span class="fl">0.73</span>, <span class="fl">0.52</span>, <span class="fl">0.85</span>, <span class="fl">0.81</span>, <span class="cn">NA</span>, <span class="cn">NA</span>, <span class="cn">NA</span>),</span>
<span id="cb55-3"><a href="estparynopar.html#cb55-3" tabindex="-1"></a>                 <span class="at">NoExpuestos =</span> <span class="fu">c</span>(<span class="fl">0.93</span>, <span class="fl">0.99</span>, <span class="fl">0.96</span>, <span class="fl">0.74</span>, <span class="fl">0.81</span>, <span class="fl">0.93</span>, <span class="fl">0.63</span>, <span class="fl">0.68</span>, <span class="fl">0.99</span>, <span class="cn">NA</span>))</span></code></pre></div>
</details>
</div>
<p style="text-align: center;">
<strong>Solución</strong>
</p>
<p>Sea <span class="math inline">\(\mu_i\)</span> el valor promedio poblacional de concentración plasmática de la sustancia química para el grupo <span class="math inline">\(i\)</span>, donde:</p>
<ul>
<li><span class="math inline">\(i = 1\)</span>: Empleados expuestos<br />
</li>
<li><span class="math inline">\(i = 2\)</span>: Agricultores expuestos<br />
</li>
<li><span class="math inline">\(i = 3\)</span>: No expuestos</li>
</ul>
<p>El objetivo del análisis es determinar si los valores medios de concentración difieren significativamente entre los tres grupos.</p>
<p>Bajo este contexto, se plantean las siguientes hipótesis estadísticas:</p>
<p><span class="math display">\[
\begin{aligned}
H_0: &amp;\quad \mu_1 = \mu_2 = \mu_3 \quad \text{(todas las medias son iguales)} \ vs \\\\
H_1: &amp;\quad \text{Al menos una media difiere de las demás}
\end{aligned}
\]</span></p>
<p>Bajo la hipótesis nula, se considera que todos los grupos provienen de poblaciones con igual valor medio. Rechazarla implica que existe evidencia estadística de diferencias significativas en al menos uno de los grupos.</p>
<ul>
<li>Quitemos los <code>NA</code>s</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="estparynopar.html#cb56-1" tabindex="-1"></a>empleados <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(df<span class="sc">$</span>Empleados)              </span>
<span id="cb56-2"><a href="estparynopar.html#cb56-2" tabindex="-1"></a>agricultores <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(df<span class="sc">$</span>Agricultores)</span>
<span id="cb56-3"><a href="estparynopar.html#cb56-3" tabindex="-1"></a>no_expuestos <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(df<span class="sc">$</span>NoExpuestos)</span></code></pre></div>
</details>
<ul>
<li>Hallamos los tamaños de cada muestra</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="estparynopar.html#cb57-1" tabindex="-1"></a>n1 <span class="ot">&lt;-</span> <span class="fu">length</span>(empleados)     <span class="co"># tamaño de muestra n_1</span></span>
<span id="cb57-2"><a href="estparynopar.html#cb57-2" tabindex="-1"></a>n2 <span class="ot">&lt;-</span> <span class="fu">length</span>(agricultores)  <span class="co"># tamaño de muestra n_2</span></span>
<span id="cb57-3"><a href="estparynopar.html#cb57-3" tabindex="-1"></a>n3 <span class="ot">&lt;-</span> <span class="fu">length</span>(no_expuestos)  <span class="co"># tamaño de muestra n_3</span></span>
<span id="cb57-4"><a href="estparynopar.html#cb57-4" tabindex="-1"></a>N <span class="ot">&lt;-</span> n1 <span class="sc">+</span> n2 <span class="sc">+</span> n3           <span class="co"># tamaño de muestral total </span></span>
<span id="cb57-5"><a href="estparynopar.html#cb57-5" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="fu">ncol</span>(df)               <span class="co"># número de poblaciones</span></span></code></pre></div>
</details>
<ul>
<li>Hallemos los promedios de cada muestra</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="estparynopar.html#cb58-1" tabindex="-1"></a>xbar_1 <span class="ot">&lt;-</span> <span class="fu">mean</span>(empleados)</span>
<span id="cb58-2"><a href="estparynopar.html#cb58-2" tabindex="-1"></a>xbar_2 <span class="ot">&lt;-</span> <span class="fu">mean</span>(agricultores)</span>
<span id="cb58-3"><a href="estparynopar.html#cb58-3" tabindex="-1"></a>xbar_3 <span class="ot">&lt;-</span> <span class="fu">mean</span>(no_expuestos)</span>
<span id="cb58-4"><a href="estparynopar.html#cb58-4" tabindex="-1"></a></span>
<span id="cb58-5"><a href="estparynopar.html#cb58-5" tabindex="-1"></a>xbar_total <span class="ot">&lt;-</span> (<span class="fu">sum</span>(empleados)<span class="sc">+</span><span class="fu">sum</span>(agricultores)<span class="sc">+</span><span class="fu">sum</span>(no_expuestos))<span class="sc">/</span>N</span></code></pre></div>
</details>
<ul>
<li>Hallemos la suma de cuadrados total (SST)</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="estparynopar.html#cb59-1" tabindex="-1"></a>SST <span class="ot">&lt;-</span> <span class="fu">sum</span>((empleados <span class="sc">-</span> xbar_total)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb59-2"><a href="estparynopar.html#cb59-2" tabindex="-1"></a>       <span class="fu">sum</span>((agricultores <span class="sc">-</span> xbar_total)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb59-3"><a href="estparynopar.html#cb59-3" tabindex="-1"></a>       <span class="fu">sum</span>((no_expuestos <span class="sc">-</span> xbar_total)<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
</details>
<ul>
<li>Hallemos la suma de cuadrados entre grupos (SSA)</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="estparynopar.html#cb60-1" tabindex="-1"></a>SSA <span class="ot">&lt;-</span> n1 <span class="sc">*</span> (xbar_1 <span class="sc">-</span> xbar_total)<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span></span>
<span id="cb60-2"><a href="estparynopar.html#cb60-2" tabindex="-1"></a>       n2 <span class="sc">*</span> (xbar_2 <span class="sc">-</span> xbar_total)<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span></span>
<span id="cb60-3"><a href="estparynopar.html#cb60-3" tabindex="-1"></a>       n3 <span class="sc">*</span> (xbar_3 <span class="sc">-</span> xbar_total)<span class="sc">^</span><span class="dv">2</span></span></code></pre></div>
</details>
<ul>
<li>Ahora, hallemos la suma de cuadrados dentro de grupos (SSE)</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="estparynopar.html#cb61-1" tabindex="-1"></a>SSE <span class="ot">&lt;-</span> SST <span class="sc">-</span> SSA</span></code></pre></div>
</details>
<ul>
<li>Calculemos los cuadrados medios y el estadístico de Fisher</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="estparynopar.html#cb62-1" tabindex="-1"></a>MSA <span class="ot">&lt;-</span> SSA <span class="sc">/</span> (k <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb62-2"><a href="estparynopar.html#cb62-2" tabindex="-1"></a>MSE <span class="ot">&lt;-</span> SSE <span class="sc">/</span> (N <span class="sc">-</span> k)</span>
<span id="cb62-3"><a href="estparynopar.html#cb62-3" tabindex="-1"></a></span>
<span id="cb62-4"><a href="estparynopar.html#cb62-4" tabindex="-1"></a>F <span class="ot">&lt;-</span> MSA <span class="sc">/</span> MSE</span></code></pre></div>
</details>
<ul>
<li>Hallemos el <span class="math inline">\(F\)</span> critico y veamos si rechazo o no la hipotesis nula</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="estparynopar.html#cb63-1" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb63-2"><a href="estparynopar.html#cb63-2" tabindex="-1"></a>v1 <span class="ot">&lt;-</span> k<span class="dv">-1</span></span>
<span id="cb63-3"><a href="estparynopar.html#cb63-3" tabindex="-1"></a>v2 <span class="ot">&lt;-</span> N<span class="sc">-</span>k</span>
<span id="cb63-4"><a href="estparynopar.html#cb63-4" tabindex="-1"></a></span>
<span id="cb63-5"><a href="estparynopar.html#cb63-5" tabindex="-1"></a>F_critico <span class="ot">&lt;-</span> <span class="fu">qf</span>(<span class="at">p =</span> <span class="dv">1</span><span class="sc">-</span>alpha, <span class="at">df1 =</span> v1, <span class="at">df2 =</span> v2)</span>
<span id="cb63-6"><a href="estparynopar.html#cb63-6" tabindex="-1"></a></span>
<span id="cb63-7"><a href="estparynopar.html#cb63-7" tabindex="-1"></a>decision <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(F <span class="sc">&gt;</span> F_critico, <span class="st">&quot;Se rechaza H_0&quot;</span>, <span class="st">&quot;No se rechaza H_0&quot;</span>)</span>
<span id="cb63-8"><a href="estparynopar.html#cb63-8" tabindex="-1"></a></span>
<span id="cb63-9"><a href="estparynopar.html#cb63-9" tabindex="-1"></a><span class="fu">print</span>(decision)</span></code></pre></div>
</details>
<pre><code>## [1] &quot;Se rechaza H_0&quot;</code></pre>
<ul>
<li>Otra forma de realizarlo es:</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="estparynopar.html#cb65-1" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb65-2"><a href="estparynopar.html#cb65-2" tabindex="-1"></a>v1 <span class="ot">&lt;-</span> k<span class="dv">-1</span></span>
<span id="cb65-3"><a href="estparynopar.html#cb65-3" tabindex="-1"></a>v2 <span class="ot">&lt;-</span> N<span class="sc">-</span>k</span>
<span id="cb65-4"><a href="estparynopar.html#cb65-4" tabindex="-1"></a></span>
<span id="cb65-5"><a href="estparynopar.html#cb65-5" tabindex="-1"></a>pvalor <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pf</span>(F, v1, v2)</span>
<span id="cb65-6"><a href="estparynopar.html#cb65-6" tabindex="-1"></a>decision <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(pvalor <span class="sc">&lt;</span> alpha, <span class="st">&quot;Se rechaza H_0&quot;</span>, <span class="st">&quot;No se rechaza H_0&quot;</span>)</span>
<span id="cb65-7"><a href="estparynopar.html#cb65-7" tabindex="-1"></a></span>
<span id="cb65-8"><a href="estparynopar.html#cb65-8" tabindex="-1"></a><span class="fu">print</span>(decision)</span></code></pre></div>
</details>
<pre><code>## [1] &quot;Se rechaza H_0&quot;</code></pre>
<p>Esto indica que <strong>existen diferencias estadísticamente significativas en los niveles medios de concentración plasmática</strong> del compuesto químico entre al menos dos de los grupos: empleados expuestos, agricultores expuestos y personas no expuestas. Este resultado sugiere que el grado de exposición al compuesto químico podría estar influyendo en los niveles plasmáticos observados, por lo cual se recomienda realizar un análisis post hoc (como la prueba de Tukey) para identificar con mayor precisión cuáles pares de grupos difieren significativamente entre sí.</p>
<div class="admon-box ejemplo">
<div class="admon-title">
<span class="icon"></span> Ejemplo
</div>
<p>
Una institución educativa implementó tres estrategias diferentes de enseñanza para evaluar su impacto en el rendimiento académico de los estudiantes. Cada estrategia fue aplicada a un grupo distinto de alumnos, identificados como <strong>Grupo A</strong>, <strong>Grupo B</strong> y <strong>Grupo C</strong>.
</p>
<p>
Al finalizar el periodo académico, se aplicó una prueba estandarizada común a todos los estudiantes, y se registraron las calificaciones obtenidas sobre una escala de 0 a 100 puntos. Los datos de las calificaciones por grupo se presentan a continuación.
</p>
<p>
El objetivo del análisis es determinar, mediante un <strong>análisis de varianza de un factor (ANOVA)</strong>, si existen <strong>diferencias estadísticamente significativas en los promedios de calificaciones</strong> entre los tres grupos de estudiantes, lo que permitiría identificar si alguna estrategia resulta más efectiva que las otras.
</p>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="estparynopar.html#cb67-1" tabindex="-1"></a><span class="co"># Datos de calificaciones por grupo de enseñanza</span></span>
<span id="cb67-2"><a href="estparynopar.html#cb67-2" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb67-3"><a href="estparynopar.html#cb67-3" tabindex="-1"></a>  <span class="at">Grupo =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>), <span class="at">each =</span> <span class="dv">10</span>),</span>
<span id="cb67-4"><a href="estparynopar.html#cb67-4" tabindex="-1"></a>  <span class="at">Calificaciones =</span> <span class="fu">c</span>(<span class="dv">75</span>, <span class="dv">78</span>, <span class="dv">80</span>, <span class="dv">82</span>, <span class="dv">85</span>, <span class="dv">88</span>, <span class="dv">90</span>, <span class="dv">92</span>, <span class="dv">95</span>, <span class="dv">98</span>,   <span class="co"># Grupo A</span></span>
<span id="cb67-5"><a href="estparynopar.html#cb67-5" tabindex="-1"></a>                     <span class="dv">68</span>, <span class="dv">70</span>, <span class="dv">72</span>, <span class="dv">74</span>, <span class="dv">76</span>, <span class="dv">78</span>, <span class="dv">80</span>, <span class="dv">82</span>, <span class="dv">84</span>, <span class="dv">86</span>,   <span class="co"># Grupo B</span></span>
<span id="cb67-6"><a href="estparynopar.html#cb67-6" tabindex="-1"></a>                     <span class="dv">60</span>, <span class="dv">63</span>, <span class="dv">66</span>, <span class="dv">69</span>, <span class="dv">72</span>, <span class="dv">75</span>, <span class="dv">78</span>, <span class="dv">81</span>, <span class="dv">84</span>, <span class="dv">87</span>)   <span class="co"># Grupo C</span></span>
<span id="cb67-7"><a href="estparynopar.html#cb67-7" tabindex="-1"></a>)</span></code></pre></div>
</details>
</div>
<p style="text-align: center;">
<strong>Solución</strong>
</p>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio
</div>
<p>
Realiza el análisis exploratorio del conjunto de datos
</p>
</div>
<ul>
<li>Verifiquemos la prueba de normalidad</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="estparynopar.html#cb68-1" tabindex="-1"></a>datos <span class="sc">%&gt;%</span></span>
<span id="cb68-2"><a href="estparynopar.html#cb68-2" tabindex="-1"></a>  <span class="fu">group_by</span>(Grupo) <span class="sc">%&gt;%</span></span>
<span id="cb68-3"><a href="estparynopar.html#cb68-3" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">estadistico =</span> <span class="fu">shapiro.test</span>(Calificaciones)<span class="sc">$</span>statistic,</span>
<span id="cb68-4"><a href="estparynopar.html#cb68-4" tabindex="-1"></a>    <span class="at">p_valor =</span> <span class="fu">shapiro.test</span>(Calificaciones)<span class="sc">$</span>p.value)</span></code></pre></div>
</details>
<pre><code>## # A tibble: 3 × 3
##   Grupo estadistico p_valor
##   &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;
## 1 A           0.974   0.924
## 2 B           0.970   0.892
## 3 C           0.970   0.892</code></pre>
<p>La prueba de Shapiro-Will muestra que hay no hay diferencias estadísticamente significativas con respecto a la normalidad de cada grupo.</p>
<ul>
<li>Probemos homogeneidad de varianzas</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="estparynopar.html#cb70-1" tabindex="-1"></a><span class="fu">bartlett.test</span>(Calificaciones <span class="sc">~</span> <span class="fu">factor</span>(Grupo), <span class="at">data =</span> datos)</span></code></pre></div>
</details>
<pre><code>## 
##  Bartlett test of homogeneity of variances
## 
## data:  Calificaciones by factor(Grupo)
## Bartlett&#39;s K-squared = 1.3763, df = 2, p-value = 0.5025</code></pre>
<p>La prueba de homogeneidad de varianzas de Bartlett nos indica que no diferencias significativas en la igualdad de varianzas entre los grupos.</p>
<ul>
<li>Ahora, apliquemos el ANOVA</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="estparynopar.html#cb72-1" tabindex="-1"></a>modelo <span class="ot">&lt;-</span> <span class="fu">aov</span>(Calificaciones <span class="sc">~</span> Grupo, <span class="at">data =</span> datos)</span>
<span id="cb72-2"><a href="estparynopar.html#cb72-2" tabindex="-1"></a><span class="fu">summary</span>(modelo)</span></code></pre></div>
</details>
<pre><code>##             Df Sum Sq Mean Sq F value  Pr(&gt;F)   
## Grupo        2  875.3   437.6   7.429 0.00269 **
## Residuals   27 1590.6    58.9                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>La prueba de ANOVA nos muestra que strong&gt;existen diferencias significativas</strong> entre los promedios de calificaciones de al menos uno de los tres grupos.</p>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio 1
</div>
<p>
La siguiente es una parte de la tabla de análisis de varianza (ANOVA):
</p>
<table>
<thead>
<tr>
<th>
Fuente de variación
</th>
<th>
Suma de cuadrados
</th>
<th>
Grados de libertad
</th>
<th>
Cuadrado medio
</th>
<th>
Razón F
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Tratamientos
</td>
<td>
SSA
</td>
<td>
k − 1 = 2
</td>
<td>
MSA
</td>
<td>
F = MSA / MSE
</td>
</tr>
<tr>
<td>
Error
</td>
<td>
SSE
</td>
<td>
N − k
</td>
<td>
MSE = 20
</td>
<td>
</td>
</tr>
<tr>
<td>
Total
</td>
<td>
SST = 500
</td>
<td>
N − 1 = 11
</td>
<td>
</td>
<td>
</td>
</tr>
</tbody>
</table>
<p>
Complete el cuadro y responda:
</p>
<ol type="a">
<li>
¿Cuántos tratamientos hay?
</li>
<li>
¿Cuál es el tamaño total de la muestra?
</li>
<li>
¿Cuáles son las hipótesis nula y alternativa?
</li>
<li>
¿Cuál es su conclusión con respecto a la hipótesis nula?
</li>
</ol>
</div>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio 2
</div>
<p>
De cada una de cuatro poblaciones se tomó una muestra aleatoria de 16 observaciones. Parte de la tabla ANOVA es:
</p>
<table>
<thead>
<tr>
<th>
Fuente de variación
</th>
<th>
Suma de cuadrados
</th>
<th>
Grados de libertad
</th>
<th>
Cuadrado medio
</th>
<th>
Razón F
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Tratamientos
</td>
<td>
SSA
</td>
<td>
k − 1
</td>
<td>
MSA = 400
</td>
<td>
F = MSA / MSE
</td>
</tr>
<tr>
<td>
Error
</td>
<td>
SSE
</td>
<td>
N − k
</td>
<td>
MSE
</td>
<td>
</td>
</tr>
<tr>
<td>
Total
</td>
<td>
SST = 1500
</td>
<td>
N − 1
</td>
<td>
</td>
<td>
</td>
</tr>
</tbody>
</table>
<p>
Suponga que las poblaciones en cuestión son normales con varianzas iguales. Al nivel de significancia <span class="math inline">\(\alpha = 0.05\)</span>, ¿se puede rechazar la hipótesis nula de que las medias de las cuatro poblaciones son iguales?
</p>
</div>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio 3
</div>
<p>
En un experimento para investigar el funcionamiento de cuatro marcas diferentes de procesadores para computador, se probaron cinco procesadores de cada marca y se observó el tiempo de funcionamiento hasta presentarse una falla. Parte de la tabla ANOVA es:
</p>
<table>
<thead>
<tr>
<th>
Fuente de variación
</th>
<th>
Suma de cuadrados
</th>
<th>
Grados de libertad
</th>
<th>
Cuadrado medio
</th>
<th>
Razón F
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Marca
</td>
<td>
?
</td>
<td>
?
</td>
<td>
?
</td>
<td>
?
</td>
</tr>
<tr>
<td>
Error
</td>
<td>
?
</td>
<td>
?
</td>
<td>
14713.69
</td>
<td>
</td>
</tr>
<tr>
<td>
Total
</td>
<td>
310500.76
</td>
<td>
?
</td>
<td>
</td>
<td>
</td>
</tr>
</tbody>
</table>
<p>
Complete la tabla, formule las hipótesis correspondientes, y determine si hay evidencia suficiente para rechazar la hipótesis nula. También obtenga el valor-p asociado.
</p>
</div>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio 4
</div>
<p>
La siguiente tabla muestra la duración (en días) de la carga para cuatro marcas diferentes de baterías, registradas a partir de cinco observaciones por marca:
</p>
<table>
<thead>
<tr>
<th>
Batería A
</th>
<th>
Batería B
</th>
<th>
Batería C
</th>
<th>
Batería D
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
82
</td>
<td>
55
</td>
<td>
69
</td>
<td>
87
</td>
</tr>
<tr>
<td>
79
</td>
<td>
67
</td>
<td>
72
</td>
<td>
61
</td>
</tr>
<tr>
<td>
75
</td>
<td>
84
</td>
<td>
78
</td>
<td>
82
</td>
</tr>
<tr>
<td>
68
</td>
<td>
77
</td>
<td>
83
</td>
<td>
61
</td>
</tr>
<tr>
<td>
65
</td>
<td>
71
</td>
<td>
74
</td>
<td>
72
</td>
</tr>
</tbody>
</table>
<p>
Utilice un nivel de significancia <span class="math inline">\(\alpha = 0{,}05\)</span> para determinar si existen diferencias significativas en la duración media de las cargas entre las cuatro marcas de baterías.
</p>
<p>
Suponga que las poblaciones en cuestión son normales y con varianzas iguales.
</p>
</div>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio 5
</div>
<p>
Se realizó un estudio para conocer cuánto tiempo, en minutos, tardan los estudiantes de octavo grado de tres escuelas diferentes en terminar un ejercicio específico de álgebra. De cada una de las escuelas se seleccionaron al azar siete estudiantes. Los resultados obtenidos fueron los siguientes:
</p>
<table>
<thead>
<tr>
<th>
Escuela A
</th>
<th>
Escuela B
</th>
<th>
Escuela C
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
17
</td>
<td>
24
</td>
<td>
25
</td>
</tr>
<tr>
<td>
21
</td>
<td>
18
</td>
<td>
24
</td>
</tr>
<tr>
<td>
25
</td>
<td>
19
</td>
<td>
25
</td>
</tr>
<tr>
<td>
16
</td>
<td>
22
</td>
<td>
21
</td>
</tr>
<tr>
<td>
19
</td>
<td>
23
</td>
<td>
24
</td>
</tr>
<tr>
<td>
22
</td>
<td>
20
</td>
<td>
28
</td>
</tr>
<tr>
<td>
18
</td>
<td>
21
</td>
<td>
19
</td>
</tr>
</tbody>
</table>
<p>
Utilice un nivel de significancia <span class="math inline">\(\alpha = 0{,}01\)</span> para determinar si existe diferencia significativa en los promedios de tiempo que tardan los estudiantes de las tres escuelas en resolver el ejercicio.
</p>
<p>
Suponga que las poblaciones son normales y tienen varianzas iguales.
</p>
</div>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio 6
</div>
<p>
Se analizaron seis muestras de docentes de cada una de las cuatro universidades privadas que hay en cierta ciudad, con el fin de realizar un estudio sobre el <strong>incremento porcentual salarial</strong> de los docentes en dichas instituciones. Los datos recolectados fueron los siguientes:
</p>
<table>
<thead>
<tr>
<th>
Universidad 1
</th>
<th>
Universidad 2
</th>
<th>
Universidad 3
</th>
<th>
Universidad 4
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
6.0
</td>
<td>
6.1
</td>
<td>
6.4
</td>
<td>
7.8
</td>
</tr>
<tr>
<td>
6.1
</td>
<td>
7.5
</td>
<td>
4.9
</td>
<td>
7.0
</td>
</tr>
<tr>
<td>
6.7
</td>
<td>
5.9
</td>
<td>
6.0
</td>
<td>
5.5
</td>
</tr>
<tr>
<td>
5.8
</td>
<td>
5.6
</td>
<td>
5.2
</td>
<td>
7.2
</td>
</tr>
<tr>
<td>
5.2
</td>
<td>
6.5
</td>
<td>
5.8
</td>
<td>
8.3
</td>
</tr>
<tr>
<td>
4.5
</td>
<td>
8.0
</td>
<td>
4.7
</td>
<td>
6.1
</td>
</tr>
</tbody>
</table>
<p>
¿Sugiere esta información que al menos dos universidades difieren en su promedio de incremento porcentual salarial docente?
</p>
<p>
Utilice una prueba de ANOVA con nivel de significancia <span class="math inline">\(\alpha = 0{,}05\)</span>, basada en el <em>p-valor</em>, y suponga que las poblaciones en cuestión son normales con varianzas iguales.
</p>
</div>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio 7
</div>
<p>
En un diseño completamente aleatorizado, se aplicaron cinco niveles distintos de un factor. Para cada uno de estos niveles se usaron siete unidades experimentales. La tabla parcial del análisis de varianza (ANOVA) es la siguiente:
</p>
<table>
<thead>
<tr>
<th>
Fuente de variación
</th>
<th>
Suma de cuadrados
</th>
<th>
Grados de libertad
</th>
<th>
Cuadrado medio
</th>
<th>
F
</th>
<th>
Valor-p
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Tratamientos
</td>
<td>
300
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
Error
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
Total
</td>
<td>
460
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
</tbody>
</table>
<ol type="a">
<li>
¿Cuáles son las hipótesis en este problema?
</li>
<li>
Utilice un nivel de significancia <span class="math inline">\(\alpha = 0{,}05\)</span>. ¿Se puede rechazar la hipótesis nula del inciso a)? Justifique su respuesta utilizando el valor del estadístico F y el p-valor correspondiente.
</li>
</ol>
</div>
</div>
<div id="comparaciones-múltiples" class="section level3 hasAnchor" number="4.5.5">
<h3><span class="header-section-number">4.5.5</span> Comparaciones múltiples<a href="#comparaciones-m%C3%BAltiples" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Aunque en un análisis de varianza se pueda rechazar la <strong>hipótesis nula</strong>, que establece que todas las medias poblacionales son iguales, en favor de la alternativa, que indica que <strong>al menos una media difiere</strong>, este resultado no permite identificar cuáles medias son diferentes ni entre qué grupos se presentan dichas diferencias.</p>
<p>Por tanto, una vez detectada una diferencia significativa en el análisis global, es necesario aplicar una estrategia adicional que permita estudiar con mayor detalle las relaciones entre grupos y precisar cuáles presentan diferencias relevantes en sus medias.</p>
<div class="admon-box teorema">
<div class="admon-title">
<span class="icon"></span> Teorema. CME y CMGE
</div>
<p>
Si se define el cuadrado medio del error, <strong>CME</strong>, por:
</p>
<p><span class="math display">\[CME = \frac{\sum_{j=1}^{k} (n_j - 1) s_j^2}{N - k}\]</span></p>
<p>
y la media geométrica ponderada de las <span class="math inline">\(s_j^2\)</span>, denotada por <strong>CMGE</strong>, por:
</p>
<p><span class="math display">\[CMGE = \left[ (s_1^2)^{n_1 - 1} \cdot (s_2^2)^{n_2 - 1} \cdots (s_k^2)^{n_k - 1} \right]^{1 / (N - k)}, \]</span></p>
<p>
entonces se cumple que:
</p>
<p><span class="math display">\[CMGE \leq CME\]</span></p>
</div>
<div id="método-t-de-tukey-o-método-hsd" class="section level4 hasAnchor" number="4.5.5.1">
<h4><span class="header-section-number">4.5.5.1</span> Método T de Tukey (o método HSD)<a href="#m%C3%A9todo-t-de-tukey-o-m%C3%A9todo-hsd" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>El método de Tukey para comparaciones múltiples se aplica cuando se requiere comparar todos los pares posibles de medias <span class="math inline">\(\mu_i\)</span> y <span class="math inline">\(\mu_j\)</span>, con <span class="math inline">\(i \neq j\)</span>, de todas las poblaciones.</p>
<p>Cuando todos los tamaños muestrales son iguales, el coeficiente de confianza del método de Tukey es exactamente <span class="math inline">\(1 - \alpha\)</span>. Cuando los tamaños muestrales son diferentes, el método sigue siendo válido, aunque se vuelve más conservador, proporcionando estimaciones más prudentes.</p>
<p>Este método utiliza como estadístico el <strong>rango studentizado</strong> <span class="math inline">\(q\)</span>, definido como:</p>
<p><span class="math display">\[q := \frac{\max \bar{Y}_j - \min \bar{Y}_j}{\sqrt{CME / N}}\]</span></p>
<p>donde <span class="math inline">\(CME\)</span> es el cuadrado medio del error y <span class="math inline">\(N\)</span> es el número de observaciones por grupo.</p>
<p>Para determinar si dos medias <span class="math inline">\(\bar{Y}_i\)</span> y <span class="math inline">\(\bar{Y}_j\)</span> difieren significativamente, se utiliza el valor HSD (“honestamente significativa diferencia”), definido de las siguientes formas:</p>
<ul>
<li>Cuando los tamaños muestrales son desiguales:</li>
</ul>
<p><span class="math display">\[HSD = q_{\alpha}(k, N - k) \cdot \sqrt{CME \left( \frac{1}{n_i} + \frac{1}{n_j} \right)}\]</span></p>
<ul>
<li>Cuando los tamaños muestrales son iguales:</li>
</ul>
<p><span class="math display">\[HSD = q_{\alpha}(k, N - k) \cdot \sqrt{\frac{k \cdot CME}{N}}\]</span></p>
<p>donde <span class="math inline">\(q_{\alpha}(k, N-k)\)</span> es el valor crítico de la distribución del rango studentizado para los parámetros <span class="math inline">\(k\)</span> y <span class="math inline">\(N-k\)</span>, que se obtiene de una tabla para los niveles de significancia <span class="math inline">\(\alpha = 0.05\)</span> o <span class="math inline">\(0.01\)</span>.</p>
<p>El intervalo de confianza para la diferencia entre dos medias <span class="math inline">\(\mu_i - \mu_j\)</span> con nivel de confianza <span class="math inline">\(1 - \alpha\)</span> está dado por:</p>
<p><span class="math display">\[\bar{Y}_i - \bar{Y}_j \pm HSD.\]</span></p>
<div class="admon-box ejemplo">
<div class="admon-title">
<span class="icon"></span> Ejemplo
</div>
<p>
En un estudio experimental se comparan seis tratamientos diferentes aplicados a una misma población con el fin de analizar su efecto sobre una variable cuantitativa de interés. Se ha diseñado un experimento completamente aleatorizado, con cinco observaciones independientes para cada tratamiento.
</p>
<p>
Luego de aplicar un análisis de varianza (ANOVA), se obtuvo un valor del <strong>cuadrado medio del error</strong> igual a <strong>CME = 2,45</strong> con <strong>24 grados de libertad</strong>. A partir de este resultado, se desea realizar un análisis <strong>post hoc</strong> para identificar cuáles tratamientos presentan diferencias estadísticamente significativas en sus medias.
</p>
<p>
Para ello, se utilizará el <strong>método de Tukey</strong> para comparaciones múltiples por pares, con un nivel de significancia <span class="math inline">\(\alpha = 0{,}05\)</span>, considerando los siguientes promedios muestrales ordenados en forma creciente:
</p>
<p><span class="math display">\[
  \bar{y}_2 = 14{,}50, \quad \bar{y}_5 = 16{,}75, \quad \bar{y}_1 = 19{,}84, \quad \bar{y}_3 = 21{,}12, \quad \bar{y}_6 = 22{,}90, \quad \bar{y}_4 = 23{,}20
  \]</span></p>
<p>
El objetivo es determinar qué pares de tratamientos presentan diferencias significativas, utilizando el estadístico de Tukey y el umbral HSD correspondiente.
</p>
</div>
<p style="text-align: center;">
<strong>Solución</strong>
</p>
<ul>
<li>Tenemos los siguientes datos</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="estparynopar.html#cb74-1" tabindex="-1"></a>medias <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">14.50</span>, <span class="fl">16.75</span>, <span class="fl">19.84</span>, <span class="fl">21.12</span>, <span class="fl">22.90</span>, <span class="fl">23.20</span>)</span>
<span id="cb74-2"><a href="estparynopar.html#cb74-2" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb74-3"><a href="estparynopar.html#cb74-3" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">6</span></span>
<span id="cb74-4"><a href="estparynopar.html#cb74-4" tabindex="-1"></a>CME <span class="ot">&lt;-</span> <span class="fl">2.45</span></span>
<span id="cb74-5"><a href="estparynopar.html#cb74-5" tabindex="-1"></a>gl_error <span class="ot">&lt;-</span> <span class="dv">24</span></span>
<span id="cb74-6"><a href="estparynopar.html#cb74-6" tabindex="-1"></a></span>
<span id="cb74-7"><a href="estparynopar.html#cb74-7" tabindex="-1"></a><span class="co">#nivel de significancia</span></span>
<span id="cb74-8"><a href="estparynopar.html#cb74-8" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb74-9"><a href="estparynopar.html#cb74-9" tabindex="-1"></a>q <span class="ot">&lt;-</span> <span class="fu">qtukey</span>(<span class="at">p =</span> <span class="dv">1</span><span class="sc">-</span>alpha, <span class="at">nmeans =</span> k, <span class="at">df =</span> gl_error)</span></code></pre></div>
</details>
<p>Por lo tanto, las diferencias absolutas se comparan</p>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="estparynopar.html#cb75-1" tabindex="-1"></a>HSD <span class="ot">&lt;-</span> q <span class="sc">*</span> <span class="fu">sqrt</span>(CME <span class="sc">/</span> n)</span>
<span id="cb75-2"><a href="estparynopar.html#cb75-2" tabindex="-1"></a>HSD  </span></code></pre></div>
</details>
<pre><code>## [1] 3.060856</code></pre>
<p>Como resultado, las siguientes representan las medias encontradas que son significativamente
diferentes con el método de Tukey:</p>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="estparynopar.html#cb77-1" tabindex="-1"></a><span class="co"># Etiquetas de tratamientos (siguiendo orden de las medias)</span></span>
<span id="cb77-2"><a href="estparynopar.html#cb77-2" tabindex="-1"></a>tratamientos <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Y2&quot;</span>, <span class="st">&quot;Y5&quot;</span>, <span class="st">&quot;Y1&quot;</span>, <span class="st">&quot;Y3&quot;</span>, <span class="st">&quot;Y6&quot;</span>, <span class="st">&quot;Y4&quot;</span>)</span>
<span id="cb77-3"><a href="estparynopar.html#cb77-3" tabindex="-1"></a></span>
<span id="cb77-4"><a href="estparynopar.html#cb77-4" tabindex="-1"></a><span class="co"># Matriz de comparaciones por pares</span></span>
<span id="cb77-5"><a href="estparynopar.html#cb77-5" tabindex="-1"></a>comparaciones <span class="ot">&lt;-</span> <span class="fu">combn</span>(<span class="dv">1</span><span class="sc">:</span>k, <span class="dv">2</span>, <span class="cf">function</span>(idx) {</span>
<span id="cb77-6"><a href="estparynopar.html#cb77-6" tabindex="-1"></a>  i <span class="ot">&lt;-</span> idx[<span class="dv">1</span>]</span>
<span id="cb77-7"><a href="estparynopar.html#cb77-7" tabindex="-1"></a>  j <span class="ot">&lt;-</span> idx[<span class="dv">2</span>]</span>
<span id="cb77-8"><a href="estparynopar.html#cb77-8" tabindex="-1"></a>  dif <span class="ot">&lt;-</span> <span class="fu">abs</span>(medias[i] <span class="sc">-</span> medias[j])</span>
<span id="cb77-9"><a href="estparynopar.html#cb77-9" tabindex="-1"></a>  <span class="fu">c</span>(<span class="at">Tratamiento_1 =</span> tratamientos[i],</span>
<span id="cb77-10"><a href="estparynopar.html#cb77-10" tabindex="-1"></a>    <span class="at">Tratamiento_2 =</span> tratamientos[j],</span>
<span id="cb77-11"><a href="estparynopar.html#cb77-11" tabindex="-1"></a>    <span class="at">Diferencia =</span> <span class="fu">round</span>(dif, <span class="dv">3</span>),</span>
<span id="cb77-12"><a href="estparynopar.html#cb77-12" tabindex="-1"></a>    <span class="at">Diferentes =</span> <span class="fu">ifelse</span>(dif <span class="sc">&gt;</span> HSD, <span class="st">&quot;Sí&quot;</span>, <span class="st">&quot;No&quot;</span>))</span>
<span id="cb77-13"><a href="estparynopar.html#cb77-13" tabindex="-1"></a>})</span>
<span id="cb77-14"><a href="estparynopar.html#cb77-14" tabindex="-1"></a></span>
<span id="cb77-15"><a href="estparynopar.html#cb77-15" tabindex="-1"></a><span class="co"># Convertir a tabla</span></span>
<span id="cb77-16"><a href="estparynopar.html#cb77-16" tabindex="-1"></a>comparacion_tukey <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">t</span>(comparaciones), <span class="at">stringsAsFactors =</span> <span class="cn">FALSE</span>)</span>
<span id="cb77-17"><a href="estparynopar.html#cb77-17" tabindex="-1"></a><span class="fu">names</span>(comparacion_tukey) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Grupo 1&quot;</span>, <span class="st">&quot;Grupo 2&quot;</span>, <span class="st">&quot;Diferencia&quot;</span>, <span class="st">&quot;¿Significativa?&quot;</span>)</span>
<span id="cb77-18"><a href="estparynopar.html#cb77-18" tabindex="-1"></a></span>
<span id="cb77-19"><a href="estparynopar.html#cb77-19" tabindex="-1"></a><span class="co"># Mostrar resultados</span></span>
<span id="cb77-20"><a href="estparynopar.html#cb77-20" tabindex="-1"></a>comparacion_tukey</span></code></pre></div>
</details>
<pre><code>##    Grupo 1 Grupo 2 Diferencia ¿Significativa?
## 1       Y2      Y5       2.25              No
## 2       Y2      Y1       5.34              Sí
## 3       Y2      Y3       6.62              Sí
## 4       Y2      Y6        8.4              Sí
## 5       Y2      Y4        8.7              Sí
## 6       Y5      Y1       3.09              Sí
## 7       Y5      Y3       4.37              Sí
## 8       Y5      Y6       6.15              Sí
## 9       Y5      Y4       6.45              Sí
## 10      Y1      Y3       1.28              No
## 11      Y1      Y6       3.06              No
## 12      Y1      Y4       3.36              Sí
## 13      Y3      Y6       1.78              No
## 14      Y3      Y4       2.08              No
## 15      Y6      Y4        0.3              No</code></pre>
<p>La función <code>TukeyHSD()</code> del paquete <code>stats</code> nos muestra los grupos diferentes. Para ello usemos los datos de porcentajes (en microgramos) de concentración plasmática de una sustancia química</p>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="estparynopar.html#cb79-1" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Empleados =</span> <span class="fu">c</span>(<span class="fl">0.66</span>, <span class="fl">0.63</span>, <span class="fl">0.65</span>, <span class="fl">0.69</span>, <span class="fl">0.44</span>, <span class="fl">0.63</span>, <span class="fl">0.61</span>, <span class="fl">0.42</span>, <span class="fl">0.59</span>, <span class="fl">0.46</span>),</span>
<span id="cb79-2"><a href="estparynopar.html#cb79-2" tabindex="-1"></a>                 <span class="at">Agricultores =</span> <span class="fu">c</span>(<span class="fl">0.65</span>, <span class="fl">0.60</span>, <span class="fl">0.69</span>, <span class="fl">0.73</span>, <span class="fl">0.52</span>, <span class="fl">0.85</span>, <span class="fl">0.81</span>, <span class="cn">NA</span>, <span class="cn">NA</span>, <span class="cn">NA</span>),</span>
<span id="cb79-3"><a href="estparynopar.html#cb79-3" tabindex="-1"></a>                 <span class="at">NoExpuestos =</span> <span class="fu">c</span>(<span class="fl">0.93</span>, <span class="fl">0.99</span>, <span class="fl">0.96</span>, <span class="fl">0.74</span>, <span class="fl">0.81</span>, <span class="fl">0.93</span>, <span class="fl">0.63</span>, <span class="fl">0.68</span>, <span class="fl">0.99</span>, <span class="cn">NA</span>))</span></code></pre></div>
</details>
<p>Organicemos los datos</p>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="estparynopar.html#cb80-1" tabindex="-1"></a><span class="co"># Reorganicemos al formato largo</span></span>
<span id="cb80-2"><a href="estparynopar.html#cb80-2" tabindex="-1"></a>df_largo <span class="ot">&lt;-</span> tidyr<span class="sc">::</span><span class="fu">pivot_longer</span>(</span>
<span id="cb80-3"><a href="estparynopar.html#cb80-3" tabindex="-1"></a>  df,</span>
<span id="cb80-4"><a href="estparynopar.html#cb80-4" tabindex="-1"></a>  <span class="at">cols =</span> <span class="fu">everything</span>(),</span>
<span id="cb80-5"><a href="estparynopar.html#cb80-5" tabindex="-1"></a>  <span class="at">names_to =</span> <span class="st">&quot;Grupo&quot;</span>,</span>
<span id="cb80-6"><a href="estparynopar.html#cb80-6" tabindex="-1"></a>  <span class="at">values_to =</span> <span class="st">&quot;Concentracion&quot;</span></span>
<span id="cb80-7"><a href="estparynopar.html#cb80-7" tabindex="-1"></a>)</span>
<span id="cb80-8"><a href="estparynopar.html#cb80-8" tabindex="-1"></a></span>
<span id="cb80-9"><a href="estparynopar.html#cb80-9" tabindex="-1"></a><span class="co"># Eliminemos los NA</span></span>
<span id="cb80-10"><a href="estparynopar.html#cb80-10" tabindex="-1"></a>df_largo <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(df_largo)</span>
<span id="cb80-11"><a href="estparynopar.html#cb80-11" tabindex="-1"></a></span>
<span id="cb80-12"><a href="estparynopar.html#cb80-12" tabindex="-1"></a><span class="co"># Verifiquemos</span></span>
<span id="cb80-13"><a href="estparynopar.html#cb80-13" tabindex="-1"></a><span class="fu">head</span>(df_largo)</span></code></pre></div>
</details>
<pre><code>## # A tibble: 6 × 2
##   Grupo        Concentracion
##   &lt;chr&gt;                &lt;dbl&gt;
## 1 Empleados             0.66
## 2 Agricultores          0.65
## 3 NoExpuestos           0.93
## 4 Empleados             0.63
## 5 Agricultores          0.6 
## 6 NoExpuestos           0.99</code></pre>
<p>Apliquemos el ANOVA y la prueba Tukey</p>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="estparynopar.html#cb82-1" tabindex="-1"></a><span class="co"># Modelo ANOVA</span></span>
<span id="cb82-2"><a href="estparynopar.html#cb82-2" tabindex="-1"></a>modelo <span class="ot">&lt;-</span> <span class="fu">aov</span>(Concentracion <span class="sc">~</span> Grupo, <span class="at">data =</span> df_largo)</span>
<span id="cb82-3"><a href="estparynopar.html#cb82-3" tabindex="-1"></a></span>
<span id="cb82-4"><a href="estparynopar.html#cb82-4" tabindex="-1"></a><span class="co"># Resumen del ANOVA</span></span>
<span id="cb82-5"><a href="estparynopar.html#cb82-5" tabindex="-1"></a><span class="fu">summary</span>(modelo)</span></code></pre></div>
</details>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## Grupo        2 0.3544  0.1772   12.57 0.000205 ***
## Residuals   23 0.3242  0.0141                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="estparynopar.html#cb84-1" tabindex="-1"></a><span class="co"># Prueba de comparaciones múltiples de Tukey</span></span>
<span id="cb84-2"><a href="estparynopar.html#cb84-2" tabindex="-1"></a>resultado_tukey <span class="ot">&lt;-</span> <span class="fu">TukeyHSD</span>(modelo)</span>
<span id="cb84-3"><a href="estparynopar.html#cb84-3" tabindex="-1"></a></span>
<span id="cb84-4"><a href="estparynopar.html#cb84-4" tabindex="-1"></a><span class="co"># Mostremos resultados</span></span>
<span id="cb84-5"><a href="estparynopar.html#cb84-5" tabindex="-1"></a>resultado_tukey</span></code></pre></div>
</details>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = Concentracion ~ Grupo, data = df_largo)
## 
## $Grupo
##                                diff         lwr        upr     p adj
## Empleados-Agricultores   -0.1148571 -0.26137992 0.03166563 0.1441473
## NoExpuestos-Agricultores  0.1582540  0.00841685 0.30809109 0.0371048
## NoExpuestos-Empleados     0.2731111  0.13650025 0.40972198 0.0001314</code></pre>
<p>Se concluye que los niveles de concentración plasmática en el grupo no expuestos son significativamente mayores que en los otros dos grupos. Esto sugiere que la exposición de los grupos empleados y agricultores podría estar asociada a una reducción en los niveles observados del compuesto químico.</p>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio 1
</div>
<p>
Investiga sobre el método de LSD (diferencia mínima significativa) y el método de Duncan
</p>
</div>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio 2
</div>
<p>
Con los datos de calificaciones por grupo de enseñanza, aplica los métodos de Tukey, LSD y Duncan.
</p>
</div>
</div>
</div>
</div>
<div id="kruskalwallis" class="section level2 hasAnchor" number="4.6">
<h2><span class="header-section-number">4.6</span> Kruskal–Wallis<a href="estparynopar.html#kruskalwallis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El <strong>test de Kruskal–Wallis</strong>, también llamado <strong>test H</strong>, es la alternativa no paramétrica al análisis de varianza (<strong>ANOVA</strong>) de una vía cuando los datos no cumplen con los supuestos de normalidad o cuando las variables se miden en una escala ordinal. Es una extensión del test de Mann–Whitney para comparar más de dos grupos, y se basa en los <strong>rangos</strong> de los datos en lugar de sus valores originales.</p>
<p>A diferencia del ANOVA, que compara medias, el test de Kruskal–Wallis evalúa si las muestras provienen de la misma distribución. En la práctica, suele interpretarse como una comparación de <strong>medianas</strong> bajo ciertas condiciones.</p>
<div id="hipótesis-del-test" class="section level3 hasAnchor" number="4.6.1">
<h3><span class="header-section-number">4.6.1</span> Hipótesis del test<a href="#hip%C3%B3tesis-del-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><span class="math inline">\(H_0\)</span>: todas las muestras provienen de la misma población (misma distribución).</li>
<li><span class="math inline">\(H_A\)</span>: al menos una muestra proviene de una población con distribución distinta.</li>
</ul>
</div>
<div id="estadístico-de-prueba" class="section level3 hasAnchor" number="4.6.2">
<h3><span class="header-section-number">4.6.2</span> Estadístico de prueba<a href="#estad%C3%ADstico-de-prueba" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para realizar el test, se ordenan todas las observaciones de menor a mayor, se les asignan rangos y se calcula el estadístico <span class="math inline">\(H\)</span> mediante la fórmula:</p>
<p><span class="math display">\[
H = \frac{12}{N(N+1)} \sum_{i=1}^{k} \frac{R_i^2}{n_i} - 3(N+1)
\]</span></p>
<p>donde</p>
<ul>
<li><span class="math inline">\(N\)</span> es el número total de observaciones,</li>
<li><span class="math inline">\(k\)</span> es el número de grupos,</li>
<li><span class="math inline">\(R_i\)</span> es la suma de rangos del grupo <span class="math inline">\(i\)</span>,</li>
<li><span class="math inline">\(n_i\)</span> es el tamaño del grupo <span class="math inline">\(i\)</span>.</li>
</ul>
</div>
<div id="condiciones-del-test-de-kruskalwallis" class="section level3 hasAnchor" number="4.6.3">
<h3><span class="header-section-number">4.6.3</span> Condiciones del test de Kruskal–Wallis<a href="estparynopar.html#condiciones-del-test-de-kruskalwallis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>No se requiere que los datos provengan de una distribución normal.</li>
<li>Se asume <strong>homocedasticidad</strong>: las muestras deben tener varianzas similares.</li>
<li>La forma de las distribuciones debe ser igual entre grupos, aunque no necesariamente normal.</li>
<li>Es adecuado cuando los datos tienen un orden natural o son ordinales.</li>
</ul>
<p>El estadístico <span class="math inline">\(H\)</span> se compara con una distribución <span class="math inline">\(\chi^2\)</span> con <span class="math inline">\(k - 1\)</span> grados de libertad. Si el número de grupos es 3 y el tamaño de muestra por grupo es pequeño (≤5), se recomienda utilizar valores críticos tabulados.</p>
</div>
<div id="comparaciones-post-hoc" class="section level3 hasAnchor" number="4.6.4">
<h3><span class="header-section-number">4.6.4</span> Comparaciones Post-Hoc<a href="estparynopar.html#comparaciones-post-hoc" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Si el test de Kruskal–Wallis resulta significativo, indica que <strong>al menos dos grupos difieren</strong>, pero no especifica cuáles. Para identificarlos, se debe aplicar un análisis post-hoc que corrija el nivel de significancia para múltiples comparaciones.</p>
<p>Dos opciones frecuentes en R:</p>
<ul>
<li><strong>Prueba de Mann–Whitney</strong> para pares de grupos con corrección de p-valor:</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="estparynopar.html#cb86-1" tabindex="-1"></a>  <span class="fu">pairwise.wilcox.test</span>(variable, grupo)</span></code></pre></div>
</details>
<div class="admon-box ejemplo">
<div class="admon-title">
<span class="icon"></span> Ejemplo
</div>
<p>
En un estudio sobre el rendimiento cognitivo, se evaluó el <strong>tiempo de reacción</strong> (en milisegundos) de un grupo de participantes después de ser entrenados con tres métodos diferentes de estimulación mental: <strong>Método A</strong>, <strong>Método B</strong> y <strong>Método C</strong>. Cada uno de los métodos fue aplicado a un grupo de 18 personas seleccionadas aleatoriamente.
</p>
<p>
Al finalizar las sesiones de entrenamiento, a todos los participantes se les aplicó una prueba de reacción ante estímulos visuales. A continuación, se registraron sus tiempos de respuesta.
</p>
<p>
Dado que los datos muestran alta variabilidad y posibles valores extremos, se empleará una prueba estadística no paramétrica con el fin de comparar las distribuciones de los tiempos de reacción entre los tres métodos.
</p>
<p>
El objetivo del análisis es determinar si existen <strong>diferencias significativas en los tiempos de reacción</strong> entre al menos dos de los métodos utilizados.
</p>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="estparynopar.html#cb87-1" tabindex="-1"></a><span class="co"># Crear conjunto de datos</span></span>
<span id="cb87-2"><a href="estparynopar.html#cb87-2" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb87-3"><a href="estparynopar.html#cb87-3" tabindex="-1"></a>  <span class="at">metodo =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;Metodo_A&quot;</span>, <span class="dv">18</span>), <span class="fu">rep</span>(<span class="st">&quot;Metodo_B&quot;</span>, <span class="dv">18</span>), <span class="fu">rep</span>(<span class="st">&quot;Metodo_C&quot;</span>, <span class="dv">18</span>)),</span>
<span id="cb87-4"><a href="estparynopar.html#cb87-4" tabindex="-1"></a>  <span class="at">tiempo_reaccion =</span> <span class="fu">c</span>(</span>
<span id="cb87-5"><a href="estparynopar.html#cb87-5" tabindex="-1"></a>    <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">16</span>, <span class="dv">27</span>, <span class="dv">28</span>, <span class="dv">29</span>, <span class="dv">30</span>, <span class="dv">51</span>, <span class="dv">52</span>, <span class="dv">53</span>, <span class="dv">342</span>,          <span class="co"># Método A</span></span>
<span id="cb87-6"><a href="estparynopar.html#cb87-6" tabindex="-1"></a>    <span class="dv">40</span>, <span class="dv">41</span>, <span class="dv">42</span>, <span class="dv">43</span>, <span class="dv">44</span>, <span class="dv">45</span>, <span class="dv">46</span>, <span class="dv">47</span>, <span class="dv">48</span>, <span class="dv">67</span>, <span class="dv">88</span>, <span class="dv">89</span>, <span class="dv">90</span>, <span class="dv">91</span>, <span class="dv">92</span>, <span class="dv">93</span>, <span class="dv">94</span>, <span class="dv">293</span>, <span class="co"># Método B</span></span>
<span id="cb87-7"><a href="estparynopar.html#cb87-7" tabindex="-1"></a>    <span class="dv">19</span>, <span class="dv">20</span>, <span class="dv">21</span>, <span class="dv">22</span>, <span class="dv">23</span>, <span class="dv">24</span>, <span class="dv">25</span>, <span class="dv">26</span>, <span class="dv">27</span>, <span class="dv">28</span>, <span class="dv">25</span>, <span class="dv">36</span>, <span class="dv">37</span>, <span class="dv">58</span>, <span class="dv">59</span>, <span class="dv">60</span>, <span class="dv">71</span>, <span class="dv">72</span>   <span class="co"># Método C</span></span>
<span id="cb87-8"><a href="estparynopar.html#cb87-8" tabindex="-1"></a>  )</span>
<span id="cb87-9"><a href="estparynopar.html#cb87-9" tabindex="-1"></a>)</span></code></pre></div>
</details>
</div>
<p style="text-align: center;">
<strong>Solución</strong>
</p>
<div class="admon-box ejercicio">
<div class="admon-title">
<span class="icon"></span> Ejercicio
</div>
<p>
Realiza el análisis exploratorio del conjunto de datos
</p>
</div>
<ul>
<li>Verifiquemos la prueba de normalidad</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="estparynopar.html#cb88-1" tabindex="-1"></a>datos <span class="sc">%&gt;%</span></span>
<span id="cb88-2"><a href="estparynopar.html#cb88-2" tabindex="-1"></a>  <span class="fu">group_by</span>(metodo) <span class="sc">%&gt;%</span></span>
<span id="cb88-3"><a href="estparynopar.html#cb88-3" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">n =</span> <span class="fu">length</span>(tiempo_reaccion),</span>
<span id="cb88-4"><a href="estparynopar.html#cb88-4" tabindex="-1"></a>            <span class="at">estsw =</span> <span class="fu">shapiro.test</span>(tiempo_reaccion)<span class="sc">$</span>statistic,</span>
<span id="cb88-5"><a href="estparynopar.html#cb88-5" tabindex="-1"></a>            <span class="at">p_sw =</span> <span class="fu">shapiro.test</span>(tiempo_reaccion)<span class="sc">$</span>p.value)</span></code></pre></div>
</details>
<pre><code>## # A tibble: 3 × 4
##   metodo       n estsw        p_sw
##   &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;       &lt;dbl&gt;
## 1 Metodo_A    18 0.445 0.000000275
## 2 Metodo_B    18 0.575 0.00000383 
## 3 Metodo_C    18 0.790 0.00111</code></pre>
<p>La prueba de Shapiro-Will muestra que cada método no tienen comportamiento de una distribución normal.</p>
<ul>
<li>Probemos homogeneidad de varianzas</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="estparynopar.html#cb90-1" tabindex="-1"></a><span class="fu">leveneTest</span>(tiempo_reaccion <span class="sc">~</span> metodo, <span class="at">data =</span> datos)</span></code></pre></div>
</details>
<pre><code>## Warning in leveneTest.default(y = y, group = group, ...): group coerced to
## factor.</code></pre>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##       Df F value Pr(&gt;F)
## group  2  0.7929  0.458
##       51</code></pre>
<p>La prueba de Levene nos muestra que no se encuentra evidencia estadísticamente significativa para rechazar la hipótesis nula de homogeneidad de varianzas (<span class="math inline">\(F_{(2,51)}=0.79, p-valor = 0.458\)</span>). En consecuencia, se concluye que los tres métodos presentan varianzas similares en los tiempos de reacción, y por tanto, se cumple uno de los supuestos fundamentales para la aplicación de pruebas estadísticas comparativas.</p>
<ul>
<li>Veamos si hay diferencias en los métodos</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="estparynopar.html#cb93-1" tabindex="-1"></a><span class="fu">kruskal.test</span>(tiempo_reaccion <span class="sc">~</span> metodo, <span class="at">data =</span> datos)</span></code></pre></div>
</details>
<pre><code>## 
##  Kruskal-Wallis rank sum test
## 
## data:  tiempo_reaccion by metodo
## Kruskal-Wallis chi-squared = 19.964, df = 2, p-value = 4.623e-05</code></pre>
<p>La prueba de Kruskal-Wallis nos indica que existen diferencias estadísticamente significativas en los tiempos de reacción entre al menos dos de los métodos aplicados (<span class="math inline">\(\chi^2_{(2)}=19.964, p-valor &lt; 0.0001\)</span>)</p>
<ul>
<li>Apliquemos una prueba post-hoc para ver que métodos son diferentes</li>
</ul>
<details class=chunk-details open><summary class=chunk-summary><span class=chunk-summary-text>Code</span></summary>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="estparynopar.html#cb95-1" tabindex="-1"></a><span class="fu">pairwise.wilcox.test</span>(<span class="at">x =</span> datos<span class="sc">$</span>tiempo_reaccion,</span>
<span id="cb95-2"><a href="estparynopar.html#cb95-2" tabindex="-1"></a>                     <span class="at">g =</span> datos<span class="sc">$</span>metodo,</span>
<span id="cb95-3"><a href="estparynopar.html#cb95-3" tabindex="-1"></a>                     <span class="at">exact =</span> <span class="cn">FALSE</span>,</span>
<span id="cb95-4"><a href="estparynopar.html#cb95-4" tabindex="-1"></a>                     <span class="at">p.adjust.method =</span> <span class="st">&quot;bonferroni&quot;</span>)</span></code></pre></div>
</details>
<pre><code>## 
##  Pairwise comparisons using Wilcoxon rank sum test with continuity correction 
## 
## data:  datos$tiempo_reaccion and datos$metodo 
## 
##          Metodo_A Metodo_B
## Metodo_B 0.00068  -       
## Metodo_C 0.14386  0.00087 
## 
## P value adjustment method: bonferroni</code></pre>
<p>Con base en el ajuste de Bonferroni, se encontraron diferencias estadísticamente significativas entre los pares método A vs B y método B vs C (p &lt; 0.001 en ambos casos). No se detectó una diferencia significativa entre método A y método C (p = 0.14386). Esto sugiere que el método B se comporta de forma diferente respecto a los otros dos en términos de tiempo de reacción.</p>
<div class="admon-box nota">
<div class="admon-title">
<span class="icon"></span> Nota técnica: Comparación entre Bonferroni y Holm
</div>
<p>
Cuando se realizan múltiples comparaciones estadísticas, es necesario ajustar los valores-p para controlar el <strong>error de tipo I</strong> acumulado (la probabilidad de detectar falsos positivos). Dos métodos comunes para este ajuste son <strong>Bonferroni</strong> y <strong>Holm</strong>.
</p>
<p>
A continuación, se presenta una comparación entre ambos métodos:
</p>
<table>
<thead>
<tr>
<th>
Característica
</th>
<th>
Bonferroni
</th>
<th>
Holm
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Tipo de ajuste
</td>
<td>
Fijo (directo)
</td>
<td>
Secuencial (jerárquico)
</td>
</tr>
<tr>
<td>
Fórmula
</td>
<td>
<span class="math inline">\(p_i^\text{ajustado} = m \cdot p_i\)</span>
</td>
<td>
Ajuste por posición en orden ascendente
</td>
</tr>
<tr>
<td>
Conservadurismo
</td>
<td>
Muy conservador
</td>
<td>
Menos conservador
</td>
</tr>
<tr>
<td>
Potencia estadística
</td>
<td>
Baja
</td>
<td>
Alta
</td>
</tr>
<tr>
<td>
¿Rechaza más hipótesis?
</td>
<td>
No necesariamente
</td>
<td>
Sí
</td>
</tr>
<tr>
<td>
Controla el FWER
</td>
<td>
Sí
</td>
<td>
Sí
</td>
</tr>
<tr>
<td>
Uso en R
</td>
<td>
<code>method = “bonferroni”</code>
</td>
<td>
<code>method = “holm”</code>
</td>
</tr>
</tbody>
</table>
<p>
En la práctica, <strong>Holm</strong> es preferido cuando se desea mantener un buen control del error sin perder demasiada potencia estadística, mientras que <strong>Bonferroni</strong> puede utilizarse cuando se requiere máxima precaución (por ejemplo, en estudios clínicos).
</p>
</div>

</div>
</div>
</div>
<h3>Referencias<a href="referencias-1.html#referencias-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-llinas2019" class="csl-entry">
Solano, Humberto Llinás. 2019. <em>Estadística Inferencial</em>. Área metropolitana de Barranquilla, Colombia: Universidad del Norte.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="eda.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="tabcontingencia.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/rstudio/bookdown-demo/edit/master/04-estparynopa.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
