[["eda.html", "Capítulo 3 Análisis exploratorio de datos (EDA) 3.1 ¿Cuándo debo utilizarlo? 3.2 Representación de datos según su naturaleza 3.3 Presentación y análisis de la información en estudios descriptivos 3.4 Análisis explotario con variable respuesta numérica 3.5 Análisis explotario con variable respuesta categórica 3.6 Análisis de estadística paramétrica y no paramétrica", " Capítulo 3 Análisis exploratorio de datos (EDA) Figura 3.1: Análisis exploratorio de datos (EDA) El Análisis Exploratorio de Datos (Exploratory Data Analysis, EDA por sus siglas en inglés) es una etapa fundamental del proceso estadístico que consiste en utilizar gráficos, visualizaciones y resúmenes numéricos para examinar un conjunto de datos. Su propósito principal es explorar, descubrir patrones, identificar anomalías y formular posibles hipótesis, sin realizar inferencias estadísticas formales. El EDA busca comprender la estructura de los datos y generar ideas, más que confirmar hipótesis previamente establecidas. 3.1 ¿Cuándo debo utilizarlo? El Análisis Exploratorio de Datos (EDA) es una herramienta poderosa para examinar, comprender y preparar un conjunto de datos. Aunque el análisis esté orientado a hipótesis específicas, el EDA es útil en etapas previas como la limpieza de datos, la detección de errores, el análisis de subgrupos o simplemente para obtener una mejor comprensión de la estructura y comportamiento de los datos. Uno de los pasos iniciales más importantes del EDA es la representación gráfica de los datos, que permite identificar patrones, tendencias y valores atípicos con mayor claridad. 3.1.1 Tipos de análisis exploratorio: No gráfico: Utiliza estadísticas descriptivas para resumir las variables numéricamente. Gráfico: Representa visualmente los datos mediante histogramas, diagramas de caja, gráficos de dispersión, entre otros. Univariado: Analiza una sola variable a la vez, observando su distribución, tendencia central y dispersión. Multivariado: Examina dos o más variables simultáneamente, identificando relaciones o asociaciones entre ellas. Cada una de estas divisiones puede, a su vez, clasificarse según el tipo de variable involucrada: categórica o numérica. 3.2 Representación de datos según su naturaleza La forma en que se representan los datos depende fundamentalmente de su naturaleza, es decir, del tipo de variable que se está analizando. Esta clasificación influye directamente en la selección de métodos gráficos y estadísticos adecuados para el análisis. Tabla 3.1: Fechas de cortes y distribución de porcentajes Naturaleza.de.la.variable Escala.de.Medidas Frecuencias Medidas.de.Localización Medidas.de.Dispersión Medidas.de.Distribución Gráficos Cualitativa Nominal Sí Moda No No Sectores, Barras Ordinal Sí Moda No No Sectores, Barras (sin orden) Cuantitativa Intervalo Agrupadas Media, Mediana y Moda Sí Sí Histograma, Tallo y hojas, Cajas y Bigotes, Dispersión Razón Sí Sí 3.3 Presentación y análisis de la información en estudios descriptivos En los estudios descriptivos, la presentación y análisis de la información constituyen fases clave para comprender las características fundamentales de los datos recolectados. El objetivo principal es resumir y organizar la información de forma clara y accesible, sin realizar inferencias ni establecer relaciones causales. Tabla 3.2: Relación entre tipo de tabla y tipo de gráfico Tipo de Tabla Tipo de Gráfico De Frecuencia (Variable Cualitativa) Barras simples Pastel De Frecuencia (Variable Cuantitativa) Histograma De Asociacion (Dos Variables Cualitativas) Barras compuestas Barras superpuestas De Asociacion (Una Variable Cualitativa y una Cuantitativa Discreta) Barras: Compuestas Superpuestas De Asociacion (Una Variable Cualitativa y una Cuantitativa Continua) Poligono de Frecuencia Box plot (diagrama de cajas y bigotes) De Asociacion (Dos Variables Cuantitativas) Diagrama de Puntos 3.4 Análisis explotario con variable respuesta numérica Para el desarrollo de las visualización trabajaremos con datos sobre los almacenes Walmart, que es un cadena de grande almacenes de Ewa. Figura 3.2: Tienda Walmart El conjunto de datos completos lo puede encontrar este link. Trabajaremos un subconjunto de datos contiene las ventas semanales en dolares, cada tienda tiene un número de identificación y un tipo de tienda específico, las ventas estan separadas por ID de departamento. Junto con las ventas hay variables como si fue de vacaciones o no, la temperatura media durante la semana en esa localidad, el tiempo medio del combustible en dolares por litro esa semana y la tasa de desempleo de esa semana. 3.4.1 Contexto de los datos de Walmart Aquí tienes una explicación de las variables en el conjunto de datos de ventas proporcionado: Unnamed: Columna de índice que parece haber sido incluida al guardar el archivo. No es una variable significativa. store: Identificador del número de la tienda. type: Tipo de tienda, representado por una letra (por ejemplo, “A”, “B”, etc.). n department: Identificador del número de departamento dentro de la tienda. date: Fecha en la que se registró la venta. weekly_sales: Ventas semanales en USD registradas en esa tienda y departamento específicos (Target). is_holiday: Variable booleana que indica si la fecha corresponde a un día festivo o no. Los valores son “True” o “False”. temperature_c: Temperatura en grados Celsius en la fecha registrada. fuel_price_usd_per_l: Precio del combustible en dólares estadounidenses por litro en la fecha registrada. unemployment: Tasa de desempleo en la fecha registrada. El objetivo a resolver es predecir las ventas semanales, pero iniciaremos el análisis exploratorio de los datos de Walmart 3.4.2 Extracción, transformación y carga (ETL) Carguemos el conjunto de datos: Code url &lt;- &quot;https://raw.githubusercontent.com/cdeoroaguado/Datos/refs/heads/main/datamanip/sales.csv&quot; datos &lt;- read.csv(url) Verifiquemos que leímos bien los datos viendo el encabezado y la cola de los datos: Code head(datos,n=5) ## X store type department date weekly_sales is_holiday temperature_c ## 1 0 1 A 1 2010-02-05 24924.50 False 5.727778 ## 2 1 1 A 1 2010-03-05 21827.90 False 8.055556 ## 3 2 1 A 1 2010-04-02 57258.43 False 16.816667 ## 4 3 1 A 1 2010-05-07 17413.94 False 22.527778 ## 5 4 1 A 1 2010-06-04 17558.09 False 27.050000 ## fuel_price_usd_per_l unemployment ## 1 0.6794508 8.106 ## 2 0.6934520 8.106 ## 3 0.7182841 7.808 ## 4 0.7489281 7.808 ## 5 0.7145857 7.808 Las dimensiones, los nombres de las columnas y la estructura de la base de datos se obtienen con los códigos: Code dim(datos) ## [1] 10774 10 Code colnames(datos) ## [1] &quot;X&quot; &quot;store&quot; &quot;type&quot; ## [4] &quot;department&quot; &quot;date&quot; &quot;weekly_sales&quot; ## [7] &quot;is_holiday&quot; &quot;temperature_c&quot; &quot;fuel_price_usd_per_l&quot; ## [10] &quot;unemployment&quot; Code str(datos) ## &#39;data.frame&#39;: 10774 obs. of 10 variables: ## $ X : int 0 1 2 3 4 5 6 7 8 9 ... ## $ store : int 1 1 1 1 1 1 1 1 1 1 ... ## $ type : chr &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ... ## $ department : int 1 1 1 1 1 1 1 1 1 1 ... ## $ date : chr &quot;2010-02-05&quot; &quot;2010-03-05&quot; &quot;2010-04-02&quot; &quot;2010-05-07&quot; ... ## $ weekly_sales : num 24925 21828 57258 17414 17558 ... ## $ is_holiday : chr &quot;False&quot; &quot;False&quot; &quot;False&quot; &quot;False&quot; ... ## $ temperature_c : num 5.73 8.06 16.82 22.53 27.05 ... ## $ fuel_price_usd_per_l: num 0.679 0.693 0.718 0.749 0.715 ... ## $ unemployment : num 8.11 8.11 7.81 7.81 7.81 ... Eliminemos la variable X y date, ya que no estan en nuestra investigación: Code library(tidyverse) datos %&gt;% select(-X,-date) -&gt; df Code head(df, n=5) ## store type department weekly_sales is_holiday temperature_c ## 1 1 A 1 24924.50 False 5.727778 ## 2 1 A 1 21827.90 False 8.055556 ## 3 1 A 1 57258.43 False 16.816667 ## 4 1 A 1 17413.94 False 22.527778 ## 5 1 A 1 17558.09 False 27.050000 ## fuel_price_usd_per_l unemployment ## 1 0.6794508 8.106 ## 2 0.6934520 8.106 ## 3 0.7182841 7.808 ## 4 0.7489281 7.808 ## 5 0.7145857 7.808 Identifiquemos los valores NA por columna: Code df %&gt;% summarise(across(everything(), ~ sum(is.na(.)), .names = &quot;NA_{.col}&quot;)) ## NA_store NA_type NA_department NA_weekly_sales NA_is_holiday NA_temperature_c ## 1 0 0 0 0 0 0 ## NA_fuel_price_usd_per_l NA_unemployment ## 1 0 0 Otra forma de hacerlo es: Code library(Amelia) missmap(df) 3.4.3 Análisis de la variable weekly_sales (Target) Consideremos el resumen de la weekly_sales: Code df %&gt;% summarise( n = length(weekly_sales), media = mean(weekly_sales), ds = sd(weekly_sales), mediana = median(weekly_sales), minimo = min(weekly_sales), maximo = max(weekly_sales), Q1 = quantile(weekly_sales, 0.25), Q3 = quantile(weekly_sales, 0.75), IQR = IQR(weekly_sales) ) ## n media ds mediana minimo maximo Q1 Q3 IQR ## 1 10774 23843.95 30220.39 12049.06 -1098 293966 3867.115 32349.85 28482.73 La variable weekly_sales fue analizada a partir de 10.774 observaciones. Se obtuvo un promedio de ventas semanales de aproximadamente \\(23.843,95\\) usd (DS = \\(30.220,39\\) usd), donde El \\(50\\%\\) de las ventas semanales se encuentran por debajo de \\(12.049,06\\) usd. El mínimo registrado fue de \\(-1.098\\) usd, lo que indica que en ciertas semanas se presentaron saldos negativos de ventas, posiblemente debido a devoluciones de productos, ajustes contables o cancelaciones, situaciones comunes en grandes cadenas minoristas como Walmart. Por su parte, el máximo alcanzó los \\(293.966\\) usd, lo cual refleja una alta heterogeneidad entre tiendas o departamentos. Veamos un histograma Code df %&gt;% ggplot(aes(x = weekly_sales)) + geom_histogram(aes(y = after_stat(density)), binwidth = 5000, fill = &quot;#2c7fb8&quot;, color = &quot;white&quot;, alpha = 0.6) + geom_density(color = &quot;darkblue&quot;, linewidth = 1.2) + labs( title = &quot;Distribución de Ventas Semanales&quot;, x = &quot;Ventas Semanales (USD)&quot;, y = &quot;Densidad&quot; ) + theme_bw() Veamos un diagrama de cajas y bigotes Code df %&gt;% ggplot(aes(x = &quot;&quot;, y = weekly_sales)) + geom_boxplot(fill = &quot;#a6cee3&quot;, color = &quot;#1f78b4&quot;, outlier.color = &quot;red&quot;) + stat_summary( fun = mean, geom = &quot;point&quot;, shape = 20, size = 3, color = &quot;black&quot; ) + labs( title = &quot;Diagrama de cajas y bigotes de ventas semanales&quot;, x = &quot;&quot;, y = &quot;Ventas Semanales (USD)&quot; ) + theme_bw() La distribución de weekly_sales es altamente asimétrica, con fuerte concentración de valores bajos y una cantidad significativa de valores extremos altos. Esto indica que aunque la mayoría de las tiendas tienen ventas semanales moderadas, existen algunas con ventas excepcionalmente altas que influyen notablemente en los estadísticos como la media y la desviación estándar. 3.4.4 Análisis de las variables características (independientes) Analizaremos el iniciamente las variables numéricas Code df %&gt;% summarise( n = length(temperature_c), media = mean(temperature_c), ds = sd(temperature_c), mediana = median(temperature_c), minimo = min(temperature_c), maximo = max(temperature_c), Q1 = quantile(temperature_c, 0.25), Q3 = quantile(temperature_c, 0.75), IQR = IQR(temperature_c)) %&gt;% mutate(variable = &quot;temperature_c&quot;) -&gt; var_num_temp df %&gt;% summarise( n = length(fuel_price_usd_per_l), media = mean(fuel_price_usd_per_l), ds = sd(fuel_price_usd_per_l), mediana = median(fuel_price_usd_per_l), minimo = min(fuel_price_usd_per_l), maximo = max(fuel_price_usd_per_l), Q1 = quantile(fuel_price_usd_per_l, 0.25), Q3 = quantile(fuel_price_usd_per_l, 0.75), IQR = IQR(fuel_price_usd_per_l)) %&gt;% mutate(variable = &quot;fuel_price_usd_per_l&quot;) -&gt; var_num_fuel df %&gt;% summarise( n = length(unemployment), media = mean(unemployment), ds = sd(unemployment), mediana = median(unemployment), minimo = min(unemployment), maximo = max(unemployment), Q1 = quantile(unemployment, 0.25), Q3 = quantile(unemployment, 0.75), IQR = IQR(unemployment)) %&gt;% mutate(variable = &quot;unemployment&quot;)-&gt; var_num_unemploy bind_rows(var_num_temp, var_num_fuel, var_num_unemploy) %&gt;% select(variable, everything()) ## variable n media ds mediana minimo ## 1 temperature_c 10774 15.7319782 9.92244608 16.9666667 -8.3666667 ## 2 fuel_price_usd_per_l 10774 0.7497458 0.05949359 0.7433805 0.6641289 ## 3 unemployment 10774 8.0820086 0.62435501 8.0990000 3.8790000 ## maximo Q1 Q3 IQR ## 1 33.827778 7.5833333 24.1666667 16.58333333 ## 2 1.107674 0.7082456 0.7814213 0.07317569 ## 3 9.765000 7.7950000 8.3600000 0.56500000 Code library(patchwork) # Boxplot de temperature_c p1 &lt;- df %&gt;% ggplot(aes(x=&quot;&quot;, y = temperature_c)) + geom_boxplot(fill = &quot;#1f77b4&quot;, alpha = 0.7) + labs( title = &quot;Distribucion de temperatura&quot;, y = &quot;Temperatura (°C)&quot;, x = &quot;&quot; ) + theme_bw() # Boxplot de fuel_price_usd_per_l p2 &lt;- df %&gt;% ggplot(aes(x=&quot;&quot;,y = fuel_price_usd_per_l)) + geom_boxplot(fill = &quot;#2ca02c&quot;, alpha = 0.7) + labs( title = &quot;Distribucion del precio del combustible&quot;, y = &quot;Precio (USD/litro)&quot;, x = &quot;&quot; ) + theme_bw() # Boxplot de unemployment p3 &lt;- df %&gt;% ggplot(aes(x=&quot;&quot;,y = unemployment)) + geom_boxplot(fill = &quot;#d62728&quot;, alpha = 0.7) + labs( title = &quot;Distribucion del desempleo&quot;, y = &quot;Tasa de desempleo (%)&quot;, x = &quot;&quot; ) + theme_bw() # Unir los tres gráficos en una sola visualización p1 + p2 + p3 Ejercicio La interpretación de la tabla y el gráfico quedan como ejercicio Ahora analizaremos las variables categóricas Code # Tabla de frecuencias para type tabla_type &lt;- df %&gt;% count(type, name = &quot;Frecuencia&quot;) %&gt;% mutate( Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;type&quot;, Categoria = as.character(type) ) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Tabla de frecuencias para department tabla_department &lt;- df %&gt;% count(department, name = &quot;Frecuencia&quot;) %&gt;% mutate( Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;department&quot;, Categoria = as.character(department) ) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Tabla de frecuencias para is_holiday tabla_holiday &lt;- df %&gt;% count(is_holiday, name = &quot;Frecuencia&quot;) %&gt;% mutate( Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;is_holiday&quot;, Categoria = as.character(is_holiday) ) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Unir todas las tablas bind_rows(tabla_type, tabla_department, tabla_holiday) ## Variable Categoria Frecuencia Porcentaje ## 1 type A 9872 91.63 ## 2 type B 902 8.37 ## 3 department 1 144 1.34 ## 4 department 2 144 1.34 ## 5 department 3 144 1.34 ## 6 department 4 144 1.34 ## 7 department 5 144 1.34 ## 8 department 6 144 1.34 ## 9 department 7 144 1.34 ## 10 department 8 144 1.34 ## 11 department 9 144 1.34 ## 12 department 10 144 1.34 ## 13 department 11 144 1.34 ## 14 department 12 144 1.34 ## 15 department 13 144 1.34 ## 16 department 14 144 1.34 ## 17 department 16 144 1.34 ## 18 department 17 144 1.34 ## 19 department 18 144 1.34 ## 20 department 19 140 1.30 ## 21 department 20 144 1.34 ## 22 department 21 144 1.34 ## 23 department 22 144 1.34 ## 24 department 23 144 1.34 ## 25 department 24 144 1.34 ## 26 department 25 144 1.34 ## 27 department 26 144 1.34 ## 28 department 27 144 1.34 ## 29 department 28 144 1.34 ## 30 department 29 144 1.34 ## 31 department 30 144 1.34 ## 32 department 31 144 1.34 ## 33 department 32 144 1.34 ## 34 department 33 144 1.34 ## 35 department 34 144 1.34 ## 36 department 35 144 1.34 ## 37 department 36 144 1.34 ## 38 department 37 120 1.11 ## 39 department 38 144 1.34 ## 40 department 39 7 0.06 ## 41 department 40 144 1.34 ## 42 department 41 144 1.34 ## 43 department 42 144 1.34 ## 44 department 43 2 0.02 ## 45 department 44 144 1.34 ## 46 department 45 126 1.17 ## 47 department 46 144 1.34 ## 48 department 47 114 1.06 ## 49 department 48 90 0.84 ## 50 department 49 144 1.34 ## 51 department 50 72 0.67 ## 52 department 51 99 0.92 ## 53 department 52 144 1.34 ## 54 department 54 144 1.34 ## 55 department 55 144 1.34 ## 56 department 56 144 1.34 ## 57 department 58 144 1.34 ## 58 department 59 144 1.34 ## 59 department 60 144 1.34 ## 60 department 67 144 1.34 ## 61 department 71 144 1.34 ## 62 department 72 144 1.34 ## 63 department 74 144 1.34 ## 64 department 77 39 0.36 ## 65 department 78 56 0.52 ## 66 department 79 144 1.34 ## 67 department 80 144 1.34 ## 68 department 81 144 1.34 ## 69 department 82 144 1.34 ## 70 department 83 144 1.34 ## 71 department 85 144 1.34 ## 72 department 87 144 1.34 ## 73 department 90 144 1.34 ## 74 department 91 144 1.34 ## 75 department 92 144 1.34 ## 76 department 93 144 1.34 ## 77 department 94 144 1.34 ## 78 department 95 144 1.34 ## 79 department 96 138 1.28 ## 80 department 97 144 1.34 ## 81 department 98 144 1.34 ## 82 department 99 123 1.14 ## 83 is_holiday False 10732 99.61 ## 84 is_holiday True 42 0.39 El \\(91.63\\%\\) de los registros pertenecen al tipo A, lo que indica que la gran mayoría de las observaciones están asociadas a este tipo de tienda, donde el tipo B representa solo el \\(8.37\\%\\) de los casos, lo cual puede sugerir que es menos común, más específico o de menor cobertura. Existen más de \\(80\\) categorías distintas. La mayoría de los departamentos tienen la misma frecuencia de \\(144\\) observaciones (\\(1.34\\%\\)), lo que sugiere una distribución uniforme entre muchas de las categorías. Tambien nos inidica que hay una alta dispersión en las frecuencias de los departamentos, lo que indica que no todos los departamentos tienen el mismo nivel de actividad. Algunos departamentos deben ser tratados con precaución en los análisis inferenciales por su baja frecuencia. Solo el \\(0.39\\%\\) de los registros corresponden a días festivos. Esto muestra una clara desproporción: los días feriados son poco frecuentes en los datos. Aunque son escasos, los registros en días festivos pueden tener un comportamiento distinto (por ejemplo, picos de ventas o cambios de demanda), por lo que deben analizarse por separado o con métodos robustos que no se vean afectados por el desbalance. Code tabla_type_b &lt;- df %&gt;% count(type, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 1), Etiqueta = paste0(Frecuencia, &quot; (&quot;, Porcentaje, &quot;%)&quot;)) ggplot(tabla_type_b, aes(x = type, y = Frecuencia)) + geom_col(fill = &quot;#008B8B&quot;, width = 0.6) + geom_text(aes(label = Etiqueta), vjust = -0.5, size = 5) + facet_wrap(~ &quot;Distribución de la variable type&quot;) + scale_y_continuous(expand = expansion(mult = c(0, 0.15))) + labs(x = &quot;Tipo de tienda&quot;, y = &quot;Frecuencia (Porcentaje)&quot;) + theme_bw(base_size = 14) + theme( plot.title = element_blank(), strip.background = element_rect(fill = &quot;gray80&quot;, color = NA), strip.text = element_text(face = &quot;bold&quot;), panel.grid.major.x = element_blank() ) La gran mayoría de las observaciones (\\(91.6\\%\\)) corresponden al tipo A, con \\(9872\\) registros. Solo el \\(8.4\\%\\) restante corresponde al tipo B, con \\(902\\) registros. Code # Crear tabla de frecuencias para department tabla_department_b &lt;- df %&gt;% count(department, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 1), Etiqueta = paste0(Frecuencia, &quot; (&quot;, Porcentaje, &quot;%)&quot;)) # Gráfico ggplot(tabla_department_b, aes(x = factor(department), y = Frecuencia)) + geom_col(fill = &quot;#008B8B&quot;, width = 0.6) + geom_text(aes(label = Etiqueta), hjust = -0.1, size = 3) + facet_wrap(~ &quot;Distribución de la variable department&quot;) + scale_y_continuous(expand = expansion(mult = c(0, 0.10))) + labs(x = &quot;Departamento&quot;, y = &quot;Frecuencia (Porcentaje)&quot;) + coord_flip() + theme_bw(base_size = 14) + theme( plot.title = element_blank(), strip.background = element_rect(fill = &quot;gray80&quot;, color = NA), strip.text = element_text(face = &quot;bold&quot;), panel.grid.major.y = element_blank(), axis.text.y = element_text(size = 8) ) Ejercicio Interpreta el gráfico de la variable department y muestra únicamente las 10 categorías con mayor porcentaje. Realiza el gráfico para la variable is_holiday e interprétalo. 3.4.5 Análisis exploratorio bivariado Realizaremos la comparacion de la variable weekly_sales con respecto a las variables numéricas independientes. Code # Diagrama de dispersión: weekly_sales vs temperature_c df %&gt;% ggplot(aes(x = temperature_c, y = weekly_sales)) + geom_point(alpha = 0.4, color = &quot;#1E90FF&quot;) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;red&quot;) + labs(x = &quot;Temperatura (°C)&quot;, y = &quot;Ventas semanales (uds)&quot; ) + theme_bw()+ facet_grid(.~ &quot;Dispersión entre Weekly Sales y Temperature (°C)&quot;) Los puntos están muy dispersos a lo largo de todo el eje de temperatura (desde aproximadamente \\(-10 °C\\) hasta \\(35 °C\\)), pero no muestran una tendencia clara ascendente ni descendente. La mayoría de las tiendas se agrupan entre temperaturas de \\(0 °C\\) y \\(30 °C\\), lo que es esperado para regiones con climas templados. A lo largo del eje de temperatura, las ventas semanales presentan alta variabilidad, es decir, hay tiendas con ventas altas y bajas a cualquier temperatura. Existen varios puntos con ventas muy elevadas (por encima de 200.000), que podrían representar eventos especiales, promociones, festividades, etc. También se observan múltiples valores cercanos a cero, lo cual podría indicar tiendas cerradas, errores en la base de datos, o semanas sin ventas. No se evidencia una relación lineal clara entre la temperatura y las ventas semanales. La temperatura parece tener un efecto mínimo o nulo sobre las ventas, lo cual sugiere que otras variables podrían tener mayor peso explicativo en el comportamiento de weekly_sales. Ejercicio Realiza el diagrama de dispersión para la variable weekly_sales con respecto a las variables fuel_price_usd_per_l y unemployment e interprétalos. Realizaremos la comparacion de la variable weekly_sales con respecto a las variables categóricas independientes. Code # Agrupación por &#39;type&#39; type_week &lt;- df %&gt;% group_by(type) %&gt;% summarise(n = length(weekly_sales), media = mean(weekly_sales), ds = sd(weekly_sales), mediana = median(weekly_sales), minimo = min(weekly_sales), maximo = max(weekly_sales), Q1 = quantile(weekly_sales, 0.25), Q3 = quantile(weekly_sales, 0.75), IQR = IQR(weekly_sales)) %&gt;% mutate(variable = &quot;type&quot;, niveles = as.character(type)) %&gt;% select(variable, niveles, everything(), -type) # Agrupación por &#39;store&#39; store_week &lt;- df %&gt;% group_by(store) %&gt;% summarise(n = length(weekly_sales), media = mean(weekly_sales), ds = sd(weekly_sales), mediana = median(weekly_sales), minimo = min(weekly_sales), maximo = max(weekly_sales), Q1 = quantile(weekly_sales, 0.25), Q3 = quantile(weekly_sales, 0.75), IQR = IQR(weekly_sales)) %&gt;% mutate(variable = &quot;store&quot;, niveles = as.character(store)) %&gt;% select(variable, niveles, everything(), -store) # Agrupación por &#39;department&#39; dep_week &lt;- df %&gt;% group_by(department) %&gt;% summarise(n = length(weekly_sales), media = mean(weekly_sales), ds = sd(weekly_sales), mediana = median(weekly_sales), minimo = min(weekly_sales), maximo = max(weekly_sales), Q1 = quantile(weekly_sales, 0.25), Q3 = quantile(weekly_sales, 0.75), IQR = IQR(weekly_sales)) %&gt;% mutate(variable = &quot;department&quot;, niveles = as.character(department)) %&gt;% select(variable, niveles, everything(), -department) # Agrupación por &#39;is_holiday&#39; holi_week &lt;- df %&gt;% group_by(is_holiday) %&gt;% summarise(n = length(weekly_sales), media = mean(weekly_sales), ds = sd(weekly_sales), mediana = median(weekly_sales), minimo = min(weekly_sales), maximo = max(weekly_sales), Q1 = quantile(weekly_sales, 0.25), Q3 = quantile(weekly_sales, 0.75), IQR = IQR(weekly_sales)) %&gt;% mutate(variable = &quot;is_holiday&quot;, niveles = as.character(is_holiday)) %&gt;% select(variable, niveles, everything(), -is_holiday) # Unión de todas las tablas bind_rows(type_week, store_week, dep_week, holi_week) ## # A tibble: 96 × 11 ## variable niveles n media ds mediana minimo maximo Q1 Q3 ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 type A 9872 23675. 30129. 11944. -1098 293966. 3862. 31982. ## 2 type B 902 25697. 31156. 13336. -798 232559. 3998. 38195. ## 3 store 1 901 20897. 26994. 9775. -698 140504. 3199 30186. ## 4 store 2 897 26517. 32682. 13765. -1098 178983. 4892. 34612. ## 5 store 4 901 26127. 31202. 13064. -88 165766. 4571. 35552. ## 6 store 6 894 21561. 23658. 13201. -698 119812. 4284. 30962. ## 7 store 10 902 25697. 31156. 13336. -798 232559. 3998. 38195. ## 8 store 13 913 25664. 31499. 13050. -98 166872. 4396. 34686. ## 9 store 14 885 30384. 40467. 14793. -498 293966. 4386 37384. ## 10 store 19 906 19931. 24662. 11092. -449 147449. 3695. 24861. ## # ℹ 86 more rows ## # ℹ 1 more variable: IQR &lt;dbl&gt; La variable type clasifica las tiendas en dos categorías: A y B, donde el \\(91.6\\%\\) de los registros corresponde a tiendas tipo A (\\(n = 9872\\)) y solo el \\(8.4\\%\\) a tipo B (\\(n = 902\\)). A pesar de su menor frecuencia, las tiendas tipo B presentan una media de ventas semanales más alta de \\(25696.68\\) usd (DS = \\(31155.87\\) usd) comparada con las de tipo A de \\(23674.67\\) usd (DS = \\(30129.41\\) usd). El \\(50\\%\\) de las tiendas tipo B tiene ventas semanales por debajo de 13336.08 usd, mientras que en las tipo A este valor es de \\(11943.920\\) usd. Además, las tiendas tipo B presentan un rango intercuartílico más amplio (IQR = \\(34196.80\\) usd) en comparación con las tipo A (IQR = \\(28119.99\\) usd), lo que indica una mayor dispersión en la distribución de sus ventas semanales. Estos datos sugieren que, aunque las tiendas tipo B son menos frecuentes, tienden a mostrar un mejor desempeño en ventas, acompañado de una mayor variabilidad en sus resultados. La variable is_holiday identifica si una semana corresponde a un periodo festivo (True) o no (False). La mayoría de los registros (\\(99.6\\%\\)) corresponden a semanas no festivas (\\(n = 10732\\)), mientras que solo el \\(0.4\\%\\) pertenece a semanas festivas (\\(n = 42\\)). Las semanas no festivas presentan una media de ventas semanales de \\(23934.91 usd\\) (DS = \\(30,244.33\\) usd), significativamente superior a la de las semanas festivas, que registran en promedio apenas \\(600.55\\) usd (DS = \\(1054.73\\) usd). El \\(50\\%\\) de las semanas no festivas tiene ventas por debajo de \\(12135.16\\) usd, mientras que en las semanas festivas ese valor cae a tan solo \\(37.50\\) usd. El rango intercuartílico (IQR) también es mucho más amplio en las semanas no festivas (\\(28555.85\\) usd) que en las festivas (\\(928\\) usd), lo que indica no solo un volumen mayor de ventas en semanas regulares, sino también una mayor variabilidad. Estos resultados reflejan que las semanas festivas se asocian con un desempeño comercial considerablemente menor en comparación con las semanas ordinarias. Ejercicio Realiza la interpretación para la variable weekly_sales con respecto a las variables department y store. Code # boxplot: weekly_sales vs tipo df %&gt;% ggplot(aes(x = type, y = weekly_sales)) + geom_boxplot(fill = &quot;#87CEFA&quot;, outlier.colour = &quot;red&quot;, outlier.shape = 16) + stat_summary(fun = mean, geom = &quot;point&quot;, shape = 18, size = 3, color = &quot;darkblue&quot;) + labs(x = &quot;Tipo de tienda&quot;, y = &quot;Ventas semanales (usd)&quot; ) + theme_bw()+ facet_grid(.~&quot;Distribución de Weekly Sales por tipo de tienda&quot;) El gráfico compara las ventas semanales de las tiendas tipo A y B. Se observa que, aunque hay muchas más tiendas tipo A, las tiendas tipo B presentan un promedio de ventas semanales ligeramente más alto, lo cual se refleja en el rombo azul más elevado en su caja. Además, las tiendas tipo B muestran mayor variación en sus ventas, es decir, algunas venden mucho y otras menos, mientras que las tipo A tienen un comportamiento un poco más concentrado. Los puntos rojos sobre las cajas indican semanas con ventas excepcionalmente altas, siendo más frecuentes en las tiendas tipo A. En conjunto, esto sugiere que las tiendas tipo B, aunque menos numerosas, tienden a tener un mejor desempeño promedio, pero con mayor variabilidad; mientras que las tiendas tipo A tienen más casos extremos de ventas muy altas. Ejercicio Realiza la gráfica para la variable weekly_sales con respecto a las variables department, is_holiday y store. Interprétala. Realiza el análisis bivariado con respecto a las variables independientes. Paquete GGally El paquete GGally es una extensión de ggplot2 que facilita la creación de gráficos multivariados para análisis exploratorio de datos. Una de sus funciones más utilizadas es ggpairs(), que permite visualizar simultáneamente relaciones entre varias variables, tanto numéricas como categóricas, mediante: Diagramas de dispersión (scatterplots), Histogramas o densidades en la diagonal, Correlaciones entre pares de variables numéricas. Esto es especialmente útil para detectar patrones, asociaciones o valores atípicos en conjuntos de datos con múltiples variables. Su instalación y carga del paquete Code install.packages(&quot;GGally&quot;) library(GGally) Modo de uso del paquete GGally: Code library(GGally) df %&gt;% ggpairs() Ejercicio Menciona los errores que puedes encontrar en el gráfico 3.5 Análisis explotario con variable respuesta categórica 3.5.1 Contexto del conjunto de datos de marketing de un banco Este conjunto de datos corresponde a campañas de marketing directo realizadas por una institución bancaria portuguesa, cuyo objetivo era promover la contratación de depósitos a plazo fijo por parte de sus clientes. Las campañas se llevaron a cabo principalmente mediante llamadas telefónicas, y los datos recolectados reflejan tanto características socioeconómicas del cliente como información específica de la interacción comercial. El conjunto contiene 4521 observaciones y 17 variables, entre las cuales se incluyen datos demográficos, financieros y relacionados con el historial de contacto de cada cliente. A continuación se describen las variables: Estas son las variables age: Edad del cliente. job: Profesión del cliente (por ejemplo: desempleado, servicios, gestión). marital: Estado civil del cliente (soltero, casado, divorciado). education: Nivel educativo (primaria, secundaria, terciaria). default: Indica si el cliente tiene crédito en incumplimiento (sí/no). balance: Saldo promedio anual de la cuenta bancaria. housing: Indica si posee préstamo hipotecario (sí/no). loan: Indica si tiene préstamo personal (sí/no). contact: Tipo de comunicación utilizada (celular o fijo). day: Día del mes en que se realizó el último contacto. month: Mes del último contacto. duration: Duración de la última llamada (en segundos). campaign: Número de contactos realizados durante la campaña actual. pdays: Número de días transcurridos desde el último contacto previo (valor -1 indica que no hubo contacto anterior). previous: Número de contactos previos al actual. poutcome: Resultado de una campaña anterior (éxito, fracaso, desconocido). y: Variable objetivo que indica si el cliente aceptó (yes) o no aceptó (no) contratar un depósito a plazo fijo. El objetivo principal es predecir si un cliente aceptará o no un depósito a plazo fijo (y), a partir de sus características personales, financieras y del historial de contactos anteriores. Este análisis permitirá a la entidad financiera optimizar sus estrategias de marketing, enfocándose en los perfiles con mayor probabilidad de conversión, reduciendo costos y mejorando la eficiencia de las campañas. Inicialmente, haremos un análisis exploratorio de los datos. 3.5.2 Extracción, transformación y carga (ETL) Carguemos el conjunto de datos: Code url &lt;- &quot;https://raw.githubusercontent.com/cdeoroaguado/Datos/refs/heads/main/datamanip/bank.csv&quot; datos &lt;- read.csv(url, sep = &quot;;&quot;, stringsAsFactors = TRUE) Verifiquemos que leímos bien los datos viendo el encabezado y la cola de los datos: Code head(datos,n=5) ## age job marital education default balance housing loan contact day ## 1 30 unemployed married primary no 1787 no no cellular 19 ## 2 33 services married secondary no 4789 yes yes cellular 11 ## 3 35 management single tertiary no 1350 yes no cellular 16 ## 4 30 management married tertiary no 1476 yes yes unknown 3 ## 5 59 blue-collar married secondary no 0 yes no unknown 5 ## month duration campaign pdays previous poutcome y ## 1 oct 79 1 -1 0 unknown no ## 2 may 220 1 339 4 failure no ## 3 apr 185 1 330 1 failure no ## 4 jun 199 4 -1 0 unknown no ## 5 may 226 1 -1 0 unknown no Las dimensiones, los nombres de las columnas y la estructura de la base de datos se obtienen con los códigos: Code dim(datos) ## [1] 4521 17 Code colnames(datos) ## [1] &quot;age&quot; &quot;job&quot; &quot;marital&quot; &quot;education&quot; &quot;default&quot; &quot;balance&quot; ## [7] &quot;housing&quot; &quot;loan&quot; &quot;contact&quot; &quot;day&quot; &quot;month&quot; &quot;duration&quot; ## [13] &quot;campaign&quot; &quot;pdays&quot; &quot;previous&quot; &quot;poutcome&quot; &quot;y&quot; Code str(datos) ## &#39;data.frame&#39;: 4521 obs. of 17 variables: ## $ age : int 30 33 35 30 59 35 36 39 41 43 ... ## $ job : Factor w/ 12 levels &quot;admin.&quot;,&quot;blue-collar&quot;,..: 11 8 5 5 2 5 7 10 3 8 ... ## $ marital : Factor w/ 3 levels &quot;divorced&quot;,&quot;married&quot;,..: 2 2 3 2 2 3 2 2 2 2 ... ## $ education: Factor w/ 4 levels &quot;primary&quot;,&quot;secondary&quot;,..: 1 2 3 3 2 3 3 2 3 1 ... ## $ default : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ balance : int 1787 4789 1350 1476 0 747 307 147 221 -88 ... ## $ housing : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 2 2 2 2 1 2 2 2 2 ... ## $ loan : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 2 1 2 1 1 1 1 1 2 ... ## $ contact : Factor w/ 3 levels &quot;cellular&quot;,&quot;telephone&quot;,..: 1 1 1 3 3 1 1 1 3 1 ... ## $ day : int 19 11 16 3 5 23 14 6 14 17 ... ## $ month : Factor w/ 12 levels &quot;apr&quot;,&quot;aug&quot;,&quot;dec&quot;,..: 11 9 1 7 9 4 9 9 9 1 ... ## $ duration : int 79 220 185 199 226 141 341 151 57 313 ... ## $ campaign : int 1 1 1 4 1 2 1 2 2 1 ... ## $ pdays : int -1 339 330 -1 -1 176 330 -1 -1 147 ... ## $ previous : int 0 4 1 0 0 3 2 0 0 2 ... ## $ poutcome : Factor w/ 4 levels &quot;failure&quot;,&quot;other&quot;,..: 4 1 1 4 4 1 2 4 4 1 ... ## $ y : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 1 1 1 1 1 1 1 1 1 ... Para facilitar el análisis exploratorio y evitar redundancias o ruido en el modelo, se eliminarán las variables day, month y previous. Code library(tidyverse) datos %&gt;% select(-day, -month, -previous) -&gt; df Code head(df, n=5) ## age job marital education default balance housing loan contact ## 1 30 unemployed married primary no 1787 no no cellular ## 2 33 services married secondary no 4789 yes yes cellular ## 3 35 management single tertiary no 1350 yes no cellular ## 4 30 management married tertiary no 1476 yes yes unknown ## 5 59 blue-collar married secondary no 0 yes no unknown ## duration campaign pdays poutcome y ## 1 79 1 -1 unknown no ## 2 220 1 339 failure no ## 3 185 1 330 failure no ## 4 199 4 -1 unknown no ## 5 226 1 -1 unknown no Identifiquemos los valores NA por columna: Code df %&gt;% summarise(across(everything(), ~ sum(is.na(.)), .names = &quot;NA_{.col}&quot;)) ## NA_age NA_job NA_marital NA_education NA_default NA_balance NA_housing ## 1 0 0 0 0 0 0 0 ## NA_loan NA_contact NA_duration NA_campaign NA_pdays NA_poutcome NA_y ## 1 0 0 0 0 0 0 0 Otra forma de hacerlo es: Code library(Amelia) missmap(df) 3.5.3 Análisis de la variable y (Target) Consideremos el resumen de la y: Code df %&gt;% count(y) %&gt;% mutate(porcentaje = (n/sum(n))*100) ## y n porcentaje ## 1 no 4000 88.476 ## 2 yes 521 11.524 La variable y representa el resultado de la campaña de marketing, indicando si el cliente aceptó (yes) o no aceptó (no) contratar un depósito a plazo fijo. De un total de \\(4521\\) observaciones, el \\(88.48\\%\\) de los clientes (\\(n = 4000\\)) no aceptaron la oferta, mientras que solo el \\(11.52\\%\\) (\\(n = 521\\)) sí lo hicieron. Esta distribución refleja un fuerte desequilibrio en los clientes, lo que sugiere que la mayoría de los clientes no están interesados en este producto financiero, y dicho desequilibrio debe considerarse cuidadosamente al construir modelos de predicción. Veamos un diagrama de barras Code # Crear tabla de frecuencias para department tabla_y &lt;- df %&gt;% count(y, name = &quot;Clientes&quot;) %&gt;% mutate(Porcentaje = round(Clientes / sum(Clientes) * 100, 1), Etiqueta = paste0(Clientes, &quot; (&quot;, Porcentaje, &quot;%)&quot;)) # Gráfico tabla_y %&gt;% ggplot(aes(x = factor(y), y = Clientes)) + geom_col(fill = &quot;#008B8B&quot;, width = 0.6) + geom_text(aes(label = Etiqueta), vjust = -0.5, size = 3) + facet_grid(~ &quot;Distribución de la campaña de marketing (no/yes)&quot;) + scale_y_continuous(expand = expansion(mult = c(0, 0.15))) + labs(x = &quot;Campaña de marketing&quot;, y = &quot;número de clientes (Porcentaje)&quot;) + #coord_flip() + theme_bw(base_size = 14) + theme( plot.title = element_blank(), strip.background = element_rect(fill = &quot;gray80&quot;, color = NA), strip.text = element_text(face = &quot;bold&quot;), panel.grid.major.y = element_blank(), axis.text.y = element_text(size = 8) ) El gráfico de barras muestra claramente la distribución de respuestas en la campaña de marketing, evidenciando que la gran mayoría de los clientes no aceptaron la oferta del depósito a plazo fijo. Específicamente, el \\(88.5\\%\\) de los clientes (\\(4000\\) personas) rechazaron la campaña (no), mientras que solo el \\(11.5&#39;%\\) (\\(521\\) personas) decidieron aceptarla (yes). Esta marcada diferencia indica un fuerte desbalance en las clases de la variable objetivo, lo cual es relevante al momento de construir modelos predictivos, ya que se requiere considerar técnicas que manejen adecuadamente este desequilibrio para no sesgar el modelo hacia la clase mayoritaria. 3.5.4 Análisis de las variables características (independientes) Analizaremos el iniciamente las variables numéricas Code df %&gt;% summarise( n = length(age), media = mean(age), ds = sd(age), mediana = median(age), minimo = min(age), maximo = max(age), Q1 = quantile(age, 0.25), Q3 = quantile(age, 0.75), IQR = IQR(age)) %&gt;% mutate(variable = &quot;age&quot;) -&gt; var_num_age df %&gt;% summarise( n = length(balance), media = mean(balance), ds = sd(balance), mediana = median(balance), minimo = min(balance), maximo = max(balance), Q1 = quantile(balance, 0.25), Q3 = quantile(balance, 0.75), IQR = IQR(balance)) %&gt;% mutate(variable = &quot;balance&quot;) -&gt; var_num_bal df %&gt;% summarise( n = length(duration), media = mean(duration), ds = sd(duration), mediana = median(duration), minimo = min(duration), maximo = max(duration), Q1 = quantile(duration, 0.25), Q3 = quantile(duration, 0.75), IQR = IQR(duration)) %&gt;% mutate(variable = &quot;duration&quot;)-&gt; var_num_dur df %&gt;% summarise( n = length(campaign), media = mean(campaign), ds = sd(campaign), mediana = median(campaign), minimo = min(campaign), maximo = max(campaign), Q1 = quantile(campaign, 0.25), Q3 = quantile(campaign, 0.75), IQR = IQR(campaign)) %&gt;% mutate(variable = &quot;campaign&quot;)-&gt; var_num_camp df %&gt;% summarise( n = length(pdays), media = mean(pdays), ds = sd(pdays), mediana = median(pdays), minimo = min(pdays), maximo = max(pdays), Q1 = quantile(pdays, 0.25), Q3 = quantile(pdays, 0.75), IQR = IQR(pdays)) %&gt;% mutate(variable = &quot;pdays&quot;)-&gt; var_num_pdays bind_rows(var_num_age, var_num_bal, var_num_dur,var_num_camp,var_num_pdays) %&gt;% select(variable, everything()) ## variable n media ds mediana minimo maximo Q1 Q3 IQR ## 1 age 4521 41.17010 10.576211 39 19 87 33 49 16 ## 2 balance 4521 1422.65782 3009.638142 444 -3313 71188 69 1480 1411 ## 3 duration 4521 263.96129 259.856633 185 4 3025 104 329 225 ## 4 campaign 4521 2.79363 3.109807 2 1 50 1 3 2 ## 5 pdays 4521 39.76664 100.121124 -1 -1 871 -1 -1 0 El análisis estadístico de las variables numéricas revela características clave de los clientes contactados durante la campaña de marketing. La edad promedio es de \\(41.17\\) años (DS = \\(10.58\\) años), con un rango de \\(19\\) a \\(87\\) años, lo que indica una población adulta diversa. El saldo promedio anual en la cuenta bancaria (balance) es de \\(1422.66\\) USD (DS = \\(3009.64\\) USD), evidenciando una alta dispersión y la presencia de valores extremos, desde \\(-3313\\) hasta \\(71188\\) USD. La duración de las llamadas telefónicas presenta un promedio de \\(263.96\\) segundos (DS = \\(259.86\\) segundos), con el \\(50\\%\\) de las observaciones por debajo de \\(185\\) segundos y un rango que va desde \\(4\\) hasta \\(3025\\) segundos, lo que sugiere una distribución muy dispersa y posiblemente sesgada. En cuanto al número de contactos durante la campaña (campaign), se observa un promedio de \\(2.79\\) contactos (DS = \\(3.11\\)), con el \\(50\\%\\) de los registros por debajo de \\(2\\) y valores extremos que alcanzan hasta \\(50\\), aunque la mayoría de los clientes fue contactado pocas veces (rango intercuartílico de \\(P75% = 3\\) y \\(P25% = 1\\)). Por último, la variable pdays, que indica los días transcurridos desde el último contacto en campañas anteriores, tiene una media de \\(39.77\\) días (DS = \\(100.12\\) días), pero con el \\(50\\%\\) de los registros y los percentiles \\(25\\%\\) y \\(75\\%\\) en \\(-1\\), lo que indica que la mayoría de los clientes no había sido contactada previamente, a pesar de que algunos registros superan los \\(800\\) días. Estos datos permiten identificar comportamientos heterogéneos y posibles segmentos dentro de la base de clientes. Code library(patchwork) library(gridExtra) # Boxplot de age p1 &lt;- df %&gt;% ggplot(aes(x = &quot;&quot;, y = age)) + geom_boxplot(fill = &quot;#1f77b4&quot;, alpha = 0.7) + stat_summary(fun = mean, geom = &quot;point&quot;, shape = 18, size = 4, color = &quot;black&quot;) + labs( title = &quot;Distribución de la edad&quot;, y = &quot;Años&quot;, x = &quot;&quot; ) + theme_bw() # Boxplot de balance p2 &lt;- df %&gt;% ggplot(aes(x = &quot;&quot;, y = balance)) + geom_boxplot(fill = &quot;#2f43b1&quot;, alpha = 0.7) + stat_summary(fun = mean, geom = &quot;point&quot;, shape = 18, size = 4, color = &quot;black&quot;) + labs( title = &quot;Distribución del balance de la cuenta&quot;, y = &quot;Usd&quot;, x = &quot;&quot; ) + theme_bw() # Diagrama de boxplot para duration p3 &lt;- df %&gt;% ggplot(aes(x = &quot;&quot;, y = duration)) + geom_boxplot(fill = &quot;#2ca02c&quot;, alpha = 0.7) + stat_summary(fun = mean, geom = &quot;point&quot;, shape = 18, size = 4, color = &quot;black&quot;) + labs( title = &quot;Distribución de la duración de llamada (duration)&quot;, y = &quot;Segundos&quot;, x = &quot;&quot; ) + theme_bw() # Diagrama de boxplot para campaign p4 &lt;-df %&gt;% ggplot(aes(x = &quot;&quot;, y = campaign)) + geom_boxplot(fill = &quot;#ff7f0e&quot;, alpha = 0.7) + stat_summary(fun = mean, geom = &quot;point&quot;, shape = 18, size = 4, color = &quot;black&quot;) + labs( title = &quot;Distribución del número de contactos (campaign)&quot;, y = &quot;Número de contactos&quot;, x = &quot;&quot; ) + theme_bw() # Diagrama de boxplot para pdays p5 &lt;-df %&gt;% ggplot(aes(x = &quot;&quot;, y = pdays)) + geom_boxplot(fill = &quot;#9467bd&quot;, alpha = 0.7) + stat_summary(fun = mean, geom = &quot;point&quot;, shape = 18, size = 4, color = &quot;black&quot;) + labs( title = &quot;Días desde último contacto en campaña anterior (pdays)&quot;, y = &quot;Días&quot;, x = &quot;&quot; ) + theme_bw() grid.arrange(p1, p2,p3,p4,p5, ncol = 2,newpage = FALSE) Ejercicio La interpretación de los gráficos quedan como ejercicio Ahora analizaremos las variables categóricas Code # Para job tabla_job &lt;- df %&gt;% count(job, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;job&quot;, Categoria = job) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Para marital tabla_marital &lt;- df %&gt;% count(marital, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;marital&quot;, Categoria = marital) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Para education tabla_education &lt;- df %&gt;% count(education, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;education&quot;, Categoria = education) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Para default tabla_default &lt;- df %&gt;% count(default, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;default&quot;, Categoria = default) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Para housing tabla_housing &lt;- df %&gt;% count(housing, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;housing&quot;, Categoria = housing) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Para loan tabla_loan &lt;- df %&gt;% count(loan, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;loan&quot;, Categoria = loan) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Para contact tabla_contact &lt;- df %&gt;% count(contact, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;contact&quot;, Categoria = contact) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Para poutcome tabla_poutcome &lt;- df %&gt;% count(poutcome, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;poutcome&quot;, Categoria = poutcome) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Unir todas las tablas bind_rows(tabla_job, tabla_marital, tabla_education,tabla_default, tabla_housing, tabla_loan,tabla_contact, tabla_poutcome) ## Variable Categoria Frecuencia Porcentaje ## 1 job admin. 478 10.57 ## 2 job blue-collar 946 20.92 ## 3 job entrepreneur 168 3.72 ## 4 job housemaid 112 2.48 ## 5 job management 969 21.43 ## 6 job retired 230 5.09 ## 7 job self-employed 183 4.05 ## 8 job services 417 9.22 ## 9 job student 84 1.86 ## 10 job technician 768 16.99 ## 11 job unemployed 128 2.83 ## 12 job unknown 38 0.84 ## 13 marital divorced 528 11.68 ## 14 marital married 2797 61.87 ## 15 marital single 1196 26.45 ## 16 education primary 678 15.00 ## 17 education secondary 2306 51.01 ## 18 education tertiary 1350 29.86 ## 19 education unknown 187 4.14 ## 20 default no 4445 98.32 ## 21 default yes 76 1.68 ## 22 housing no 1962 43.40 ## 23 housing yes 2559 56.60 ## 24 loan no 3830 84.72 ## 25 loan yes 691 15.28 ## 26 contact cellular 2896 64.06 ## 27 contact telephone 301 6.66 ## 28 contact unknown 1324 29.29 ## 29 poutcome failure 490 10.84 ## 30 poutcome other 197 4.36 ## 31 poutcome success 129 2.85 ## 32 poutcome unknown 3705 81.95 En cuanto al estado civil (marital), la mayoría de los clientes están casados (\\(61.87\\%\\)), seguidos por solteros (\\(26.45\\%\\)) y divorciados (\\(11.68\\%\\)), lo que sugiere una base de datos predominantemente compuesta por personas con vínculos conyugales estables. Respecto al nivel educativo (education), más de la mitad de los clientes tiene educación secundaria (\\(51.01\\%\\)), mientras que el \\(29.86\\%\\) alcanzó estudios terciarios y el \\(15.00\\%\\) solo nivel primario. Un pequeño porcentaje (\\(4.14\\%\\)) no reporta su nivel educativo. Estos datos permiten identificar patrones demográficos que podrían ser relevantes para el diseño de estrategias de marketing más efectivas según el perfil del cliente. Ejercicio Continua interpretando las demas variables. Code tabla_default_b &lt;- df %&gt;% count(default, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 1), Etiqueta = paste0(Frecuencia, &quot; (&quot;, Porcentaje, &quot;%)&quot;)) tabla_default_b %&gt;% ggplot(aes(x = default, y = Frecuencia)) + geom_col(fill = &quot;#008B8B&quot;, width = 0.6) + geom_text(aes(label = Etiqueta), vjust = -0.5, size = 5) + facet_wrap(~ &quot;Distribución de la variable default&quot;) + scale_y_continuous(expand = expansion(mult = c(0, 0.15))) + labs(x = &quot;¿Tiene crédito en incumplimiento?&quot;, y = &quot;Frecuencia (Porcentaje)&quot;) + theme_bw(base_size = 14) + theme( plot.title = element_blank(), strip.background = element_rect(fill = &quot;gray80&quot;, color = NA), strip.text = element_text(face = &quot;bold&quot;), panel.grid.major.x = element_blank() ) La gráfica muestra la distribución de la variable default, que indica si un cliente tiene o no un crédito en incumplimiento de pago. Se observa que el \\(98.3\\%\\) de los clientes (\\(4445\\) personas) no tienen incumplimientos, mientras que solo el \\(1.7\\%\\) (\\(76\\) personas) sí presentan incumplimientos. Esta marcada desproporción sugiere que la mayoría de los clientes se encuentran al día con sus compromisos financieros, y que el incumplimiento es un evento poco frecuente en la base de datos. Ejercicio Realiza los gráficos de las variables independientes categóricas faltantes e interprelas. 3.5.5 Análisis exploratorio bivariado Realizaremos la comparacion de la variable y con respecto a las variables numéricas independientes. Code # Diagrama boxplot: y vs age df %&gt;% ggplot(aes(x = y, y = age)) + geom_boxplot(fill = &quot;#1E90FF&quot;, alpha = 0.6, color = &quot;black&quot;) + stat_summary(fun = mean, geom = &quot;point&quot;, shape = 20, size = 3, color = &quot;red&quot;) + labs( title = &quot;Distribución de la edad según la respuesta del cliente&quot;, x = &quot;¿Aceptó el depósito a plazo fijo? (y)&quot;, y = &quot;Edad del cliente&quot; ) + theme_bw() + theme( plot.title = element_text(hjust = 0.5), strip.background = element_rect(fill = &quot;gray90&quot;, color = NA), strip.text = element_text(face = &quot;bold&quot;) ) El grafico muestra la distribución de la edad de los clientes según su respuesta a la campaña de marketing, diferenciando entre quienes no aceptaron (no) y quienes sí aceptaron (yes) contratar un depósito a plazo fijo. Ambas gráficos muestran un comportamiento similar, donde el \\(50\\%\\) de los clientes alrededor de los 40 años o menos en ambos casos. Tambien, se observa que los clientes que aceptaron la oferta tienden a tener un promedio ligeramente superior en comparación con quienes no aceptaron. Esto podría indicar que los clientes de mayor edad muestran una leve mayor disposición a aceptar el producto. En resumen, aunque hay una leve diferencia por edad, esta variable por sí sola no parece explicar completamente la decisión de aceptar el producto. Ejercicio Realiza el gráfico boxplot para las variables balance, duration, campaing, pdays segun la respuesta de campaña de marketing del banco (y) e interprétalos. Realizaremos la comparacion de las variables numéricas independientes con respecto a la variable y Code # Agrupación por &#39;y&#39; age_y &lt;- df %&gt;% group_by(y) %&gt;% summarise(n = length(age), media = mean(age), ds = sd(age), mediana = median(age), minimo = min(age), maximo = max(age), Q1 = quantile(age, 0.25), Q3 = quantile(age, 0.75), IQR = IQR(age)) %&gt;% mutate(variable = &quot;age&quot;, niveles = as.character(y)) %&gt;% select(variable, niveles, everything(), -y) balance_y &lt;- df %&gt;% group_by(y) %&gt;% summarise(n = length(balance), media = mean(balance), ds = sd(balance), mediana = median(balance), minimo = min(balance), maximo = max(balance), Q1 = quantile(balance, 0.25), Q3 = quantile(balance, 0.75), IQR = IQR(balance)) %&gt;% mutate(variable = &quot;balance&quot;, niveles = as.character(y)) %&gt;% select(variable, niveles, everything(), -y) duration_y &lt;- df %&gt;% group_by(y) %&gt;% summarise(n = length(duration), media = mean(duration), ds = sd(duration), mediana = median(duration), minimo = min(duration), maximo = max(duration), Q1 = quantile(duration, 0.25), Q3 = quantile(duration, 0.75), IQR = IQR(duration)) %&gt;% mutate(variable = &quot;duration&quot;, niveles = as.character(y)) %&gt;% select(variable, niveles, everything(), -y) campaign_y &lt;- df %&gt;% group_by(y) %&gt;% summarise(n = length(campaign), media = mean(campaign), ds = sd(campaign), mediana = median(campaign), minimo = min(campaign), maximo = max(campaign), Q1 = quantile(campaign, 0.25), Q3 = quantile(campaign, 0.75), IQR = IQR(campaign)) %&gt;% mutate(variable = &quot;campaign&quot;, niveles = as.character(y)) %&gt;% select(variable, niveles, everything(), -y) pdays_y &lt;- df %&gt;% group_by(y) %&gt;% summarise(n = length(pdays), media = mean(pdays), ds = sd(pdays), mediana = median(pdays), minimo = min(pdays), maximo = max(pdays), Q1 = quantile(pdays, 0.25), Q3 = quantile(pdays, 0.75), IQR = IQR(pdays)) %&gt;% mutate(variable = &quot;pdays&quot;, niveles = as.character(y)) %&gt;% select(variable, niveles, everything(), -y) # Unión de todas las tablas bind_rows(age_y,balance_y,duration_y,campaign_y,pdays_y) ## # A tibble: 10 × 11 ## variable niveles n media ds mediana minimo maximo Q1 Q3 IQR ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 age no 4000 41.0 1.02e1 39 19 86 33 48 15 ## 2 age yes 521 42.5 1.31e1 40 19 87 32 50 18 ## 3 balance no 4000 1403. 3.08e3 420. -3313 71188 61 1407 1346 ## 4 balance yes 521 1572. 2.44e3 710 -1206 26965 171 2160 1989 ## 5 duration no 4000 226. 2.10e2 167 4 3025 96 283 187 ## 6 duration yes 521 553. 3.90e2 442 30 2769 260 755 495 ## 7 campaign no 4000 2.86 3.21e0 2 1 50 1 3 2 ## 8 campaign yes 521 2.27 2.09e0 2 1 24 1 3 2 ## 9 pdays no 4000 36.0 9.63e1 -1 -1 871 -1 -1 0 ## 10 pdays yes 521 68.6 1.22e2 -1 -1 804 -1 98 99 Ejercicio Realiza la interpretación para las variables independientes según y. Realizaremos la comparacion de las variables categóricas independientes con respecto a la variable y Code df %&gt;% group_by(y) %&gt;% count(marital, name = &quot;n&quot;) %&gt;% mutate(categoria = marital, variable = &quot;marital&quot;, porcentaje = (n / sum(n)) * 100) %&gt;% select(y, variable, categoria, n, porcentaje) ## # A tibble: 6 × 5 ## # Groups: y [2] ## y variable categoria n porcentaje ## &lt;fct&gt; &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; ## 1 no marital divorced 451 11.3 ## 2 no marital married 2520 63 ## 3 no marital single 1029 25.7 ## 4 yes marital divorced 77 14.8 ## 5 yes marital married 277 53.2 ## 6 yes marital single 167 32.1 La distribución del estado civil según la respuesta del marketing muestra diferencias relevantes en los patrones de respuesta. Entre quienes respondieron afirmativamente (yes), el \\(53.17\\%\\) están casados, el \\(32.05\\%\\) solteros y el \\(14.78\\%\\) divorciados. En contraste, en el grupo que respondió negativamente (no), la mayoría (\\(63\\%\\)) también está casada, pero la proporción de solteros (\\(25.73%\\)) y divorciados (\\(11.28\\%\\)) es menor. Esta diferencia sugiere que las personas solteras y divorciadas presentan una mayor disposición o probabilidad de responder afirmativamente frente a la acción evaluada por la variable y, mientras que los casados tienden más a rechazarla, lo que podría ser clave para estrategias de segmentación o análisis de comportamiento. Ejercicio Realiza las tablas de las variables independientes segun variable respuesta y. Interpreta las tablas. Code df_plot &lt;- df %&gt;% group_by(y) %&gt;% count(default, name = &quot;n&quot;) %&gt;% mutate(categoria = default, variable = &quot;default&quot;, porcentaje = (n / sum(n)) * 100) %&gt;% select(y, categoria, n, porcentaje) # Gráfica de barras agrupadas con etiquetas df_plot %&gt;% ggplot(aes(x = categoria, y = n, fill = y)) + geom_bar(stat = &quot;identity&quot;, position = position_dodge(width = 0.9)) + geom_text(aes(label = paste0(n, &quot; (&quot;, round(porcentaje, 1), &quot;%)&quot;)), position = position_dodge(width = 0.9), vjust = -0.3, size = 3) + labs(title = &quot;Historial de impago (default)&quot;, x = &quot;Historial de impago (default)&quot;, y = &quot;Cantidad de clientes&quot; ) + theme_bw() + scale_fill_brewer(palette = &quot;Set1&quot;) Ejercicio Interpreta la gráfica. Realiza las demas gráficas con sus respectivas interpretaciones 3.6 Análisis de estadística paramétrica y no paramétrica El análisis de estadística paramétrica y no paramétrica comprende un conjunto de técnicas inferenciales utilizadas para contrastar hipótesis y evaluar relaciones entre variables. La estadística paramétrica se basa en supuestos específicos sobre la distribución de los datos, como la normalidad y la homogeneidad de varianzas, lo que permite aplicar pruebas como la t de Student, ANOVA y pruebas de proporciones. Por su parte, la estadística no paramétrica ofrece métodos alternativos que no requieren dichos supuestos estrictos, siendo útiles cuando los datos no cumplen condiciones de normalidad o se trata de escalas ordinales. Este enfoque incluye pruebas como la de Wilcoxon, Mann-Whitney, Kruskal-Wallis y Chi-cuadrado. Ambos enfoques permiten tomar decisiones estadísticas robustas y fundamentadas, adaptándose a la naturaleza de los datos analizados. 3.6.1 Comparación de medias entre dos grupos independientes con estadística paramétrica Una de las estrategias más empleadas al comparar una variable cuantitativa entre dos grupos independientes es el contraste de medias. No obstante, observar diferencias en los promedios muestrales no implica automáticamente que exista una diferencia estadísticamente significativa a nivel poblacional. Esto se debe a que cada grupo presenta su propia variabilidad (varianza intrínseca), lo cual puede generar diferencias aparentes por el simple azar muestral. Para evaluar si la diferencia observada es estadísticamente significativa, se recurre a pruebas paramétricas como el test \\(Z\\) (cuando se conoce la desviación estándar poblacional y los tamaños muestrales son grandes) o, más comúnmente, al t-test de Student, que es aplicable cuando las desviaciones estándar poblacionales son desconocidas. Este tipo de pruebas permite: Realizar pruebas de hipótesis, bajo la formulación: \\[ H_0: \\mu_1 = \\mu_2 \\quad \\text{vs} \\quad H_a: \\mu_1 \\ne \\mu_2 \\] Construir intervalos de confianza para estimar la diferencia real entre las medias poblacionales con un nivel de confianza específico (por ejemplo, 95%). 3.6.1.1 Condiciones del t-test para muestras independientes Para que los resultados del t-test sean válidos, deben cumplirse las siguientes condiciones: Independencia: Las observaciones dentro y entre los grupos deben ser independientes. Esto se garantiza si el muestreo es aleatorio y si el tamaño muestral no supera el 10% de la población (cuando no se hace con reemplazo). Normalidad: Las poblaciones deben seguir una distribución normal. Si bien esta condición se formula sobre las poblaciones, en la práctica se evalúa con las muestras. La prueba es robusta frente a desviaciones moderadas de normalidad si cada grupo tiene al menos 30 observaciones, gracias al Teorema del Límite Central. Homogeneidad de varianzas (homocedasticidad): Se asume que ambas poblaciones tienen varianzas iguales. Esta condición puede ser verificada con pruebas como Levene o F de Fisher o Bartless. Si no se cumple, se utiliza una versión alternativa del t-test: el Welch Two Sample t-test, que ajusta los grados de libertad para corregir esta desigualdad, aunque con una ligera pérdida de precisión. 3.6.1.2 Grados de libertad En el t-test clásico (varianzas iguales): \\[df = n_1 + n_2 - 2\\] En el t-test de Welch (varianzas desiguales), los grados de libertad se aproximan con: \\[df \\approx \\frac{ \\left( \\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2} \\right)^2 }{ \\frac{ \\left( \\frac{s_1^2}{n_1} \\right)^2 }{n_1 - 1} + \\frac{ \\left( \\frac{s_2^2}{n_2} \\right)^2 }{n_2 - 1} }\\] 3.6.1.3 Error estándar de la diferencia de medias El error estándar (SE) para comparar dos medias es: \\[SE = \\sqrt{ \\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2} }\\] Este valor se utiliza tanto para construir intervalos de confianza como para calcular el estadístico de prueba: \\[t = \\frac{\\bar{x}_1 - \\bar{x}_2}{SE}\\] Cuando se cumplen las condiciones mencionadas, se puede considerar que la diferencia de medias muestrales sigue una distribución t de Student con los grados de libertad apropiados. En consecuencia, los t-scores reemplazan a los z-scores en los cálculos, ajustando así los valores críticos a la incertidumbre inherente al tamaño muestral. Este enfoque proporciona una herramienta poderosa para evaluar efectos de tratamientos, diferencias entre grupos y pruebas de efectividad, en una amplia gama de contextos experimentales y observacionales. 3.6.1.4 Tamaño del Efecto (Effect Size) en comparaciones de medias El tamaño del efecto es una medida que cuantifica la magnitud de la diferencia observada entre grupos, sin depender del tamaño muestral ni de la inferencia estadística. A diferencia de los p-values, que únicamente indican si la diferencia es estadísticamente significativa bajo una hipótesis nula, el tamaño del efecto ofrece una medida de relevancia práctica o importancia clínica de los resultados. En contextos de comparación de medias mediante t-tests para muestras independientes, dos de las métricas más utilizadas para estimar el tamaño del efecto son: La d de Cohen representa la diferencia estandarizada entre medias, es decir, cuántas desviaciones estándar separan en promedio los grupos comparados: \\[d = \\frac{|\\bar{X}_1 - \\bar{X}_2|}{s_p},\\] donde \\(s_p\\) es la desviación estándar combinada. Existen dos formas comunes de calcularla: La primera es desviación estándar ponderada: \\[s_p = \\sqrt{ \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2} }\\] y se usa cuando asumes que las varianzas de los dos grupos son iguales. La segunda es el promedio cuadrático simple: \\[s_p = \\sqrt{ \\frac{s_1^2 + s_2^2}{2} }\\] y se usa cuando asumes que las varianzas de los dos grupos son iguales. Además, la interpretacion de valores de \\(d\\) es: \\(d \\leq 0.2\\): tamaño del efecto pequeño \\(d \\approx 0.5\\): tamaño del efecto mediano \\(d \\geq 0.8\\): tamaño del efecto grande \\(r\\) de Pearson (para t-test) Este coeficiente mide la fuerza de asociación entre una variable categórica binaria (grupo) y una variable continua: \\[r = \\sqrt{ \\frac{t^2}{t^2 + gl} }\\] donde: \\(t\\) es el estadístico del t-test. \\(gl\\) son los grados de libertad. La interpretación de valores de \\(r\\): \\(r \\leq 0.1\\): tamaño del efecto pequeño \\(r \\geq 0.3\\): tamaño del efecto mediano \\(r \\geq 0.5\\): tamaño del efecto grande Ejemplo de presión arterial Se ha recolectado una muestra aleatoria de pacientes para evaluar sus niveles de presión arterial. En el archivo datos_medicos.xlsx se encuentran registradas dos variables continuas: PresionSistolica y PresionDiastolica, correspondientes a la presión sistólica y diastólica de cada individuo, respectivamente. Con base en esta información, verifique si existe o no una diferencia significativa entre la presión sistólica y la diastólica en la muestra analizada, y si esta diferencia es relevante desde el punto de vista práctico. Solución Carguemos los datos Code library(readxl) # Lectura de los datos df &lt;- read_excel(&quot;data/datos_medicos.xlsx&quot;) # Ver las 5 primeras obeservaciones head(df) ## # A tibble: 6 × 2 ## Presion Valores ## &lt;chr&gt; &lt;dbl&gt; ## 1 PresionSistolica 114. ## 2 PresionSistolica 118. ## 3 PresionSistolica 136. ## 4 PresionSistolica 121. ## 5 PresionSistolica 121. ## 6 PresionSistolica 137. Ejercicio Realiza el análisis exploratorio del conjunto de datos Verifiquemos si los datos tiene comportamiento normal Code # dataframe de presion sistolica dfps &lt;- df %&gt;% filter(Presion == &quot;PresionSistolica&quot;) # dataframe de presion diastolica dfpd &lt;- df %&gt;% filter(Presion == &quot;PresionDiastolica&quot;) Code # kolmogorov-smirnov ks.test(scale(dfps$Valores),pnorm) ## ## Asymptotic one-sample Kolmogorov-Smirnov test ## ## data: scale(dfps$Valores) ## D = 0.058097, p-value = 0.8884 ## alternative hypothesis: two-sided Code ks.test(scale(dfpd$Valores),pnorm) ## ## Asymptotic one-sample Kolmogorov-Smirnov test ## ## data: scale(dfpd$Valores) ## D = 0.057927, p-value = 0.8905 ## alternative hypothesis: two-sided Con una confianza del \\(95\\%\\), vemos que las distribuciones de la presión sistolica (\\(D = 0.058097, p-valor = 0.8884\\)) y presión diastolica (\\(D = 0.057927, p-valor = 0.8905\\)) proviene de una distribución normal Verifiquemos igualdad de varianzas (homocedasticidad): Code var.test(dfps$Valores, dfpd$Valores) ## ## F test to compare two variances ## ## data: dfps$Valores and dfpd$Valores ## F = 0.92784, num df = 99, denom df = 99, p-value = 0.7102 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.6242897 1.3789878 ## sample estimates: ## ratio of variances ## 0.9278405 Con una confianza del \\(95\\%\\), vemos que no diferencias estadísticamente significativa en las varianzas de la presión sistolica y diastolica ($F_{(99,99)}=0.92784, p-valor=0.7102). Teorema de razón de varianzas Si \\(s_1^2\\) y \\(s_2^2\\) son las varianzas de muestras aleatorias independientes de tamaño \\(n_1\\) y \\(n_2\\), tomadas de poblaciones normales con varianzas \\(\\sigma_1^2\\) y \\(\\sigma_2^2\\), respectivamente, entonces, una prueba de hipótesis con nivel de significancia \\(\\alpha\\) para la razón de varianzas \\(\\sigma_1^2 / \\sigma_2^2\\) se basa en el siguiente estadístico de prueba: \\[ F = \\frac{s_1^2}{s_2^2} \\] donde \\(F\\) se distribuye como una variable aleatoria con distribución \\(F\\) de Fisher-Snedecor con \\(v_1 = n_1 - 1\\) y \\(v_2 = n_2 - 1\\) grados de libertad. Además, un intervalo de confianza bilateral al nivel \\(1 - \\alpha\\) para la razón de varianzas \\(\\sigma_1^2 / \\sigma_2^2\\) está dado por: \\[ \\left( \\frac{s_1^2}{s_2^2} \\cdot \\frac{1}{F_{1 - \\alpha/2}(v_1, v_2)},\\ \\frac{s_1^2}{s_2^2} \\cdot \\frac{1}{F_{\\alpha/2}(v_1, v_2)} \\right) \\] donde \\(F_{\\alpha/2}(v_1, v_2)\\) y \\(F_{1 - \\alpha/2}(v_1, v_2)\\) son los cuantiles de la distribución F que dejan un área de \\(\\alpha/2\\) en las colas derecha e izquierda, respectivamente. Ejercicio Usando el teorema de razón de varianzas verifica la salida de la función var.test con los datos de presión arterial. Veamos si hay diferencia significativas o no en el promedio de la presión sistolica y diastolica. Code t.test(dfps$Valores, dfpd$Valores, paired=FALSE, # muestras independientes var.equal = TRUE # homocedasticidad ) ## ## Two Sample t-test ## ## data: dfps$Valores and dfpd$Valores ## t = 31.888, df = 198, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 39.36328 44.55275 ## sample estimates: ## mean of x mean of y ## 120.90406 78.94604 La prueba \\(t\\) para muestras independientes nos indica que con una confianza del 95%, se concluye que existe una diferencia estadísticamente significativa entre las medias de la presión sistólica y la presión diastólica (\\(t_{198} = 31.888, p-valor &lt; 0.001\\)). Veamos el calculo del tamaño del efecto Code library(effsize) cohen.d(dfps$Valores, dfpd$Valores, paired = FALSE) ## ## Cohen&#39;s d ## ## d estimate: 4.509702 (large) ## 95 percent confidence interval: ## lower upper ## 3.984821 5.034583 Con base en el resultado del índice de Cohen’s d, se obtiene un valor estimado de \\(4.51\\) (\\(IC_{95\\%}=(3.98,5.03)\\)), lo que indica un tamaño del efecto extremadamente grande. Esto indica que dicha diferencia no solo es estadísticamente significativa, sino también altamente relevante desde el punto de vista práctico o clínico. Teorema de la diferencia de medias (muestras independientes con varianzas iguales) Sea \\(\\bar{X}_1\\) y \\(\\bar{X}_2\\) las medias muestrales de dos poblaciones independientes, con tamaños \\(n_1\\) y \\(n_2\\), y varianzas poblacionales iguales \\(\\sigma_1^2 = \\sigma_2^2 = \\sigma^2\\). Si ambas poblaciones siguen una distribución normal, o si los tamaños muestrales son suficientemente grandes (por el teorema central del límite), entonces la estadística de prueba para contrastar la hipótesis nula: \\[ H_0 : \\mu_1 = \\mu_2 \\quad \\text{vs} \\quad H_1 : \\mu_1 \\neq \\mu_2 \\] está dada por: \\[ t = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{S_p^2 \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right)}} \\] donde \\(S_p^2\\) es la varianza combinada (pooled variance), definida como: \\[ S_p^2 = \\frac{(n_1 - 1)S_1^2 + (n_2 - 1)S_2^2}{n_1 + n_2 - 2} \\] y \\(S_1^2\\) y \\(S_2^2\\) son las varianzas muestrales. Esta estadística sigue una distribución t de Student con \\(n_1 + n_2 - 2\\) grados de libertad. Además, un intervalo de confianza al nivel \\(1 - \\alpha\\) para la diferencia de medias \\(\\mu_1 - \\mu_2\\) está dado por: \\[ \\left( (\\bar{X}_1 - \\bar{X}_2) \\pm t_{(1 - \\alpha/2,\\; n_1 + n_2 - 2)} \\cdot \\sqrt{S_p^2 \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right)} \\right) \\] Ejercicio Usando el teorema de la diferencia de medias verifica la salida de la función t.test con los datos de presión arterial. Aplica el teorema de diferencia de medias con la distribución normal. Ejemplo de comparación de precios por tipo de cuenta Se ha recolectado una muestra aleatoria de cuentas clasificadas en dos tipos: Inversión y Ganancia, con el fin de evaluar si existe una diferencia significativa en el valor promedio de los precios registrados. En la variable Precio se encuentra el valor económico asociado a cada cuenta. Con base en esta información, se propone realizar una prueba estadística para determinar si hay diferencia significativa entre los promedios de precio según el tipo de cuenta, y evaluar si dicha diferencia es relevante desde el punto de vista práctico. Este análisis permitirá tomar decisiones fundamentadas sobre las políticas financieras relacionadas con los tipos de cuenta manejados por la institución. Solución Carguemos los datos Code library(readxl) # Lectura de los datos df &lt;- read_excel(&quot;data/datos_economia.xlsx&quot;) # Ver las 5 primeras observaciones head(df) ## # A tibble: 6 × 2 ## `Tipo de cuenta` Precio ## &lt;chr&gt; &lt;dbl&gt; ## 1 Inversion 4439524. ## 2 Inversion 4769823. ## 3 Inversion 6558708. ## 4 Inversion 5070508. ## 5 Inversion 5129288. ## 6 Inversion 6715065. Ejercicio Realiza el análisis exploratorio del conjunto de datos Verifiquemos si los datos tiene comportamiento normal Code # dataframe de inversion inversion &lt;- df %&gt;% filter(`Tipo de cuenta` == &quot;Inversion&quot;) %&gt;% pull(Precio) # dataframe de ganancia ganancia &lt;- df %&gt;% filter(`Tipo de cuenta` == &quot;Ganancia&quot;)%&gt;% pull(Precio) Code # kolmogorov-smirnov ks.test(scale(inversion),pnorm) ## ## Asymptotic one-sample Kolmogorov-Smirnov test ## ## data: scale(inversion) ## D = 0.058097, p-value = 0.8884 ## alternative hypothesis: two-sided Code ks.test(scale(ganancia),pnorm) ## ## Asymptotic one-sample Kolmogorov-Smirnov test ## ## data: scale(ganancia) ## D = 0.057927, p-value = 0.8905 ## alternative hypothesis: two-sided Con una confianza del \\(95\\%\\), vemos que las distribuciones de la inversión (\\(D = 0.058097, p-valor = 0.8884\\)) y la ganancia (\\(D = 0.057927, p-valor = 0.8905\\)) proviene de una distribución normal Verifiquemos igualdad de varianzas (homocedasticidad): Code var.test(Precio ~ `Tipo de cuenta`,data = df) ## ## F test to compare two variances ## ## data: Precio by Tipo de cuenta ## F = 0.044888, num df = 99, denom df = 99, p-value &lt; 2.2e-16 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.03020281 0.06671472 ## sample estimates: ## ratio of variances ## 0.04488844 Con una confianza del \\(95\\%\\), vemos que hay diferencias estadísticamente significativa en las varianzas (\\(F_{(99,99)}=0.044, p-valor &lt; 0.001\\)). Ejercicio Aplica las pruebas de Bartlett, Levene y Fligner-Killeen e interpreta el resultado Veamos si hay diferencia significativas o no en el promedio de la presión sistolica y diastolica. Code t.test(inversion, ganancia, var.equal = FALSE, paired=FALSE) ## ## Welch Two Sample t-test ## ## data: inversion and ganancia ## t = 46.212, df = 107.87, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 4126960 4496870 ## sample estimates: ## mean of x mean of y ## 5090405.9 778490.6 La prueba de Welch para muestras independientes nos indica que con una confianza del 95%, se concluye que existe una diferencia estadísticamente significativa entre las medias de la presión sistólica y la presión diastólica (\\(t_{107.87} = 46.212, p-valor &lt; 0.001\\)). Veamos el calculo del tamaño del efecto Code library(effsize) cohen.d(inversion, ganancia, paired = FALSE) ## ## Cohen&#39;s d ## ## d estimate: 6.535323 (large) ## 95 percent confidence interval: ## lower upper ## 5.833174 7.237472 Con base en el resultado del índice de Cohen’s d, se obtiene un valor estimado de \\(6.53\\) (\\(IC_{95\\%}=(5.83,7.23)\\)), lo que indica un tamaño del efecto extremadamente grande. Esto indica que dicha diferencia no solo es estadísticamente significativa, sino también altamente relevante en el tipo de cuenta. Teorema de la diferencia de medias (muestras independientes con varianzas iguales) Sea \\(\\bar{X}_1\\) y \\(\\bar{X}_2\\) las medias muestrales de dos poblaciones independientes, con tamaños \\(n_1\\) y \\(n_2\\), y varianzas poblacionales iguales \\(\\sigma_1^2 = \\sigma_2^2 = \\sigma^2\\). Si ambas poblaciones siguen una distribución normal, o si los tamaños muestrales son suficientemente grandes (por el teorema central del límite), entonces la estadística de prueba para contrastar la hipótesis nula: \\[ H_0 : \\mu_1 = \\mu_2 \\quad \\text{vs} \\quad H_1 : \\mu_1 \\neq \\mu_2 \\] está dada por: \\[ t = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{S_p^2 \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right)}} \\] donde \\(S_p^2\\) es la varianza combinada (pooled variance), definida como: \\[ S_p^2 = \\frac{(n_1 - 1)S_1^2 + (n_2 - 1)S_2^2}{n_1 + n_2 - 2} \\] y \\(S_1^2\\) y \\(S_2^2\\) son las varianzas muestrales. Esta estadística sigue una distribución t de Student con \\(n_1 + n_2 - 2\\) grados de libertad. Además, un intervalo de confianza al nivel \\(1 - \\alpha\\) para la diferencia de medias \\(\\mu_1 - \\mu_2\\) está dado por: \\[ \\left( (\\bar{X}_1 - \\bar{X}_2) \\pm t_{(1 - \\alpha/2,\\; n_1 + n_2 - 2)} \\cdot \\sqrt{S_p^2 \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right)} \\right) \\] Ejercicio Usando el teorema de la diferencia de medias verifica la salida de la función t.test con los datos de presión arterial. Aplica el teorema de diferencia de medias con la distribución normal. 3.6.2 Comparación de medias entre dos grupos pareados con estadística paramétrica Dos medias se consideran dependientes o pareadas cuando provienen de muestras relacionadas, es decir, cuando existe una correspondencia directa entre las observaciones de ambos grupos. Este tipo de diseño es común cuando las mediciones se realizan sobre los mismos individuos bajo dos condiciones diferentes. 3.6.2.1 Ejemplos comunes: Comparar el rendimiento de estudiantes en dos pruebas distintas (por ejemplo, lectura y escritura). Evaluar el efecto de un tratamiento médico comparando una variable antes y después del tratamiento en los mismos pacientes. En este contexto, para determinar si hay una diferencia significativa entre las condiciones \\(X\\) e \\(Y\\), se calcula para cada individuo la diferencia: \\[d_i = x_i - y_i\\] Aunque la hipótesis nula plantee que no existe diferencia (es decir, que \\(\\mu_X = \\mu_Y\\)), debido a la variabilidad natural entre observaciones, las diferencias individuales \\(d_i\\) no serán exactamente cero. No obstante, si no hay efecto sistemático, el promedio de estas diferencias tenderá a cero por compensación aleatoria: \\[\\bar{d} = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - y_i)\\] El análisis se centra en evaluar si este promedio de diferencias es significativamente distinto de cero, utilizando una prueba t de muestras pareadas. 3.6.2.2 Supuestos del t-test para muestras dependientes Normalidad: Se asume que las diferencias \\(d_i\\) provienen de una distribución normal. Este supuesto puede evaluarse a partir de la muestra si no se tiene información poblacional. Igualdad de varianzas: No es necesario que las varianzas de los grupos originales sean iguales (no se requiere homocedasticidad). Si los supuestos se cumplen, se puede considerar que: \\[ d_i \\sim \\mathcal{N}(\\mu_d, \\sigma_d^2) \\] Como en la mayoría de situaciones de inferencia estadística, los parámetros poblacionales son desconocidos, por lo que se estiman a partir de la muestra. Bajo estos supuestos, se tiene: \\[ \\bar{d} \\sim \\mathcal{N}(\\mu_d, \\hat{\\sigma}_d^2) \\] donde \\(\\bar{d}\\) es el promedio muestral de las diferencias y \\(\\hat{\\sigma}_d^2\\) es la varianza muestral de dichas diferencias. El test \\(t\\) pareado se utiliza para verificar la hipótesis: \\[ H_0: \\mu_d = 0 \\quad \\text{vs} \\quad H_1: \\mu_d \\neq 0 \\] La estadística de prueba está dada por: \\[ t = \\frac{\\bar{d}}{s_d / \\sqrt{n}} \\sim t_{n-1} \\] donde \\(\\bar{d}\\): media de las diferencias \\(s_d\\): desviación estándar de las diferencias \\(n\\): número de pares Ejemplo: Evaluación del desempeño en una intervención educativa Una institución educativa implementa una nueva estrategia de enseñanza con el objetivo de mejorar el desempeño de los estudiantes en una prueba estandarizada. Para evaluar su efectividad, se selecciona aleatoriamente una muestra de 10 estudiantes y se registra su tiempo (en segundos) para completar una tarea cognitiva específica al inicio del periodo académico. Al finalizar el año, se repite la misma medición con los mismos estudiantes. Este diseño corresponde a un esquema de medidas pareadas, ya que las observaciones antes y después de la intervención se realizan sobre los mismos individuos. Por tanto, el análisis estadístico adecuado consiste en aplicar una prueba t para muestras dependientes, que permita evaluar si la estrategia implementada produjo un cambio significativo en el desempeño de los estudiantes. Code # Datos de tiempos antes y después de la intervención educativa datos &lt;- data.frame( estudiante = c(1:10), antes = c(12.9, 13.5, 12.8, 15.6, 17.2, 19.2, 12.6, 15.3, 14.4, 11.3), despues = c(12.7, 13.6, 12.0, 15.2, 16.8, 20.0, 12.0, 15.9, 16.0, 11.1) ) Con base en estas mediciones, se procederá a aplicar la prueba estadística para determinar si existe evidencia significativa de mejora en los tiempos registrados tras la implementación de la nueva metodología. Solución Veamos si los datos tiene comportamiento normal: Code # prueba de normalidad shapiro.test(datos$antes) ## ## Shapiro-Wilk normality test ## ## data: datos$antes ## W = 0.94444, p-value = 0.6033 Code shapiro.test(datos$despues) ## ## Shapiro-Wilk normality test ## ## data: datos$despues ## W = 0.93638, p-value = 0.5135 La prueba de Shapiro_Will, nos muestra que la intervención de antes (\\(W = 0.9444, p-valor = 0.6033\\)) y despues (\\(W = 0.93638, p-valor = 0.5135\\)) tienen comportamiento normal. Veamos si hay diferencia significativas en los promedios de las intervenciones de antes y despues Code t.test(x = datos$despues, y = datos$antes, paired = TRUE) ## ## Paired t-test ## ## data: datos$despues and datos$antes ## t = 0.21331, df = 9, p-value = 0.8358 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -0.4802549 0.5802549 ## sample estimates: ## mean difference ## 0.05 La prueba \\(t\\) nos indica que no hay diferencias estadísticamente significativa en los promedios de las intervenciones de antes y despues (\\(t_{9}=0.2133, p-valor = 0.8358\\)) Calculemos el tamaño del efecto Code cohen.d(d = datos$antes, f = datos$despues, paired = TRUE) ## ## Cohen&#39;s d ## ## d estimate: -0.0169815 (negligible) ## 95 percent confidence interval: ## lower upper ## -0.1842481 0.1502851 El resultado del tamaño del efecto calculado mediante Cohen’s d para muestras pareadas fue de \\(-0.017\\) (\\(IC_{95\\%}=(-0.184,0.150)\\)), lo cual es prácticamente inexistente desde el punto de vista práctico. El intervalo de confianza nos confirma que no hay evidencia de un cambio significativo ni relevante en los tiempos registrados antes y después de la intervención. 3.6.3 Comparación de dos grupos independientes con estadística no paramétrica El test de Mann–Whitney–Wilcoxon (WMW), también conocido como Wilcoxon rank-sum test o U-test de Mann–Whitney, es una prueba estadística no paramétrica utilizada para comparar dos muestras independientes. Su objetivo es determinar si ambas proceden de poblaciones con distribuciones similares, sin asumir normalidad ni trabajar directamente con las medias, como ocurre en los test t. 3.6.3.1 Fundamento conceptual La idea central del test es la siguiente: si dos muestras provienen de poblaciones con la misma distribución, al combinar todas las observaciones y ordenarlas de menor a mayor, se esperaría que los valores de ambas muestras estén aleatoriamente intercalados. En cambio, si una de las muestras tiende a tener valores sistemáticamente mayores o menores, sus observaciones tenderán a agruparse hacia un extremo del ordenamiento. Desde una perspectiva probabilística, el test contrasta si la probabilidad de que una observación de una población sea mayor que una de la otra es igual a 0.5: \\[ H_0: P(X &gt; Y) = 0.5 \\quad \\text{(no hay diferencia entre grupos)} \\] \\[ H_1: P(X &gt; Y) \\neq 0.5 \\quad \\text{(hay diferencia entre grupos)} \\] Este planteamiento no presupone normalidad ni igualdad de medias, sino que se basa en la equidistribución de las poblaciones. 3.6.3.2 Interpretación y alcance Aunque es frecuente leer que el test de Mann–Whitney–Wilcoxon compara medianas, esta interpretación solo es válida si ambas poblaciones tienen la misma forma de distribución (es decir, misma asimetría y varianza). En general, lo que el test evalúa es una diferencia en tendencias centrales sin especificar la medida exacta (media o mediana). Nota técnica: ¿El test WMW compara medianas? Si bien se suele afirmar que el test de Mann–Whitney–Wilcoxon compara medianas, esto es estrictamente cierto solo cuando ambas poblaciones tienen la misma forma de distribución. Es decir, se requiere que presenten igual dispersión, simetría y curtosis. En ese caso, una diferencia en la ubicación central puede interpretarse como una diferencia de medianas. Sin embargo, si las distribuciones difieren en forma, el test detecta diferencias en la distribución global, y no exclusivamente en la mediana. Por tanto, el test WMW evalúa diferencias en localización general, y su interpretación como comparación de medianas debe hacerse con cautela, y solo bajo condiciones que aseguren homogeneidad de forma entre grupos. 3.6.3.3 Comparación con el test t El test WMW suele ser menos potente que el t-test cuando los supuestos del análisis paramétrico se cumplen (la pérdida de potencia se estima en torno al 5%). Esto se debe a que el WMW trabaja con rangos y no con valores reales, lo que reduce su sensibilidad frente a diferencias pequeñas. Sin embargo, esta misma característica le confiere mayor robustez ante valores atípicos y violaciones de normalidad, convirtiéndolo en una alternativa preferible en contextos donde los datos no cumplen los supuestos clásicos. 3.6.3.4 Supuestos y condiciones de aplicación Para aplicar correctamente el test de Mann–Whitney–Wilcoxon se deben cumplir las siguientes condiciones: Independencia de las observaciones entre los dos grupos. Los datos deben ser al menos ordinales, es decir, deben poder ordenarse de menor a mayor. No se requiere normalidad ni homocedasticidad estricta. Para interpretar el test como una comparación de medianas, se requiere que ambas poblaciones tengan distribuciones con forma similar (igual dispersión y simetría). Es preferible que las muestras tengan tamaños comparables, aunque no es obligatorio. El test de Mann–Whitney–Wilcoxon es una herramienta flexible y robusta para comparar dos muestras independientes cuando no se puede asumir normalidad o cuando existen valores extremos. A cambio de una ligera pérdida de potencia frente al test t, ofrece mayor fiabilidad en contextos no paramétricos y mantiene una base sólida para contrastar diferencias de ubicación entre grupos. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
