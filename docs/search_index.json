[["index.html", "Notas de métodos estadísticos Asignatura", " Notas de métodos estadísticos Carlos de Oro Aguado 2025-07-30 Asignatura La asignatura de Métodos Estadísticos tiene como propósito desarrollar en el estudiante competencias analíticas rigurosas para la comprensión, modelación e interpretación de datos cuantitativos, con base en herramientas estadísticas fundamentales orientadas a la ciencia de datos. A lo largo del curso se emplean enfoques descriptivos, inferenciales y multivariados, complementados con técnicas robustas no paramétricas, con énfasis en aplicaciones reales y toma de decisiones basadas en evidencia. Durante el primer corte, el enfoque se centra en el análisis exploratorio de datos y diagnóstico inferencial, abordando la caracterización de variables mediante medidas de tendencia central, dispersión y forma. Se introducen técnicas de análisis de correlación (coeficientes de Pearson, Spearman y Kendall) como base para evaluar relaciones lineales o no lineales entre variables. Además, se presenta la Regresión Lineal Simple (RLS), incluyendo la identificación de términos básicos, formulación del modelo, interpretación de coeficientes y evaluación de la bondad de ajuste. Se discuten los supuestos del modelo (normalidad, homocedasticidad, independencia y linealidad), y se introducen herramientas para el análisis gráfico de residuos. En el segundo corte, se profundiza en la modelación con RLS, enfocándose en sus aplicaciones prácticas, validación estadística e inferencia sobre los parámetros. Se abordan temas como la construcción de intervalos de confianza, contrastes de hipótesis para los coeficientes de regresión, análisis de significancia del modelo y predicciones puntuales e intervalares. Se refuerzan conceptos clave de validación, tales como el análisis de residuos, influencia y multicolinealidad. Asimismo, se inicia la transición hacia modelos más complejos, preparando el terreno para el análisis multivariado. El tercer corte está dedicado a la Regresión Lineal Múltiple (RLM), donde se modela la respuesta de una variable dependiente a partir de múltiples variables explicativas. Se analizan sus fundamentos matemáticos, estimación por mínimos cuadrados, interpretación de coeficientes parciales y evaluación de supuestos del modelo. Se incluye inferencia sobre parámetros, prueba global de significancia, análisis de varianza (ANOVA), selección de variables y medidas de ajuste como \\(R^2\\) ajustado y el criterio de información de Akaike (AIC). Finalmente, se ofrece una introducción a otros modelos de regresión (como regresión polinómica o con transformaciones) y a los principios básicos del análisis multivariado, orientado a estudiar estructuras de dependencia entre múltiples variables simultáneamente. En conjunto, este curso constituye un pilar fundamental para el desarrollo de habilidades analíticas aplicadas a la ciencia de datos, y prepara al estudiante para abordar con solvencia asignaturas posteriores como inferencia estadística, teoría de la probabilidad, aprendizaje estadístico y análisis multivariante avanzado. "],["intro.html", "Capítulo 1 Introducción 1.1 Introducción a R y RStudio 1.2 Introducción a Git y GitHub 1.3 Introducción a Tidyverse 1.4 Pasos para publicar un libro bookdown en GitHub Pages", " Capítulo 1 Introducción 1.1 Introducción a R y RStudio El primer paso para comenzar a trabajar con R, un lenguaje de programación especializado en estadística, ciencia de datos y visualización, es instalarlo en tu computadora. R es compatible con los principales sistemas operativos, incluyendo Windows, macOS y Linux. 1.1.1 ¿Qué es R? R es un lenguaje de programación y un entorno de software libre dedicado al análisis estadístico y la generación de gráficos. Su potencia radica en una gran variedad de paquetes estadísticos, su comunidad activa y su capacidad de integración con otras herramientas como Python, SQL, y plataformas de visualización como Power BI o Tableau. A continuación, se indican los enlaces oficiales para descargar (paso a paso) R: Descargar R Página oficial del proyecto R (https://cran.r-project.org): Figura 1.1: Software R En esta página puedes seleccionar tu sistema operativo: Para Windows: https://cran.r-project.org/bin/windows/base/ Para macOS: https://cran.r-project.org/bin/macosx/ Para Linux: https://cran.r-project.org/bin/linux/ Se realizará el proceso para la instalación de R para el sistema operativo Windows Figura 1.2: Paso a paso de la instalación de R (izquierda a derecha) 1.1.2 ¿Qué es RStudio? RStudio es un entorno de desarrollo integrado (IDE) que proporciona una interfaz gráfica intuitiva y muy funcional para trabajar con R. Entre sus características destacan: Editor de scripts con resaltado de sintaxis. Consola interactiva para ejecutar comandos. Panel de visualización de datos y objetos en memoria. Gráficos integrados. Soporte para proyectos y versiones de R. Integración con Git, Markdown, Quarto y Shiny. Aunque se puede usar R sin RStudio, la mayoría de los usuarios prefieren trabajar dentro de este entorno por su productividad, organización y facilidad de uso. A continuación, se indican los enlaces oficiales para descargar (paso a paso) RStudio: Descargar RStudio Página oficial de RStudio (ahora llamado Posit, https://posit.co/download/rstudio-desktop/): Figura 1.3: Desarrollo de entorno integrado (IDE) RStudio Selecciona la versión gratuita de RStudio Desktop y descarga el instalador correspondiente a tu sistema operativo. Se realizará el proceso para la instalación de RStudio para el sistema operativo Windows: Figura 1.4: Paso a paso de la instalación de RStudio Una vez finalizada la instalación, puedes iniciar RStudio desde el acceso directo en tu escritorio o buscándolo en el menú de inicio. Figura 1.5: Visualización de RStudio Al abrir RStudio por primera vez, se presenta un entorno dividido en cuatro paneles: Script o editor de código (arriba a la izquierda): donde se escriben los scripts .R o .Rmd. Consola (abajo a la izquierda): donde se ejecutan los comandos directamente. Entorno / Historial (arriba a la derecha): muestra los objetos cargados y el historial de comandos. Archivos, gráficos, paquetes, ayuda y visor (abajo a la derecha): herramientas auxiliares para explorar y trabajar eficientemente. Puedes verificar que R y RStudio están funcionando correctamente ejecutando una operación simple en la consola, como: Code 2 + 3 1.2 Introducción a Git y GitHub 1.2.1 ¿Qué es Git? Git es un sistema de control de versiones distribuido que permite gestionar y registrar los cambios realizados en archivos de un proyecto a lo largo del tiempo. Fue creado por Linus Torvalds y se ha convertido en el estándar para el desarrollo de software y proyectos colaborativos. El enlace es https://git-scm.com/. Figura 1.6: Sotfware Git Ventajas principales de Git Permite llevar un historial detallado de versiones. Facilita la colaboración en proyectos con múltiples personas. Permite trabajar en ramas (branches) para desarrollar funcionalidades de forma aislada. No depende de internet para el trabajo local. 1.2.1.1 Pasos para instalar Git Daremos una guía para la instalación de Git usando Windows (paso a paso): Instalar Git:  https://git-scm.com/downloads Ahora, debes realizar lo siguiente: Figura 1.7: Instalación de Git A continuación, comprobemos la instalación de Git. Figura 1.8: Verificación de Git 1.2.2 ¿Qué es GitHub? GitHub es una plataforma en línea que permite alojar repositorios de Git en la nube. Es ideal para compartir proyectos, colaborar en equipo y automatizar flujos de trabajo. Este es el enlace https://github.com. Figura 1.9: Plataforma GitHub Funciones principales de GitHub Crear y administrar repositorios públicos o privados. Gestionar cambios mediante pull requests. Seguir errores o tareas usando issues. Crear documentación, páginas web y wikis para los proyectos. Automatizar procesos con GitHub Actions. 1.2.2.1 Pasos para instalar GitHub A continuación, se presenta una guía paso a paso para la instalación de GitHub en Windows: Crear una cuenta en GitHub:  https://github.com Ahora, sigue las imagenes: Figura 1.10: Registro en GitHub Despues haces el proceso de verificación Completa el captcha de seguridad. GitHub puede pedirte que verifiques tu correo electrónico. Revisa tu bandeja de entrada y haz clic en el enlace de confirmación. Ingresas al enlace https://github.com y despues: Figura 1.11: Credenciales de verificación en GitHub Al ingresar, este sería el inicio Figura 1.12: Dashboard de GitHub A continuación, vamos a descargar GitHub Desktop para Windows; para ello debes usar el enlace https://desktop.github.com/download/ Figura 1.13: Credenciales de verificación en GitHub Diferencias claves entre Git y GitHub Git GitHub Herramienta local Plataforma en la nube Administra versiones Aloja y comparte repositorios No requiere internet Requiere conexión para sincronizar Se usa desde terminal o IDE Se accede por navegador o API 1.2.2.2 ¿Cómo se relacionan? Git administra tu proyecto localmente, guardando versiones y cambios. GitHub actúa como repositorio remoto, permitiendo subir (push) o descargar (pull) cambios desde y hacia otros colaboradores. Juntos permiten trabajar de forma segura, organizada y colaborativa desde distintos lugares. 1.3 Introducción a Tidyverse El Tidyverse es un conjunto de paquetes integrados para el lenguaje de programación R, diseñados con el objetivo de facilitar el análisis de datos de manera estructurada, legible y eficiente. Su filosofía se basa en el concepto de “datos ordenados” (tidy data), donde cada variable es una columna, cada observación una fila, y cada tipo de unidad observacional forma una tabla. Estos paquetes comparten principios de diseño comunes y una gramática coherente, lo que permite a los usuarios aprender un conjunto de reglas aplicables en todo el ecosistema, aumentando así la productividad y la claridad del código. 1.3.1 Representación visual del ecosistema Tidyverse Figura 1.14: Paquetes de tidyverse 1.3.2 Principales paquetes del Tidyverse A continuación se describen los paquetes más representativos que conforman el núcleo del Tidyverse:  ggplot2 Permite la creación de visualizaciones estadísticas sofisticadas mediante la Gramática de los Gráficos (Grammar of Graphics). Con ggplot2 puedes combinar capas de datos, geometrías, escalas y temas para construir gráficos informativos y estéticamente agradables. Es ampliamente utilizado en análisis exploratorio y comunicación de resultados.  dplyr Facilita la manipulación de datos mediante verbos intuitivos como: filter() para filtrar filas según condiciones lógicas, select() para elegir columnas, mutate() para crear o transformar variables, summarise() para resumir valores, group_by() para operaciones agrupadas. Trabaja perfectamente con tibble y se puede aplicar a bases de datos con dbplyr.  tidyr Su propósito es convertir datos desorganizados en un formato “ordenado”. Algunas de sus funciones clave incluyen: pivot_longer() y pivot_wider() para cambiar el formato de los datos. separate() para dividir una columna en varias. unite() para fusionar columnas en una sola. Estas funciones son fundamentales para preparar datos antes del análisis.  readr Ofrece funciones rápidas y confiables para importar archivos .csv, .tsv, .fwf, entre otros. Es más eficiente que read.table() y permite: Importar con read_csv(), read_delim() o read_fwf(). Detectar problemas de formato con problems(). Controlar tipos de datos con argumentos explícitos.  stringr Simplifica el trabajo con cadenas de texto (caracteres). Proporciona una sintaxis coherente para tareas comunes como: Búsqueda de patrones (str_detect, str_subset), Manipulación (str_replace, str_sub, str_trim), Conteo (str_count), Extracción (str_extract, str_match). Ideal para limpiar y procesar textos en análisis de encuestas, redes sociales o nombres de variables.  forcats Dedicado al tratamiento de factores en R, un tipo especial de variable categórica. forcats ofrece funciones para: Reordenar niveles según frecuencia (fct_infreq()), Fusionar niveles (fct_collapse()), Recodificar (fct_recode()), Ordenar según otras variables (fct_reorder()). Útil en análisis estadísticos donde el tratamiento adecuado de las categorías es clave.  lubridate Permite el manejo sencillo de fechas y horas. Resuelve uno de los aspectos más complejos en análisis temporal con funciones como: ymd(), dmy(), mdy() para convertir cadenas en fechas, hour(), minute(), second() para extraer componentes, interval(), duration() y period() para trabajar con intervalos de tiempo.  haven Permite importar y exportar archivos desde software estadístico como: SPSS (.sav, .zsav), Stata (.dta), SAS (.sas7bdat, .xpt). Esencial para interoperabilidad con datos institucionales y académicos que provienen de otras plataformas.  readxl Importa archivos de Excel (.xls, .xlsx) sin necesidad de tener Excel instalado. Las funciones clave incluyen: read_excel() para leer hojas completas, excel_sheets() para listar las hojas de un archivo. Ideal para usuarios que reciben datos administrativos, contables o estadísticos en formato Excel.  purrr Introduce herramientas de programación funcional en R, permitiendo aplicar funciones a listas o vectores con más control que lapply() o sapply(). Permite: Iterar con map(), map_df(), map_dbl(), etc. Trabajar con errores mediante safely(), possibly(). Manipular listas de manera estructurada. Ideal para automatizar tareas repetitivas.  tibble Es una versión mejorada de los data frames tradicionales. Entre sus ventajas: Muestra solo las primeras 10 filas y columnas visibles. No modifica automáticamente los nombres de columnas. Trabaja mejor con los flujos de trabajo del Tidyverse. 1.3.3 Instalación del Tidyverse en R Para instalar todos los paquetes del núcleo del Tidyverse, simplemente se ejecuta en la consola de R: Code install.packages(&quot;tidyverse&quot;) 1.4 Pasos para publicar un libro bookdown en GitHub Pages Para publicar un libro bookdown en GitHub Pages debes tener lo siguiente: Pre-requisitos Tener una cuenta en GitHub. Haber creado un repositorio público (ej. metodos_estadisticos). Tener Git instalado y configurado. Tener R y RStudio instalado y configurado Instalar el siguiente paquete Code install.packages(&quot;bookdown&quot;) Tener un proyecto bookdown funcional en tu computadora. Abre el archivo _bookdown.yml y asegúrate de incluir: book_filename: &quot;index&quot; output_dir: &quot;docs&quot; Esto hace que el libro se renderice en la carpeta docs, que es donde GitHub Pages busca el sitio por defecto. En RStudio o consola de R, corre: Code bookdown::render_book(&quot;index.Rmd&quot;) Abre la terminal en la carpeta del libro y ejecuta: Code git init git remote add origin https://github.com/cdeoroaguado/metodos_estadistico.git git add docs git commit -m &quot;primer despliegue del libro&quot; git push -u origin main Activa GitHub Pages Ve al repositorio en GitHub. Haz clic en Settings &gt; Pages. En “Source”, selecciona: Branch: main o master Folder: /docs Guarda los cambios. Después de unos segundos, tu libro estará disponible en: Enlace del texto Dale click en este enlace:  https://cdeoroaguado.github.io/metodos_estadistico/ 1.4.1 Video paso a paso de la publicación del libro en GitHub Pages Uno de los pasos más importantes al desarrollar un libro con bookdown es su publicación en línea, permitiendo el acceso abierto y permanente al contenido. Para ello, GitHub Pages se convierte en una herramienta ideal por su facilidad de uso y compatibilidad con proyectos de R. A continuación, se presenta un video tutorial donde se explican paso a paso los procedimientos necesarios para publicar correctamente un libro elaborado en bookdown a través de un repositorio en GitHub: "],["reglas.html", "Capítulo 2 Reglas de curso y diagnostico 2.1 Reglas de las clases 2.2 Política de evaluación y normas de integridad académica 2.3 Fechas de taller y examenes 2.4 Programación del curso por unidad 2.5 Referencias 2.6 Terminos básicos de la estadística 2.7 Diagnostico de estadística básica", " Capítulo 2 Reglas de curso y diagnostico Para asegurar que nuestro espacio de aprendizaje sea un ambiente productivo, respetuoso y justo para cada uno de ustedes, es fundamental que sigamos algunas pautas de convivencia y evaluación. Estas reglas están diseñadas para fomentar la concentración, facilitar la participación y garantizar la integridad académica en todo momento. 2.1 Reglas de las clases Durante la clase Respeto durante explicaciones. Evitar el uso de celulares cuando no sea requerido. Evite conversaciones que puedan irrumpir con el desarrollo de las clases. Si tiene alguna duda, pregunte todo lo que necesite. Durante los exámenes o evaluaciones No se admite ningún tipo de pregunta relacionada con las temáticas vistas. Solo se responderán preguntas para aclaraciones relacionadas con redacción o instrucciones. No se permiten dispositivos electrónicos. 2.2 Política de evaluación y normas de integridad académica Normas de evaluación y sanciones Todo fraude o intento de fraude, en cualquier tipo de evaluación, acarreará al estudiante una calificación de 0.0, sin perjuicio de las acciones disciplinarias a que hubiere lugar Se entiende por FRAUDE ACADÉMICO, cualquier comportamiento o práctica ilícita, empleada para obtener una nota o alcanzar un objetivo en el desarrollo de una actividad académica, que vaya en contra de las normas, reglamentos y procesos pedagógicos que la Institución establece y que atenta contra la integridad intelectual y moral del estudiante. Las evaluaciones parciales o finales no presentadas serán calificadas con cero (0.0). Esta calificación solo podrá ser modificada por la calificación obtenida en una evaluación supletoria. Fuente: Reglamento Estudiantil - Universidad del Norte Inasistencia En toda clase se tomará asistencia. Si las faltas exceden el 25% del total de las clases, el estudiante perderá el derecho del examen final, el cual será calificado en 0,0. Fuente: Reglamento Estudiantil - Universidad del Norte Inasistencias Cuando un estudiante no pueda presentar exámenes o compromisos académicos en la fecha programada por motivos de fuerza mayor, podrá solicitar una evaluación supletoria al profesor de la asignatura, quien tendrá la facultad de autorizar la realización de la misma. La evaluación supletoria se realizará dentro de los diez (10) días hábiles siguientes a la fecha inicialmente programada y es indispensable que el estudiante realice el trámite correspondiente en el sistema de información académico donde será aprobado y fijada la fecha de su realización. Fuente: Reglamento Estudiantil - Universidad del Norte 2.3 Fechas de taller y examenes Estas son las fecha de los taller y los examenes: Fechas importantes Tabla 2.1: Fechas de cortes y distribución de porcentajes Corte Porcentaje Evaluación Semana Primer Corte 25% 5% Actividades Hasta la semana 5 20% Parcial Semana 5 Segundo Corte 25% 5% Actividades Hasta la semana 9 20% Parcial Semana 9 Tercer Corte 25% 5% Actividades Hasta la semana 13 20% Parcial Semana 13 Cuarto Corte 25% 5% Actividades Hasta la semana 16 20% Parcial Fecha de registro Otras fechas para tener en cuenta: \\(6-12\\) de octubre. Semana de receso Fecha limite de retiro: 5 de noviembre 2.4 Programación del curso por unidad Este el contenido del curso de métodos estadísticos: Contenido por corte I corte. Diagnósticos Inferencial Análisis de correlación y RLS: introducción Términos básicos II corte. Análisis de correlación y RLS Modelación y aplicaciones Supuestos e inferencia sobre los parámetros III corte. RLM: Matemáticas y aplicaciones Supuestos e inferencia sobre los parámetros Temas adicionales Otros modelos de regresión Introducción al análisis multivariado 2.5 Referencias Estas son algunas referencias para la clase de métodos Referencias bibliográficas Tabla 2.2: Referencias bibliográficas del curso Referencia Bibliográfica Tipo de referencia Guía De Referencia Idioma Existe en Biblioteca Probabilidad Y Estadística Para Ingeniería Y Ciencias, 2015, CENGAGE Learning. Libro impreso x Español Sí Estadística descriptiva y distribuciones de probabilidad, Ediciones Uninorte 2015. ISBN: 9587419154. Libro impreso x Español Sí Estadística inferencial, Ediciones Uninorte 2020. ISBN: 9587419154. Libro impreso x Español Sí Practical Guide to Cluster Analysis in R: Unsupervised Machine Learning, 2017, STHDA. Libro impreso x Inglés Sí Practical Guide To Principal Component Methods in R: PCA, M(CA), FAMD, MFA, HCPC, factoextra, 2017, STHDA. Libro impreso x Inglés Sí Hands-On Time Series Analysis with R: Perform time series analysis and forecasting using R, 2019, Packt Publishing Ltd. Libro impreso x Inglés Sí 2.6 Terminos básicos de la estadística Definición: Unidad experimental. Es el objeto o entidad sobre la cual se realiza una observación o medición dentro de un estudio estadístico. Ejemplo En un estudio clínico, cada paciente corresponde a una unidad experimental. Definición: Población, muestra, censo. La población es el conjunto completo de unidades experimentales de interés La muestra es un subconjunto de unidades experimentales o de una población. Debe ser representativa y aleatoria. El censo es la enumeración completa de las unidades experimentales de una población. Ejemplo La colección de promedios por carreras de la Universidad del Norte (PPCUN) puede servir como una población estadística, y cualquier subcolección, digamos los PPCUN de la carrera de medicina, puede servir como una muestra de esa población. Definición: Variable aleatoria, dato y observación La variable es la característica que se desea medir u observar. El dato: es el valor específico que toma una variable para una unidad experimental. La observación es el conjunto de datos registrados para una unidad experimental. Ejemplo Una universidad está realizando un estudio para conocer el perfil de sus estudiantes de primer semestre. Para ello, se recolecta información de cada estudiante, como su edad, programa académico y puntaje obtenido en las pruebas de admisión. Para el estudiante Laura Torres, se registraron los siguientes valores: Edad: 18 años Programa académico: Psicología Puntaje de admisión: 92 Solución Variable: Edad, programa académico, puntaje de admisión. Dato: 18 años es el dato para la variable edad, Psicología para programa académico”, 92 para “Puntaje de admisión”. Observación: Edad = 18, Programa = Psicología, Puntaje = 92 Definición: Parametro, estadístico. Un parámetro es cualquier caractéristica numérica de una población. Un estadístico es cualquier caractéristica numérica de una muestra. Ejemplo Una universidad quiere conocer el promedio de edad de todos sus estudiantes de primer semestre. Como sería costoso y demorado consultar a toda la población, se toma una muestra aleatoria de 100 estudiantes y se calcula su promedio de edad. Identifique el paramétro y el estadístico. Solución Parametro: El promedio real de edad de todos los estudiantes de primer semestre de la universidad. Estadístico: El promedio de edad calculado con los 100 estudiantes seleccionados en la muestra. Definición: Estadística descriptiva e inferencial. Estadística descriptiva: Parte de la estadística que organiza, resume y presenta los datos de forma útil. Estadística inferencial: Parte de la estadística que permite inferir propiedades poblacionales a partir de una muestra, sin necesidad de censar toda la población. 2.7 Diagnostico de estadística básica Se realizará un diagnoticos de conceptos básicos Ejercicio En una muestra de pacientes, el número de varones dividido entre el total de pacientes es: ¿Cuál de las siguientes medidas define mejor la tendencia central de los datos: 5, 4, 42, 4, 6? Estadística inferencial es la rama de la estadística que se encarga de: Describir la información obtenida del estudio de una muestra para hacer inferencias sobre la población Describir un conjunto de datos recopilados en una muestra Diseñar científicamente un estudio con el objetivo de tomar decisiones respecto a un problema Estudiar el conjunto de individuos que poseen la característica sujeta a estudio La distribución normal:: Es simétrica Es una distribución de probabilidad de variable discreta Es asimétrica La mediana no coincide con la moda Es bimodal El intervalo [media muestral ± 1,96 EEM (error estándar de la media)]:: No dice gran cosa Comprende un 95% de las veces a la media poblacional Comprende un 99% de las veces a la media poblacional Da una seguridad del 68% Da una seguridad del 5% El intervalo [media muestral ± 1,96 EEM (error estándar de la media)]:: No dice gran cosa Comprende un 95% de las veces a la media poblacional Comprende un 99% de las veces a la media poblacional Da una seguridad del 68% Da una seguridad del 5% Un estimador es: Un parámetro que se utiliza para estimar los estadísticos Un estadístico que se utiliza para estimar los parámetros de la muestra Un estadístico que se utiliza para estimar parámetros poblacionales Un parámetro que se utiliza para estimar algunos estadísticos Son todas falsas Los grados de libertad de una tabla de contingencia (independencia) \\(2\\times 2\\) son: 1 2 3 4 5 La estimación de medias se hace con: La distribución normal El error estándar La distribución \\(t\\) de Student La distribución binomial Ciertas i, ii y iii La estimación de porcentajes se hace con (Señalar lo falso): La distribución normal La distribución t de Student La distribución binomial El porcentaje muestral El error estándar del porcentaje Se desea comparar la talla media entre hombres y mujeres. ¿Cuál será la prueba estadística más apropiada? F de Snedecor Chi-cuadrado t de Student Coeficiente de correlación de Pearson Ninguna de las anteriores Si el contraste \\(H_0: \\mu = 50\\) , \\(H_1: \\mu &lt; 50\\) no se rechaza con un \\(p-valor = 0,12\\), el contraste \\(H_0: \\mu \\geq 30\\) , \\(H_1: \\mu &lt; 30\\): Se rechaza \\(H_0\\) Contraste unilateral cola a la izquierda \\(p-valor = 0.12\\) \\(p-valor = 0.88\\) Ciertas 2 y 4 Si el contraste \\(H_0: \\mu = 100\\) , \\(H_1: μ &gt; 100\\) se acepta con un \\(p-valor = 0,10\\), el contraste \\(H_0: \\mu \\leq 100\\) , \\(H_1: \\mu &gt; 100\\) tiene: \\(p-valor = 0.10\\) Contraste unilateral cola a la derecha \\(p-valor = 0.05\\) \\(p-valor = 0.90\\) Ciertas 2 y 3 "],["eda.html", "Capítulo 3 Análisis exploratorio de datos (EDA) 3.1 ¿Cuándo debo utilizarlo? 3.2 Representación de datos según su naturaleza 3.3 Presentación y análisis de la información en estudios descriptivos 3.4 Análisis explotario con variable respuesta numérica 3.5 Análisis explotario con variable respuesta categórica", " Capítulo 3 Análisis exploratorio de datos (EDA) Figura 3.1: Análisis exploratorio de datos (EDA) El Análisis Exploratorio de Datos (Exploratory Data Analysis, EDA por sus siglas en inglés) es una etapa fundamental del proceso estadístico que consiste en utilizar gráficos, visualizaciones y resúmenes numéricos para examinar un conjunto de datos. Su propósito principal es explorar, descubrir patrones, identificar anomalías y formular posibles hipótesis, sin realizar inferencias estadísticas formales. El EDA busca comprender la estructura de los datos y generar ideas, más que confirmar hipótesis previamente establecidas. 3.1 ¿Cuándo debo utilizarlo? El Análisis Exploratorio de Datos (EDA) es una herramienta poderosa para examinar, comprender y preparar un conjunto de datos. Aunque el análisis esté orientado a hipótesis específicas, el EDA es útil en etapas previas como la limpieza de datos, la detección de errores, el análisis de subgrupos o simplemente para obtener una mejor comprensión de la estructura y comportamiento de los datos. Uno de los pasos iniciales más importantes del EDA es la representación gráfica de los datos, que permite identificar patrones, tendencias y valores atípicos con mayor claridad. 3.1.1 Tipos de análisis exploratorio: No gráfico: Utiliza estadísticas descriptivas para resumir las variables numéricamente. Gráfico: Representa visualmente los datos mediante histogramas, diagramas de caja, gráficos de dispersión, entre otros. Univariado: Analiza una sola variable a la vez, observando su distribución, tendencia central y dispersión. Multivariado: Examina dos o más variables simultáneamente, identificando relaciones o asociaciones entre ellas. Cada una de estas divisiones puede, a su vez, clasificarse según el tipo de variable involucrada: categórica o numérica. 3.2 Representación de datos según su naturaleza La forma en que se representan los datos depende fundamentalmente de su naturaleza, es decir, del tipo de variable que se está analizando. Esta clasificación influye directamente en la selección de métodos gráficos y estadísticos adecuados para el análisis. Tabla 3.1: Fechas de cortes y distribución de porcentajes Naturaleza.de.la.variable Escala.de.Medidas Frecuencias Medidas.de.Localización Medidas.de.Dispersión Medidas.de.Distribución Gráficos Cualitativa Nominal Sí Moda No No Sectores, Barras Ordinal Sí Moda No No Sectores, Barras (sin orden) Cuantitativa Intervalo Agrupadas Media, Mediana y Moda Sí Sí Histograma, Tallo y hojas, Cajas y Bigotes, Dispersión Razón Sí Sí 3.3 Presentación y análisis de la información en estudios descriptivos En los estudios descriptivos, la presentación y análisis de la información constituyen fases clave para comprender las características fundamentales de los datos recolectados. El objetivo principal es resumir y organizar la información de forma clara y accesible, sin realizar inferencias ni establecer relaciones causales. Tabla 3.2: Relación entre tipo de tabla y tipo de gráfico Tipo de Tabla Tipo de Gráfico De Frecuencia (Variable Cualitativa) Barras simples Pastel De Frecuencia (Variable Cuantitativa) Histograma De Asociacion (Dos Variables Cualitativas) Barras compuestas Barras superpuestas De Asociacion (Una Variable Cualitativa y una Cuantitativa Discreta) Barras: Compuestas Superpuestas De Asociacion (Una Variable Cualitativa y una Cuantitativa Continua) Poligono de Frecuencia Box plot (diagrama de cajas y bigotes) De Asociacion (Dos Variables Cuantitativas) Diagrama de Puntos 3.4 Análisis explotario con variable respuesta numérica Para el desarrollo de las visualización trabajaremos con datos sobre los almacenes Walmart, que es un cadena de grande almacenes de Ewa. Figura 3.2: Tienda Walmart El conjunto de datos completos lo puede encontrar este link. Trabajaremos un subconjunto de datos contiene las ventas semanales en dolares, cada tienda tiene un número de identificación y un tipo de tienda específico, las ventas estan separadas por ID de departamento. Junto con las ventas hay variables como si fue de vacaciones o no, la temperatura media durante la semana en esa localidad, el tiempo medio del combustible en dolares por litro esa semana y la tasa de desempleo de esa semana. 3.4.1 Contexto de los datos de Walmart Aquí tienes una explicación de las variables en el conjunto de datos de ventas proporcionado: Unnamed: Columna de índice que parece haber sido incluida al guardar el archivo. No es una variable significativa. store: Identificador del número de la tienda. type: Tipo de tienda, representado por una letra (por ejemplo, “A”, “B”, etc.). n department: Identificador del número de departamento dentro de la tienda. date: Fecha en la que se registró la venta. weekly_sales: Ventas semanales en USD registradas en esa tienda y departamento específicos (Target). is_holiday: Variable booleana que indica si la fecha corresponde a un día festivo o no. Los valores son “True” o “False”. temperature_c: Temperatura en grados Celsius en la fecha registrada. fuel_price_usd_per_l: Precio del combustible en dólares estadounidenses por litro en la fecha registrada. unemployment: Tasa de desempleo en la fecha registrada. El objetivo a resolver es predecir las ventas semanales, pero iniciaremos el análisis exploratorio de los datos de Walmart 3.4.2 Extracción, transformación y carga (ETL) Carguemos el conjunto de datos: Code url &lt;- &quot;https://raw.githubusercontent.com/cdeoroaguado/Datos/refs/heads/main/datamanip/sales.csv&quot; datos &lt;- read.csv(url) Verifiquemos que leímos bien los datos viendo el encabezado y la cola de los datos: Code head(datos,n=5) ## X store type department date weekly_sales is_holiday temperature_c fuel_price_usd_per_l ## 1 0 1 A 1 2010-02-05 24924.50 False 5.727778 0.6794508 ## 2 1 1 A 1 2010-03-05 21827.90 False 8.055556 0.6934520 ## 3 2 1 A 1 2010-04-02 57258.43 False 16.816667 0.7182841 ## 4 3 1 A 1 2010-05-07 17413.94 False 22.527778 0.7489281 ## 5 4 1 A 1 2010-06-04 17558.09 False 27.050000 0.7145857 ## unemployment ## 1 8.106 ## 2 8.106 ## 3 7.808 ## 4 7.808 ## 5 7.808 Las dimensiones, los nombres de las columnas y la estructura de la base de datos se obtienen con los códigos: Code dim(datos) ## [1] 10774 10 Code colnames(datos) ## [1] &quot;X&quot; &quot;store&quot; &quot;type&quot; &quot;department&quot; ## [5] &quot;date&quot; &quot;weekly_sales&quot; &quot;is_holiday&quot; &quot;temperature_c&quot; ## [9] &quot;fuel_price_usd_per_l&quot; &quot;unemployment&quot; Code str(datos) ## &#39;data.frame&#39;: 10774 obs. of 10 variables: ## $ X : int 0 1 2 3 4 5 6 7 8 9 ... ## $ store : int 1 1 1 1 1 1 1 1 1 1 ... ## $ type : chr &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ... ## $ department : int 1 1 1 1 1 1 1 1 1 1 ... ## $ date : chr &quot;2010-02-05&quot; &quot;2010-03-05&quot; &quot;2010-04-02&quot; &quot;2010-05-07&quot; ... ## $ weekly_sales : num 24925 21828 57258 17414 17558 ... ## $ is_holiday : chr &quot;False&quot; &quot;False&quot; &quot;False&quot; &quot;False&quot; ... ## $ temperature_c : num 5.73 8.06 16.82 22.53 27.05 ... ## $ fuel_price_usd_per_l: num 0.679 0.693 0.718 0.749 0.715 ... ## $ unemployment : num 8.11 8.11 7.81 7.81 7.81 ... Eliminemos la variable X y date, ya que no estan en nuestra investigación: Code library(tidyverse) datos %&gt;% select(-X,-date) -&gt; df Code head(df, n=5) ## store type department weekly_sales is_holiday temperature_c fuel_price_usd_per_l unemployment ## 1 1 A 1 24924.50 False 5.727778 0.6794508 8.106 ## 2 1 A 1 21827.90 False 8.055556 0.6934520 8.106 ## 3 1 A 1 57258.43 False 16.816667 0.7182841 7.808 ## 4 1 A 1 17413.94 False 22.527778 0.7489281 7.808 ## 5 1 A 1 17558.09 False 27.050000 0.7145857 7.808 Identifiquemos los valores NA por columna: Code df %&gt;% summarise(across(everything(), ~ sum(is.na(.)), .names = &quot;NA_{.col}&quot;)) ## NA_store NA_type NA_department NA_weekly_sales NA_is_holiday NA_temperature_c NA_fuel_price_usd_per_l ## 1 0 0 0 0 0 0 0 ## NA_unemployment ## 1 0 Otra forma de hacerlo es: Code library(Amelia) missmap(df) 3.4.3 Análisis de la variable weekly_sales (Target) Consideremos el resumen de la weekly_sales: Code df %&gt;% summarise( n = length(weekly_sales), media = mean(weekly_sales), ds = sd(weekly_sales), mediana = median(weekly_sales), minimo = min(weekly_sales), maximo = max(weekly_sales), Q1 = quantile(weekly_sales, 0.25), Q3 = quantile(weekly_sales, 0.75), IQR = IQR(weekly_sales) ) ## n media ds mediana minimo maximo Q1 Q3 IQR ## 1 10774 23843.95 30220.39 12049.06 -1098 293966 3867.115 32349.85 28482.73 La variable weekly_sales fue analizada a partir de 10.774 observaciones. Se obtuvo un promedio de ventas semanales de aproximadamente \\(23.843,95\\) usd (DS = \\(30.220,39\\) usd), donde El \\(50\\%\\) de las ventas semanales se encuentran por debajo de \\(12.049,06\\) usd. El mínimo registrado fue de \\(-1.098\\) usd, lo que indica que en ciertas semanas se presentaron saldos negativos de ventas, posiblemente debido a devoluciones de productos, ajustes contables o cancelaciones, situaciones comunes en grandes cadenas minoristas como Walmart. Por su parte, el máximo alcanzó los \\(293.966\\) usd, lo cual refleja una alta heterogeneidad entre tiendas o departamentos. Veamos un histograma Code df %&gt;% ggplot(aes(x = weekly_sales)) + geom_histogram(aes(y = after_stat(density)), binwidth = 5000, fill = &quot;#2c7fb8&quot;, color = &quot;white&quot;, alpha = 0.6) + geom_density(color = &quot;darkblue&quot;, linewidth = 1.2) + labs( title = &quot;Distribución de Ventas Semanales&quot;, x = &quot;Ventas Semanales (USD)&quot;, y = &quot;Densidad&quot; ) + theme_bw() Veamos un diagrama de cajas y bigotes Code df %&gt;% ggplot(aes(x = &quot;&quot;, y = weekly_sales)) + geom_boxplot(fill = &quot;#a6cee3&quot;, color = &quot;#1f78b4&quot;, outlier.color = &quot;red&quot;) + stat_summary( fun = mean, geom = &quot;point&quot;, shape = 20, size = 3, color = &quot;black&quot; ) + labs( title = &quot;Diagrama de cajas y bigotes de ventas semanales&quot;, x = &quot;&quot;, y = &quot;Ventas Semanales (USD)&quot; ) + theme_bw() La distribución de weekly_sales es altamente asimétrica, con fuerte concentración de valores bajos y una cantidad significativa de valores extremos altos. Esto indica que aunque la mayoría de las tiendas tienen ventas semanales moderadas, existen algunas con ventas excepcionalmente altas que influyen notablemente en los estadísticos como la media y la desviación estándar. 3.4.4 Análisis de las variables características (independientes) Analizaremos el iniciamente las variables numéricas Code df %&gt;% summarise( n = length(temperature_c), media = mean(temperature_c), ds = sd(temperature_c), mediana = median(temperature_c), minimo = min(temperature_c), maximo = max(temperature_c), Q1 = quantile(temperature_c, 0.25), Q3 = quantile(temperature_c, 0.75), IQR = IQR(temperature_c)) %&gt;% mutate(variable = &quot;temperature_c&quot;) -&gt; var_num_temp df %&gt;% summarise( n = length(fuel_price_usd_per_l), media = mean(fuel_price_usd_per_l), ds = sd(fuel_price_usd_per_l), mediana = median(fuel_price_usd_per_l), minimo = min(fuel_price_usd_per_l), maximo = max(fuel_price_usd_per_l), Q1 = quantile(fuel_price_usd_per_l, 0.25), Q3 = quantile(fuel_price_usd_per_l, 0.75), IQR = IQR(fuel_price_usd_per_l)) %&gt;% mutate(variable = &quot;fuel_price_usd_per_l&quot;) -&gt; var_num_fuel df %&gt;% summarise( n = length(unemployment), media = mean(unemployment), ds = sd(unemployment), mediana = median(unemployment), minimo = min(unemployment), maximo = max(unemployment), Q1 = quantile(unemployment, 0.25), Q3 = quantile(unemployment, 0.75), IQR = IQR(unemployment)) %&gt;% mutate(variable = &quot;unemployment&quot;)-&gt; var_num_unemploy bind_rows(var_num_temp, var_num_fuel, var_num_unemploy) %&gt;% select(variable, everything()) ## variable n media ds mediana minimo maximo Q1 Q3 ## 1 temperature_c 10774 15.7319782 9.92244608 16.9666667 -8.3666667 33.827778 7.5833333 24.1666667 ## 2 fuel_price_usd_per_l 10774 0.7497458 0.05949359 0.7433805 0.6641289 1.107674 0.7082456 0.7814213 ## 3 unemployment 10774 8.0820086 0.62435501 8.0990000 3.8790000 9.765000 7.7950000 8.3600000 ## IQR ## 1 16.58333333 ## 2 0.07317569 ## 3 0.56500000 Code library(patchwork) # Boxplot de temperature_c p1 &lt;- df %&gt;% ggplot(aes(x=&quot;&quot;, y = temperature_c)) + geom_boxplot(fill = &quot;#1f77b4&quot;, alpha = 0.7) + labs( title = &quot;Distribucion de temperatura&quot;, y = &quot;Temperatura (°C)&quot;, x = &quot;&quot; ) + theme_bw() # Boxplot de fuel_price_usd_per_l p2 &lt;- df %&gt;% ggplot(aes(x=&quot;&quot;,y = fuel_price_usd_per_l)) + geom_boxplot(fill = &quot;#2ca02c&quot;, alpha = 0.7) + labs( title = &quot;Distribucion del precio del combustible&quot;, y = &quot;Precio (USD/litro)&quot;, x = &quot;&quot; ) + theme_bw() # Boxplot de unemployment p3 &lt;- df %&gt;% ggplot(aes(x=&quot;&quot;,y = unemployment)) + geom_boxplot(fill = &quot;#d62728&quot;, alpha = 0.7) + labs( title = &quot;Distribucion del desempleo&quot;, y = &quot;Tasa de desempleo (%)&quot;, x = &quot;&quot; ) + theme_bw() # Unir los tres gráficos en una sola visualización p1 + p2 + p3 Ejercicio La interpretación de la tabla y el gráfico quedan como ejercicio Ahora analizaremos las variables categóricas Code # Tabla de frecuencias para type tabla_type &lt;- df %&gt;% count(type, name = &quot;Frecuencia&quot;) %&gt;% mutate( Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;type&quot;, Categoria = as.character(type) ) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Tabla de frecuencias para department tabla_department &lt;- df %&gt;% count(department, name = &quot;Frecuencia&quot;) %&gt;% mutate( Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;department&quot;, Categoria = as.character(department) ) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Tabla de frecuencias para is_holiday tabla_holiday &lt;- df %&gt;% count(is_holiday, name = &quot;Frecuencia&quot;) %&gt;% mutate( Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;is_holiday&quot;, Categoria = as.character(is_holiday) ) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Unir todas las tablas bind_rows(tabla_type, tabla_department, tabla_holiday) ## Variable Categoria Frecuencia Porcentaje ## 1 type A 9872 91.63 ## 2 type B 902 8.37 ## 3 department 1 144 1.34 ## 4 department 2 144 1.34 ## 5 department 3 144 1.34 ## 6 department 4 144 1.34 ## 7 department 5 144 1.34 ## 8 department 6 144 1.34 ## 9 department 7 144 1.34 ## 10 department 8 144 1.34 ## 11 department 9 144 1.34 ## 12 department 10 144 1.34 ## 13 department 11 144 1.34 ## 14 department 12 144 1.34 ## 15 department 13 144 1.34 ## 16 department 14 144 1.34 ## 17 department 16 144 1.34 ## 18 department 17 144 1.34 ## 19 department 18 144 1.34 ## 20 department 19 140 1.30 ## 21 department 20 144 1.34 ## 22 department 21 144 1.34 ## 23 department 22 144 1.34 ## 24 department 23 144 1.34 ## 25 department 24 144 1.34 ## 26 department 25 144 1.34 ## 27 department 26 144 1.34 ## 28 department 27 144 1.34 ## 29 department 28 144 1.34 ## 30 department 29 144 1.34 ## 31 department 30 144 1.34 ## 32 department 31 144 1.34 ## 33 department 32 144 1.34 ## 34 department 33 144 1.34 ## 35 department 34 144 1.34 ## 36 department 35 144 1.34 ## 37 department 36 144 1.34 ## 38 department 37 120 1.11 ## 39 department 38 144 1.34 ## 40 department 39 7 0.06 ## 41 department 40 144 1.34 ## 42 department 41 144 1.34 ## 43 department 42 144 1.34 ## 44 department 43 2 0.02 ## 45 department 44 144 1.34 ## 46 department 45 126 1.17 ## 47 department 46 144 1.34 ## 48 department 47 114 1.06 ## 49 department 48 90 0.84 ## 50 department 49 144 1.34 ## 51 department 50 72 0.67 ## 52 department 51 99 0.92 ## 53 department 52 144 1.34 ## 54 department 54 144 1.34 ## 55 department 55 144 1.34 ## 56 department 56 144 1.34 ## 57 department 58 144 1.34 ## 58 department 59 144 1.34 ## 59 department 60 144 1.34 ## 60 department 67 144 1.34 ## 61 department 71 144 1.34 ## 62 department 72 144 1.34 ## 63 department 74 144 1.34 ## 64 department 77 39 0.36 ## 65 department 78 56 0.52 ## 66 department 79 144 1.34 ## 67 department 80 144 1.34 ## 68 department 81 144 1.34 ## 69 department 82 144 1.34 ## 70 department 83 144 1.34 ## 71 department 85 144 1.34 ## 72 department 87 144 1.34 ## 73 department 90 144 1.34 ## 74 department 91 144 1.34 ## 75 department 92 144 1.34 ## 76 department 93 144 1.34 ## 77 department 94 144 1.34 ## 78 department 95 144 1.34 ## 79 department 96 138 1.28 ## 80 department 97 144 1.34 ## 81 department 98 144 1.34 ## 82 department 99 123 1.14 ## 83 is_holiday False 10732 99.61 ## 84 is_holiday True 42 0.39 El \\(91.63\\%\\) de los registros pertenecen al tipo A, lo que indica que la gran mayoría de las observaciones están asociadas a este tipo de tienda, donde el tipo B representa solo el \\(8.37\\%\\) de los casos, lo cual puede sugerir que es menos común, más específico o de menor cobertura. Existen más de \\(80\\) categorías distintas. La mayoría de los departamentos tienen la misma frecuencia de \\(144\\) observaciones (\\(1.34\\%\\)), lo que sugiere una distribución uniforme entre muchas de las categorías. Tambien nos inidica que hay una alta dispersión en las frecuencias de los departamentos, lo que indica que no todos los departamentos tienen el mismo nivel de actividad. Algunos departamentos deben ser tratados con precaución en los análisis inferenciales por su baja frecuencia. Solo el \\(0.39\\%\\) de los registros corresponden a días festivos. Esto muestra una clara desproporción: los días feriados son poco frecuentes en los datos. Aunque son escasos, los registros en días festivos pueden tener un comportamiento distinto (por ejemplo, picos de ventas o cambios de demanda), por lo que deben analizarse por separado o con métodos robustos que no se vean afectados por el desbalance. Code tabla_type_b &lt;- df %&gt;% count(type, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 1), Etiqueta = paste0(Frecuencia, &quot; (&quot;, Porcentaje, &quot;%)&quot;)) ggplot(tabla_type_b, aes(x = type, y = Frecuencia)) + geom_col(fill = &quot;#008B8B&quot;, width = 0.6) + geom_text(aes(label = Etiqueta), vjust = -0.5, size = 5) + facet_wrap(~ &quot;Distribución de la variable type&quot;) + scale_y_continuous(expand = expansion(mult = c(0, 0.15))) + labs(x = &quot;Tipo de tienda&quot;, y = &quot;Frecuencia (Porcentaje)&quot;) + theme_bw(base_size = 14) + theme( plot.title = element_blank(), strip.background = element_rect(fill = &quot;gray80&quot;, color = NA), strip.text = element_text(face = &quot;bold&quot;), panel.grid.major.x = element_blank() ) La gran mayoría de las observaciones (\\(91.6\\%\\)) corresponden al tipo A, con \\(9872\\) registros. Solo el \\(8.4\\%\\) restante corresponde al tipo B, con \\(902\\) registros. Code # Crear tabla de frecuencias para department tabla_department_b &lt;- df %&gt;% count(department, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 1), Etiqueta = paste0(Frecuencia, &quot; (&quot;, Porcentaje, &quot;%)&quot;)) # Gráfico ggplot(tabla_department_b, aes(x = factor(department), y = Frecuencia)) + geom_col(fill = &quot;#008B8B&quot;, width = 0.6) + geom_text(aes(label = Etiqueta), hjust = -0.1, size = 3) + facet_wrap(~ &quot;Distribución de la variable department&quot;) + scale_y_continuous(expand = expansion(mult = c(0, 0.10))) + labs(x = &quot;Departamento&quot;, y = &quot;Frecuencia (Porcentaje)&quot;) + coord_flip() + theme_bw(base_size = 14) + theme( plot.title = element_blank(), strip.background = element_rect(fill = &quot;gray80&quot;, color = NA), strip.text = element_text(face = &quot;bold&quot;), panel.grid.major.y = element_blank(), axis.text.y = element_text(size = 8) ) Ejercicio Interpreta el gráfico de la variable department y muestra únicamente las 10 categorías con mayor porcentaje. Realiza el gráfico para la variable is_holiday e interprétalo. 3.4.5 Análisis exploratorio bivariado Realizaremos la comparacion de la variable weekly_sales con respecto a las variables numéricas independientes. Code # Diagrama de dispersión: weekly_sales vs temperature_c df %&gt;% ggplot(aes(x = temperature_c, y = weekly_sales)) + geom_point(alpha = 0.4, color = &quot;#1E90FF&quot;) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x, se = FALSE, color = &quot;red&quot;) + labs(x = &quot;Temperatura (°C)&quot;, y = &quot;Ventas semanales (uds)&quot; ) + theme_bw()+ facet_grid(.~ &quot;Dispersión entre Weekly Sales y Temperature (°C)&quot;) Los puntos están muy dispersos a lo largo de todo el eje de temperatura (desde aproximadamente \\(-10 °C\\) hasta \\(35 °C\\)), pero no muestran una tendencia clara ascendente ni descendente. La mayoría de las tiendas se agrupan entre temperaturas de \\(0 °C\\) y \\(30 °C\\), lo que es esperado para regiones con climas templados. A lo largo del eje de temperatura, las ventas semanales presentan alta variabilidad, es decir, hay tiendas con ventas altas y bajas a cualquier temperatura. Existen varios puntos con ventas muy elevadas (por encima de 200.000), que podrían representar eventos especiales, promociones, festividades, etc. También se observan múltiples valores cercanos a cero, lo cual podría indicar tiendas cerradas, errores en la base de datos, o semanas sin ventas. No se evidencia una relación lineal clara entre la temperatura y las ventas semanales. La temperatura parece tener un efecto mínimo o nulo sobre las ventas, lo cual sugiere que otras variables podrían tener mayor peso explicativo en el comportamiento de weekly_sales. Ejercicio Realiza el diagrama de dispersión para la variable weekly_sales con respecto a las variables fuel_price_usd_per_l y unemployment e interprétalos. Realizaremos la comparacion de la variable weekly_sales con respecto a las variables categóricas independientes. Code # Agrupación por &#39;type&#39; type_week &lt;- df %&gt;% group_by(type) %&gt;% summarise(n = length(weekly_sales), media = mean(weekly_sales), ds = sd(weekly_sales), mediana = median(weekly_sales), minimo = min(weekly_sales), maximo = max(weekly_sales), Q1 = quantile(weekly_sales, 0.25), Q3 = quantile(weekly_sales, 0.75), IQR = IQR(weekly_sales)) %&gt;% mutate(variable = &quot;type&quot;, niveles = as.character(type)) %&gt;% select(variable, niveles, everything(), -type) # Agrupación por &#39;store&#39; store_week &lt;- df %&gt;% group_by(store) %&gt;% summarise(n = length(weekly_sales), media = mean(weekly_sales), ds = sd(weekly_sales), mediana = median(weekly_sales), minimo = min(weekly_sales), maximo = max(weekly_sales), Q1 = quantile(weekly_sales, 0.25), Q3 = quantile(weekly_sales, 0.75), IQR = IQR(weekly_sales)) %&gt;% mutate(variable = &quot;store&quot;, niveles = as.character(store)) %&gt;% select(variable, niveles, everything(), -store) # Agrupación por &#39;department&#39; dep_week &lt;- df %&gt;% group_by(department) %&gt;% summarise(n = length(weekly_sales), media = mean(weekly_sales), ds = sd(weekly_sales), mediana = median(weekly_sales), minimo = min(weekly_sales), maximo = max(weekly_sales), Q1 = quantile(weekly_sales, 0.25), Q3 = quantile(weekly_sales, 0.75), IQR = IQR(weekly_sales)) %&gt;% mutate(variable = &quot;department&quot;, niveles = as.character(department)) %&gt;% select(variable, niveles, everything(), -department) # Agrupación por &#39;is_holiday&#39; holi_week &lt;- df %&gt;% group_by(is_holiday) %&gt;% summarise(n = length(weekly_sales), media = mean(weekly_sales), ds = sd(weekly_sales), mediana = median(weekly_sales), minimo = min(weekly_sales), maximo = max(weekly_sales), Q1 = quantile(weekly_sales, 0.25), Q3 = quantile(weekly_sales, 0.75), IQR = IQR(weekly_sales)) %&gt;% mutate(variable = &quot;is_holiday&quot;, niveles = as.character(is_holiday)) %&gt;% select(variable, niveles, everything(), -is_holiday) # Unión de todas las tablas bind_rows(type_week, store_week, dep_week, holi_week) ## # A tibble: 96 × 11 ## variable niveles n media ds mediana minimo maximo Q1 Q3 IQR ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 type A 9872 23675. 30129. 11944. -1098 293966. 3862. 31982. 28120. ## 2 type B 902 25697. 31156. 13336. -798 232559. 3998. 38195. 34197. ## 3 store 1 901 20897. 26994. 9775. -698 140504. 3199 30186. 26987. ## 4 store 2 897 26517. 32682. 13765. -1098 178983. 4892. 34612. 29720. ## 5 store 4 901 26127. 31202. 13064. -88 165766. 4571. 35552. 30982. ## 6 store 6 894 21561. 23658. 13201. -698 119812. 4284. 30962. 26678. ## 7 store 10 902 25697. 31156. 13336. -798 232559. 3998. 38195. 34197. ## 8 store 13 913 25664. 31499. 13050. -98 166872. 4396. 34686. 30290. ## 9 store 14 885 30384. 40467. 14793. -498 293966. 4386 37384. 32998. ## 10 store 19 906 19931. 24662. 11092. -449 147449. 3695. 24861. 21166. ## # ℹ 86 more rows La variable type clasifica las tiendas en dos categorías: A y B, donde el \\(91.6\\%\\) de los registros corresponde a tiendas tipo A (\\(n = 9872\\)) y solo el \\(8.4\\%\\) a tipo B (\\(n = 902\\)). A pesar de su menor frecuencia, las tiendas tipo B presentan una media de ventas semanales más alta de \\(25696.68\\) usd (DS = \\(31155.87\\) usd) comparada con las de tipo A de \\(23674.67\\) usd (DS = \\(30129.41\\) usd). El \\(50\\%\\) de las tiendas tipo B tiene ventas semanales por debajo de 13336.08 usd, mientras que en las tipo A este valor es de \\(11943.920\\) usd. Además, las tiendas tipo B presentan un rango intercuartílico más amplio (IQR = \\(34196.80\\) usd) en comparación con las tipo A (IQR = \\(28119.99\\) usd), lo que indica una mayor dispersión en la distribución de sus ventas semanales. Estos datos sugieren que, aunque las tiendas tipo B son menos frecuentes, tienden a mostrar un mejor desempeño en ventas, acompañado de una mayor variabilidad en sus resultados. La variable is_holiday identifica si una semana corresponde a un periodo festivo (True) o no (False). La mayoría de los registros (\\(99.6\\%\\)) corresponden a semanas no festivas (\\(n = 10732\\)), mientras que solo el \\(0.4\\%\\) pertenece a semanas festivas (\\(n = 42\\)). Las semanas no festivas presentan una media de ventas semanales de \\(23934.91 usd\\) (DS = \\(30,244.33\\) usd), significativamente superior a la de las semanas festivas, que registran en promedio apenas \\(600.55\\) usd (DS = \\(1054.73\\) usd). El \\(50\\%\\) de las semanas no festivas tiene ventas por debajo de \\(12135.16\\) usd, mientras que en las semanas festivas ese valor cae a tan solo \\(37.50\\) usd. El rango intercuartílico (IQR) también es mucho más amplio en las semanas no festivas (\\(28555.85\\) usd) que en las festivas (\\(928\\) usd), lo que indica no solo un volumen mayor de ventas en semanas regulares, sino también una mayor variabilidad. Estos resultados reflejan que las semanas festivas se asocian con un desempeño comercial considerablemente menor en comparación con las semanas ordinarias. Ejercicio Realiza la interpretación para la variable weekly_sales con respecto a las variables department y store. Code # boxplot: weekly_sales vs tipo df %&gt;% ggplot(aes(x = type, y = weekly_sales)) + geom_boxplot(fill = &quot;#87CEFA&quot;, outlier.colour = &quot;red&quot;, outlier.shape = 16) + stat_summary(fun = mean, geom = &quot;point&quot;, shape = 18, size = 3, color = &quot;darkblue&quot;) + labs(x = &quot;Tipo de tienda&quot;, y = &quot;Ventas semanales (usd)&quot; ) + theme_bw()+ facet_grid(.~&quot;Distribución de Weekly Sales por tipo de tienda&quot;) El gráfico compara las ventas semanales de las tiendas tipo A y B. Se observa que, aunque hay muchas más tiendas tipo A, las tiendas tipo B presentan un promedio de ventas semanales ligeramente más alto, lo cual se refleja en el rombo azul más elevado en su caja. Además, las tiendas tipo B muestran mayor variación en sus ventas, es decir, algunas venden mucho y otras menos, mientras que las tipo A tienen un comportamiento un poco más concentrado. Los puntos rojos sobre las cajas indican semanas con ventas excepcionalmente altas, siendo más frecuentes en las tiendas tipo A. En conjunto, esto sugiere que las tiendas tipo B, aunque menos numerosas, tienden a tener un mejor desempeño promedio, pero con mayor variabilidad; mientras que las tiendas tipo A tienen más casos extremos de ventas muy altas. Ejercicio Realiza la gráfica para la variable weekly_sales con respecto a las variables department, is_holiday y store. Interprétala. Realiza el análisis bivariado con respecto a las variables independientes. Paquete GGally El paquete GGally es una extensión de ggplot2 que facilita la creación de gráficos multivariados para análisis exploratorio de datos. Una de sus funciones más utilizadas es ggpairs(), que permite visualizar simultáneamente relaciones entre varias variables, tanto numéricas como categóricas, mediante: Diagramas de dispersión (scatterplots), Histogramas o densidades en la diagonal, Correlaciones entre pares de variables numéricas. Esto es especialmente útil para detectar patrones, asociaciones o valores atípicos en conjuntos de datos con múltiples variables. Su instalación y carga del paquete Code install.packages(&quot;GGally&quot;) library(GGally) Modo de uso del paquete GGally: Code library(GGally) df %&gt;% ggpairs() Ejercicio Menciona los errores que puedes encontrar en el gráfico 3.5 Análisis explotario con variable respuesta categórica 3.5.1 Contexto del conjunto de datos de marketing de un banco Este conjunto de datos corresponde a campañas de marketing directo realizadas por una institución bancaria portuguesa, cuyo objetivo era promover la contratación de depósitos a plazo fijo por parte de sus clientes. Las campañas se llevaron a cabo principalmente mediante llamadas telefónicas, y los datos recolectados reflejan tanto características socioeconómicas del cliente como información específica de la interacción comercial. El conjunto contiene 4521 observaciones y 17 variables, entre las cuales se incluyen datos demográficos, financieros y relacionados con el historial de contacto de cada cliente. A continuación se describen las variables: Estas son las variables age: Edad del cliente. job: Profesión del cliente (por ejemplo: desempleado, servicios, gestión). marital: Estado civil del cliente (soltero, casado, divorciado). education: Nivel educativo (primaria, secundaria, terciaria). default: Indica si el cliente tiene crédito en incumplimiento (sí/no). balance: Saldo promedio anual de la cuenta bancaria. housing: Indica si posee préstamo hipotecario (sí/no). loan: Indica si tiene préstamo personal (sí/no). contact: Tipo de comunicación utilizada (celular o fijo). day: Día del mes en que se realizó el último contacto. month: Mes del último contacto. duration: Duración de la última llamada (en segundos). campaign: Número de contactos realizados durante la campaña actual. pdays: Número de días transcurridos desde el último contacto previo (valor -1 indica que no hubo contacto anterior). previous: Número de contactos previos al actual. poutcome: Resultado de una campaña anterior (éxito, fracaso, desconocido). y: Variable objetivo que indica si el cliente aceptó (yes) o no aceptó (no) contratar un depósito a plazo fijo. El objetivo principal es predecir si un cliente aceptará o no un depósito a plazo fijo (y), a partir de sus características personales, financieras y del historial de contactos anteriores. Este análisis permitirá a la entidad financiera optimizar sus estrategias de marketing, enfocándose en los perfiles con mayor probabilidad de conversión, reduciendo costos y mejorando la eficiencia de las campañas. Inicialmente, haremos un análisis exploratorio de los datos. 3.5.2 Extracción, transformación y carga (ETL) Carguemos el conjunto de datos: Code url &lt;- &quot;https://raw.githubusercontent.com/cdeoroaguado/Datos/refs/heads/main/datamanip/bank.csv&quot; datos &lt;- read.csv(url, sep = &quot;;&quot;, stringsAsFactors = TRUE) Verifiquemos que leímos bien los datos viendo el encabezado y la cola de los datos: Code head(datos,n=5) ## age job marital education default balance housing loan contact day month duration campaign pdays ## 1 30 unemployed married primary no 1787 no no cellular 19 oct 79 1 -1 ## 2 33 services married secondary no 4789 yes yes cellular 11 may 220 1 339 ## 3 35 management single tertiary no 1350 yes no cellular 16 apr 185 1 330 ## 4 30 management married tertiary no 1476 yes yes unknown 3 jun 199 4 -1 ## 5 59 blue-collar married secondary no 0 yes no unknown 5 may 226 1 -1 ## previous poutcome y ## 1 0 unknown no ## 2 4 failure no ## 3 1 failure no ## 4 0 unknown no ## 5 0 unknown no Las dimensiones, los nombres de las columnas y la estructura de la base de datos se obtienen con los códigos: Code dim(datos) ## [1] 4521 17 Code colnames(datos) ## [1] &quot;age&quot; &quot;job&quot; &quot;marital&quot; &quot;education&quot; &quot;default&quot; &quot;balance&quot; &quot;housing&quot; &quot;loan&quot; ## [9] &quot;contact&quot; &quot;day&quot; &quot;month&quot; &quot;duration&quot; &quot;campaign&quot; &quot;pdays&quot; &quot;previous&quot; &quot;poutcome&quot; ## [17] &quot;y&quot; Code str(datos) ## &#39;data.frame&#39;: 4521 obs. of 17 variables: ## $ age : int 30 33 35 30 59 35 36 39 41 43 ... ## $ job : Factor w/ 12 levels &quot;admin.&quot;,&quot;blue-collar&quot;,..: 11 8 5 5 2 5 7 10 3 8 ... ## $ marital : Factor w/ 3 levels &quot;divorced&quot;,&quot;married&quot;,..: 2 2 3 2 2 3 2 2 2 2 ... ## $ education: Factor w/ 4 levels &quot;primary&quot;,&quot;secondary&quot;,..: 1 2 3 3 2 3 3 2 3 1 ... ## $ default : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ balance : int 1787 4789 1350 1476 0 747 307 147 221 -88 ... ## $ housing : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 2 2 2 2 1 2 2 2 2 ... ## $ loan : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 2 1 2 1 1 1 1 1 2 ... ## $ contact : Factor w/ 3 levels &quot;cellular&quot;,&quot;telephone&quot;,..: 1 1 1 3 3 1 1 1 3 1 ... ## $ day : int 19 11 16 3 5 23 14 6 14 17 ... ## $ month : Factor w/ 12 levels &quot;apr&quot;,&quot;aug&quot;,&quot;dec&quot;,..: 11 9 1 7 9 4 9 9 9 1 ... ## $ duration : int 79 220 185 199 226 141 341 151 57 313 ... ## $ campaign : int 1 1 1 4 1 2 1 2 2 1 ... ## $ pdays : int -1 339 330 -1 -1 176 330 -1 -1 147 ... ## $ previous : int 0 4 1 0 0 3 2 0 0 2 ... ## $ poutcome : Factor w/ 4 levels &quot;failure&quot;,&quot;other&quot;,..: 4 1 1 4 4 1 2 4 4 1 ... ## $ y : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 1 1 1 1 1 1 1 1 1 ... Para facilitar el análisis exploratorio y evitar redundancias o ruido en el modelo, se eliminarán las variables day, month y previous. Code library(tidyverse) datos %&gt;% select(-day, -month, -previous) -&gt; df Code head(df, n=5) ## age job marital education default balance housing loan contact duration campaign pdays poutcome ## 1 30 unemployed married primary no 1787 no no cellular 79 1 -1 unknown ## 2 33 services married secondary no 4789 yes yes cellular 220 1 339 failure ## 3 35 management single tertiary no 1350 yes no cellular 185 1 330 failure ## 4 30 management married tertiary no 1476 yes yes unknown 199 4 -1 unknown ## 5 59 blue-collar married secondary no 0 yes no unknown 226 1 -1 unknown ## y ## 1 no ## 2 no ## 3 no ## 4 no ## 5 no Identifiquemos los valores NA por columna: Code df %&gt;% summarise(across(everything(), ~ sum(is.na(.)), .names = &quot;NA_{.col}&quot;)) ## NA_age NA_job NA_marital NA_education NA_default NA_balance NA_housing NA_loan NA_contact NA_duration ## 1 0 0 0 0 0 0 0 0 0 0 ## NA_campaign NA_pdays NA_poutcome NA_y ## 1 0 0 0 0 Otra forma de hacerlo es: Code library(Amelia) missmap(df) 3.5.3 Análisis de la variable y (Target) Consideremos el resumen de la y: Code df %&gt;% count(y) %&gt;% mutate(porcentaje = (n/sum(n))*100) ## y n porcentaje ## 1 no 4000 88.476 ## 2 yes 521 11.524 La variable y representa el resultado de la campaña de marketing, indicando si el cliente aceptó (yes) o no aceptó (no) contratar un depósito a plazo fijo. De un total de \\(4521\\) observaciones, el \\(88.48\\%\\) de los clientes (\\(n = 4000\\)) no aceptaron la oferta, mientras que solo el \\(11.52\\%\\) (\\(n = 521\\)) sí lo hicieron. Esta distribución refleja un fuerte desequilibrio en los clientes, lo que sugiere que la mayoría de los clientes no están interesados en este producto financiero, y dicho desequilibrio debe considerarse cuidadosamente al construir modelos de predicción. Veamos un diagrama de barras Code # Crear tabla de frecuencias para department tabla_y &lt;- df %&gt;% count(y, name = &quot;Clientes&quot;) %&gt;% mutate(Porcentaje = round(Clientes / sum(Clientes) * 100, 1), Etiqueta = paste0(Clientes, &quot; (&quot;, Porcentaje, &quot;%)&quot;)) # Gráfico tabla_y %&gt;% ggplot(aes(x = factor(y), y = Clientes)) + geom_col(fill = &quot;#008B8B&quot;, width = 0.6) + geom_text(aes(label = Etiqueta), vjust = -0.5, size = 3) + facet_grid(~ &quot;Distribución de la campaña de marketing (no/yes)&quot;) + scale_y_continuous(expand = expansion(mult = c(0, 0.15))) + labs(x = &quot;Campaña de marketing&quot;, y = &quot;número de clientes (Porcentaje)&quot;) + #coord_flip() + theme_bw(base_size = 14) + theme( plot.title = element_blank(), strip.background = element_rect(fill = &quot;gray80&quot;, color = NA), strip.text = element_text(face = &quot;bold&quot;), panel.grid.major.y = element_blank(), axis.text.y = element_text(size = 8) ) El gráfico de barras muestra claramente la distribución de respuestas en la campaña de marketing, evidenciando que la gran mayoría de los clientes no aceptaron la oferta del depósito a plazo fijo. Específicamente, el \\(88.5\\%\\) de los clientes (\\(4000\\) personas) rechazaron la campaña (no), mientras que solo el \\(11.5&#39;%\\) (\\(521\\) personas) decidieron aceptarla (yes). Esta marcada diferencia indica un fuerte desbalance en las clases de la variable objetivo, lo cual es relevante al momento de construir modelos predictivos, ya que se requiere considerar técnicas que manejen adecuadamente este desequilibrio para no sesgar el modelo hacia la clase mayoritaria. 3.5.4 Análisis de las variables características (independientes) Analizaremos el iniciamente las variables numéricas Code df %&gt;% summarise( n = length(age), media = mean(age), ds = sd(age), mediana = median(age), minimo = min(age), maximo = max(age), Q1 = quantile(age, 0.25), Q3 = quantile(age, 0.75), IQR = IQR(age)) %&gt;% mutate(variable = &quot;age&quot;) -&gt; var_num_age df %&gt;% summarise( n = length(balance), media = mean(balance), ds = sd(balance), mediana = median(balance), minimo = min(balance), maximo = max(balance), Q1 = quantile(balance, 0.25), Q3 = quantile(balance, 0.75), IQR = IQR(balance)) %&gt;% mutate(variable = &quot;balance&quot;) -&gt; var_num_bal df %&gt;% summarise( n = length(duration), media = mean(duration), ds = sd(duration), mediana = median(duration), minimo = min(duration), maximo = max(duration), Q1 = quantile(duration, 0.25), Q3 = quantile(duration, 0.75), IQR = IQR(duration)) %&gt;% mutate(variable = &quot;duration&quot;)-&gt; var_num_dur df %&gt;% summarise( n = length(campaign), media = mean(campaign), ds = sd(campaign), mediana = median(campaign), minimo = min(campaign), maximo = max(campaign), Q1 = quantile(campaign, 0.25), Q3 = quantile(campaign, 0.75), IQR = IQR(campaign)) %&gt;% mutate(variable = &quot;campaign&quot;)-&gt; var_num_camp df %&gt;% summarise( n = length(pdays), media = mean(pdays), ds = sd(pdays), mediana = median(pdays), minimo = min(pdays), maximo = max(pdays), Q1 = quantile(pdays, 0.25), Q3 = quantile(pdays, 0.75), IQR = IQR(pdays)) %&gt;% mutate(variable = &quot;pdays&quot;)-&gt; var_num_pdays bind_rows(var_num_age, var_num_bal, var_num_dur,var_num_camp,var_num_pdays) %&gt;% select(variable, everything()) ## variable n media ds mediana minimo maximo Q1 Q3 IQR ## 1 age 4521 41.17010 10.576211 39 19 87 33 49 16 ## 2 balance 4521 1422.65782 3009.638142 444 -3313 71188 69 1480 1411 ## 3 duration 4521 263.96129 259.856633 185 4 3025 104 329 225 ## 4 campaign 4521 2.79363 3.109807 2 1 50 1 3 2 ## 5 pdays 4521 39.76664 100.121124 -1 -1 871 -1 -1 0 El análisis estadístico de las variables numéricas revela características clave de los clientes contactados durante la campaña de marketing. La edad promedio es de \\(41.17\\) años (DS = \\(10.58\\) años), con un rango de \\(19\\) a \\(87\\) años, lo que indica una población adulta diversa. El saldo promedio anual en la cuenta bancaria (balance) es de \\(1422.66\\) USD (DS = \\(3009.64\\) USD), evidenciando una alta dispersión y la presencia de valores extremos, desde \\(-3313\\) hasta \\(71188\\) USD. La duración de las llamadas telefónicas presenta un promedio de \\(263.96\\) segundos (DS = \\(259.86\\) segundos), con el \\(50\\%\\) de las observaciones por debajo de \\(185\\) segundos y un rango que va desde \\(4\\) hasta \\(3025\\) segundos, lo que sugiere una distribución muy dispersa y posiblemente sesgada. En cuanto al número de contactos durante la campaña (campaign), se observa un promedio de \\(2.79\\) contactos (DS = \\(3.11\\)), con el \\(50\\%\\) de los registros por debajo de \\(2\\) y valores extremos que alcanzan hasta \\(50\\), aunque la mayoría de los clientes fue contactado pocas veces (rango intercuartílico de \\(P75% = 3\\) y \\(P25% = 1\\)). Por último, la variable pdays, que indica los días transcurridos desde el último contacto en campañas anteriores, tiene una media de \\(39.77\\) días (DS = \\(100.12\\) días), pero con el \\(50\\%\\) de los registros y los percentiles \\(25\\%\\) y \\(75\\%\\) en \\(-1\\), lo que indica que la mayoría de los clientes no había sido contactada previamente, a pesar de que algunos registros superan los \\(800\\) días. Estos datos permiten identificar comportamientos heterogéneos y posibles segmentos dentro de la base de clientes. Code library(patchwork) library(gridExtra) # Boxplot de age p1 &lt;- df %&gt;% ggplot(aes(x = &quot;&quot;, y = age)) + geom_boxplot(fill = &quot;#1f77b4&quot;, alpha = 0.7) + stat_summary(fun = mean, geom = &quot;point&quot;, shape = 18, size = 4, color = &quot;black&quot;) + labs( title = &quot;Distribución de la edad&quot;, y = &quot;Años&quot;, x = &quot;&quot; ) + theme_bw() # Boxplot de balance p2 &lt;- df %&gt;% ggplot(aes(x = &quot;&quot;, y = balance)) + geom_boxplot(fill = &quot;#2f43b1&quot;, alpha = 0.7) + stat_summary(fun = mean, geom = &quot;point&quot;, shape = 18, size = 4, color = &quot;black&quot;) + labs( title = &quot;Distribución del balance de la cuenta&quot;, y = &quot;Usd&quot;, x = &quot;&quot; ) + theme_bw() # Diagrama de boxplot para duration p3 &lt;- df %&gt;% ggplot(aes(x = &quot;&quot;, y = duration)) + geom_boxplot(fill = &quot;#2ca02c&quot;, alpha = 0.7) + stat_summary(fun = mean, geom = &quot;point&quot;, shape = 18, size = 4, color = &quot;black&quot;) + labs( title = &quot;Distribución de la duración de llamada (duration)&quot;, y = &quot;Segundos&quot;, x = &quot;&quot; ) + theme_bw() # Diagrama de boxplot para campaign p4 &lt;-df %&gt;% ggplot(aes(x = &quot;&quot;, y = campaign)) + geom_boxplot(fill = &quot;#ff7f0e&quot;, alpha = 0.7) + stat_summary(fun = mean, geom = &quot;point&quot;, shape = 18, size = 4, color = &quot;black&quot;) + labs( title = &quot;Distribución del número de contactos (campaign)&quot;, y = &quot;Número de contactos&quot;, x = &quot;&quot; ) + theme_bw() # Diagrama de boxplot para pdays p5 &lt;-df %&gt;% ggplot(aes(x = &quot;&quot;, y = pdays)) + geom_boxplot(fill = &quot;#9467bd&quot;, alpha = 0.7) + stat_summary(fun = mean, geom = &quot;point&quot;, shape = 18, size = 4, color = &quot;black&quot;) + labs( title = &quot;Días desde último contacto en campaña anterior (pdays)&quot;, y = &quot;Días&quot;, x = &quot;&quot; ) + theme_bw() grid.arrange(p1, p2,p3,p4,p5, ncol = 2,newpage = FALSE) Ejercicio La interpretación de los gráficos quedan como ejercicio Ahora analizaremos las variables categóricas Code # Para job tabla_job &lt;- df %&gt;% count(job, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;job&quot;, Categoria = job) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Para marital tabla_marital &lt;- df %&gt;% count(marital, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;marital&quot;, Categoria = marital) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Para education tabla_education &lt;- df %&gt;% count(education, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;education&quot;, Categoria = education) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Para default tabla_default &lt;- df %&gt;% count(default, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;default&quot;, Categoria = default) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Para housing tabla_housing &lt;- df %&gt;% count(housing, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;housing&quot;, Categoria = housing) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Para loan tabla_loan &lt;- df %&gt;% count(loan, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;loan&quot;, Categoria = loan) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Para contact tabla_contact &lt;- df %&gt;% count(contact, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;contact&quot;, Categoria = contact) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Para poutcome tabla_poutcome &lt;- df %&gt;% count(poutcome, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 2), Variable = &quot;poutcome&quot;, Categoria = poutcome) %&gt;% select(Variable, Categoria, Frecuencia, Porcentaje) # Unir todas las tablas bind_rows(tabla_job, tabla_marital, tabla_education,tabla_default, tabla_housing, tabla_loan,tabla_contact, tabla_poutcome) ## Variable Categoria Frecuencia Porcentaje ## 1 job admin. 478 10.57 ## 2 job blue-collar 946 20.92 ## 3 job entrepreneur 168 3.72 ## 4 job housemaid 112 2.48 ## 5 job management 969 21.43 ## 6 job retired 230 5.09 ## 7 job self-employed 183 4.05 ## 8 job services 417 9.22 ## 9 job student 84 1.86 ## 10 job technician 768 16.99 ## 11 job unemployed 128 2.83 ## 12 job unknown 38 0.84 ## 13 marital divorced 528 11.68 ## 14 marital married 2797 61.87 ## 15 marital single 1196 26.45 ## 16 education primary 678 15.00 ## 17 education secondary 2306 51.01 ## 18 education tertiary 1350 29.86 ## 19 education unknown 187 4.14 ## 20 default no 4445 98.32 ## 21 default yes 76 1.68 ## 22 housing no 1962 43.40 ## 23 housing yes 2559 56.60 ## 24 loan no 3830 84.72 ## 25 loan yes 691 15.28 ## 26 contact cellular 2896 64.06 ## 27 contact telephone 301 6.66 ## 28 contact unknown 1324 29.29 ## 29 poutcome failure 490 10.84 ## 30 poutcome other 197 4.36 ## 31 poutcome success 129 2.85 ## 32 poutcome unknown 3705 81.95 En cuanto al estado civil (marital), la mayoría de los clientes están casados (\\(61.87\\%\\)), seguidos por solteros (\\(26.45\\%\\)) y divorciados (\\(11.68\\%\\)), lo que sugiere una base de datos predominantemente compuesta por personas con vínculos conyugales estables. Respecto al nivel educativo (education), más de la mitad de los clientes tiene educación secundaria (\\(51.01\\%\\)), mientras que el \\(29.86\\%\\) alcanzó estudios terciarios y el \\(15.00\\%\\) solo nivel primario. Un pequeño porcentaje (\\(4.14\\%\\)) no reporta su nivel educativo. Estos datos permiten identificar patrones demográficos que podrían ser relevantes para el diseño de estrategias de marketing más efectivas según el perfil del cliente. Ejercicio Continua interpretando las demas variables. Code tabla_default_b &lt;- df %&gt;% count(default, name = &quot;Frecuencia&quot;) %&gt;% mutate(Porcentaje = round(Frecuencia / sum(Frecuencia) * 100, 1), Etiqueta = paste0(Frecuencia, &quot; (&quot;, Porcentaje, &quot;%)&quot;)) tabla_default_b %&gt;% ggplot(aes(x = default, y = Frecuencia)) + geom_col(fill = &quot;#008B8B&quot;, width = 0.6) + geom_text(aes(label = Etiqueta), vjust = -0.5, size = 5) + facet_wrap(~ &quot;Distribución de la variable default&quot;) + scale_y_continuous(expand = expansion(mult = c(0, 0.15))) + labs(x = &quot;¿Tiene crédito en incumplimiento?&quot;, y = &quot;Frecuencia (Porcentaje)&quot;) + theme_bw(base_size = 14) + theme( plot.title = element_blank(), strip.background = element_rect(fill = &quot;gray80&quot;, color = NA), strip.text = element_text(face = &quot;bold&quot;), panel.grid.major.x = element_blank() ) La gráfica muestra la distribución de la variable default, que indica si un cliente tiene o no un crédito en incumplimiento de pago. Se observa que el \\(98.3\\%\\) de los clientes (\\(4445\\) personas) no tienen incumplimientos, mientras que solo el \\(1.7\\%\\) (\\(76\\) personas) sí presentan incumplimientos. Esta marcada desproporción sugiere que la mayoría de los clientes se encuentran al día con sus compromisos financieros, y que el incumplimiento es un evento poco frecuente en la base de datos. Ejercicio Realiza los gráficos de las variables independientes categóricas faltantes e interprelas. 3.5.5 Análisis exploratorio bivariado Realizaremos la comparacion de la variable y con respecto a las variables numéricas independientes. Code # Diagrama boxplot: y vs age df %&gt;% ggplot(aes(x = y, y = age)) + geom_boxplot(fill = &quot;#1E90FF&quot;, alpha = 0.6, color = &quot;black&quot;) + stat_summary(fun = mean, geom = &quot;point&quot;, shape = 20, size = 3, color = &quot;red&quot;) + labs( title = &quot;Distribución de la edad según la respuesta del cliente&quot;, x = &quot;¿Aceptó el depósito a plazo fijo? (y)&quot;, y = &quot;Edad del cliente&quot; ) + theme_bw() + theme( plot.title = element_text(hjust = 0.5), strip.background = element_rect(fill = &quot;gray90&quot;, color = NA), strip.text = element_text(face = &quot;bold&quot;) ) El grafico muestra la distribución de la edad de los clientes según su respuesta a la campaña de marketing, diferenciando entre quienes no aceptaron (no) y quienes sí aceptaron (yes) contratar un depósito a plazo fijo. Ambas gráficos muestran un comportamiento similar, donde el \\(50\\%\\) de los clientes alrededor de los 40 años o menos en ambos casos. Tambien, se observa que los clientes que aceptaron la oferta tienden a tener un promedio ligeramente superior en comparación con quienes no aceptaron. Esto podría indicar que los clientes de mayor edad muestran una leve mayor disposición a aceptar el producto. En resumen, aunque hay una leve diferencia por edad, esta variable por sí sola no parece explicar completamente la decisión de aceptar el producto. Ejercicio Realiza el gráfico boxplot para las variables balance, duration, campaing, pdays segun la respuesta de campaña de marketing del banco (y) e interprétalos. Realizaremos la comparacion de las variables numéricas independientes con respecto a la variable y Code # Agrupación por &#39;y&#39; age_y &lt;- df %&gt;% group_by(y) %&gt;% summarise(n = length(age), media = mean(age), ds = sd(age), mediana = median(age), minimo = min(age), maximo = max(age), Q1 = quantile(age, 0.25), Q3 = quantile(age, 0.75), IQR = IQR(age)) %&gt;% mutate(variable = &quot;age&quot;, niveles = as.character(y)) %&gt;% select(variable, niveles, everything(), -y) balance_y &lt;- df %&gt;% group_by(y) %&gt;% summarise(n = length(balance), media = mean(balance), ds = sd(balance), mediana = median(balance), minimo = min(balance), maximo = max(balance), Q1 = quantile(balance, 0.25), Q3 = quantile(balance, 0.75), IQR = IQR(balance)) %&gt;% mutate(variable = &quot;balance&quot;, niveles = as.character(y)) %&gt;% select(variable, niveles, everything(), -y) duration_y &lt;- df %&gt;% group_by(y) %&gt;% summarise(n = length(duration), media = mean(duration), ds = sd(duration), mediana = median(duration), minimo = min(duration), maximo = max(duration), Q1 = quantile(duration, 0.25), Q3 = quantile(duration, 0.75), IQR = IQR(duration)) %&gt;% mutate(variable = &quot;duration&quot;, niveles = as.character(y)) %&gt;% select(variable, niveles, everything(), -y) campaign_y &lt;- df %&gt;% group_by(y) %&gt;% summarise(n = length(campaign), media = mean(campaign), ds = sd(campaign), mediana = median(campaign), minimo = min(campaign), maximo = max(campaign), Q1 = quantile(campaign, 0.25), Q3 = quantile(campaign, 0.75), IQR = IQR(campaign)) %&gt;% mutate(variable = &quot;campaign&quot;, niveles = as.character(y)) %&gt;% select(variable, niveles, everything(), -y) pdays_y &lt;- df %&gt;% group_by(y) %&gt;% summarise(n = length(pdays), media = mean(pdays), ds = sd(pdays), mediana = median(pdays), minimo = min(pdays), maximo = max(pdays), Q1 = quantile(pdays, 0.25), Q3 = quantile(pdays, 0.75), IQR = IQR(pdays)) %&gt;% mutate(variable = &quot;pdays&quot;, niveles = as.character(y)) %&gt;% select(variable, niveles, everything(), -y) # Unión de todas las tablas bind_rows(age_y,balance_y,duration_y,campaign_y,pdays_y) ## # A tibble: 10 × 11 ## variable niveles n media ds mediana minimo maximo Q1 Q3 IQR ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 age no 4000 41.0 10.2 39 19 86 33 48 15 ## 2 age yes 521 42.5 13.1 40 19 87 32 50 18 ## 3 balance no 4000 1403. 3075. 420. -3313 71188 61 1407 1346 ## 4 balance yes 521 1572. 2444. 710 -1206 26965 171 2160 1989 ## 5 duration no 4000 226. 210. 167 4 3025 96 283 187 ## 6 duration yes 521 553. 390. 442 30 2769 260 755 495 ## 7 campaign no 4000 2.86 3.21 2 1 50 1 3 2 ## 8 campaign yes 521 2.27 2.09 2 1 24 1 3 2 ## 9 pdays no 4000 36.0 96.3 -1 -1 871 -1 -1 0 ## 10 pdays yes 521 68.6 122. -1 -1 804 -1 98 99 Ejercicio Realiza la interpretación para las variables independientes según y. Realizaremos la comparacion de las variables categóricas independientes con respecto a la variable y Code df %&gt;% group_by(y) %&gt;% count(marital, name = &quot;n&quot;) %&gt;% mutate(categoria = marital, variable = &quot;marital&quot;, porcentaje = (n / sum(n)) * 100) %&gt;% select(y, variable, categoria, n, porcentaje) ## # A tibble: 6 × 5 ## # Groups: y [2] ## y variable categoria n porcentaje ## &lt;fct&gt; &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; ## 1 no marital divorced 451 11.3 ## 2 no marital married 2520 63 ## 3 no marital single 1029 25.7 ## 4 yes marital divorced 77 14.8 ## 5 yes marital married 277 53.2 ## 6 yes marital single 167 32.1 La distribución del estado civil según la respuesta del marketing muestra diferencias relevantes en los patrones de respuesta. Entre quienes respondieron afirmativamente (yes), el \\(53.17\\%\\) están casados, el \\(32.05\\%\\) solteros y el \\(14.78\\%\\) divorciados. En contraste, en el grupo que respondió negativamente (no), la mayoría (\\(63\\%\\)) también está casada, pero la proporción de solteros (\\(25.73%\\)) y divorciados (\\(11.28\\%\\)) es menor. Esta diferencia sugiere que las personas solteras y divorciadas presentan una mayor disposición o probabilidad de responder afirmativamente frente a la acción evaluada por la variable y, mientras que los casados tienden más a rechazarla, lo que podría ser clave para estrategias de segmentación o análisis de comportamiento. Ejercicio Realiza las tablas de las variables independientes segun variable respuesta y. Interpreta las tablas. Code df_plot &lt;- df %&gt;% group_by(y) %&gt;% count(default, name = &quot;n&quot;) %&gt;% mutate(categoria = default, variable = &quot;default&quot;, porcentaje = (n / sum(n)) * 100) %&gt;% select(y, categoria, n, porcentaje) # Gráfica de barras agrupadas con etiquetas df_plot %&gt;% ggplot(aes(x = categoria, y = n, fill = y)) + geom_bar(stat = &quot;identity&quot;, position = position_dodge(width = 0.9)) + geom_text(aes(label = paste0(n, &quot; (&quot;, round(porcentaje, 1), &quot;%)&quot;)), position = position_dodge(width = 0.9), vjust = -0.3, size = 3) + labs(title = &quot;Historial de impago (default)&quot;, x = &quot;Historial de impago (default)&quot;, y = &quot;Cantidad de clientes&quot; ) + theme_bw() + scale_fill_brewer(palette = &quot;Set1&quot;) "],["applications.html", "Capítulo 4 Applications 4.1 Example one 4.2 Example two", " Capítulo 4 Applications Some significant applications are demonstrated in this chapter. 4.1 Example one 4.2 Example two "],["final-words.html", "Capítulo 5 Final Words", " Capítulo 5 Final Words We have finished a nice book. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
